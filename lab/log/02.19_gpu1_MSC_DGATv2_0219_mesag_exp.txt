pooling_ratio 0.2, dropout0.2, hidden_dim 64, outdim 128
epochs 50, lr 0.0001, weight_decay 0.001
pooling_ratio 0.2, dropout0.2, hidden_dim 64, outdim 128
epochs 50, lr 0.0001, weight_decay 0.001
TRAIN, epoch 0, loss 0.5247391755066636, acc 0.7599052017501216,recall 0.5383423394787031,precision 0.7111962626633772,specificity 0.8807576720799861,[tp,tn,fp,fn]: [40647, 121918, 16506, 34857]
VAL, loss 0.38794967195124935, acc 0.8334145347160768,f1 0.5911664226451928, recall 0.4778680763768345,precision 0.7748848515864892,specificity 0.9532203389830508,[tp,tn,fp,fn]: [12113, 71706, 3519, 13235]

TRAIN, epoch 1, loss 0.4770428287085115, acc 0.7851707116412999,recall 0.6123384191566009,precision 0.7347827468929786,specificity 0.8794428711784084,[tp,tn,fp,fn]: [46234, 121736, 16688, 29270]
VAL, loss 0.36621717839924034, acc 0.8432581309098863,f1 0.6453702870512013, recall 0.5658829098942717,precision 0.7508375209380235,specificity 0.9367231638418079,[tp,tn,fp,fn]: [14344, 70465, 4760, 11004]

TRAIN, epoch 2, loss 0.46408201537828236, acc 0.7922291612131185,recall 0.6354630218266581,precision 0.73924565512141,specificity 0.877737964514824,[tp,tn,fp,fn]: [47980, 121500, 16924, 27524]
VAL, loss 0.36996877080076873, acc 0.8407624312688297,f1 0.628482613032686, recall 0.5344011361843144,precision 0.7627681738836646,specificity 0.9439946826188103,[tp,tn,fp,fn]: [13546, 71012, 4213, 11802]

TRAIN, epoch 3, loss 0.4567811128548501, acc 0.7963380202685015,recall 0.6483365119728756,precision 0.7420455062226197,specificity 0.8770661157024794,[tp,tn,fp,fn]: [48952, 121407, 17017, 26552]
VAL, loss 0.3640848287322587, acc 0.8432283018305111,f1 0.6335216047230551, recall 0.5376361054126558,precision 0.7710325318246111,specificity 0.9462013958125624,[tp,tn,fp,fn]: [13628, 71178, 4047, 11720]

TRAIN, epoch 4, loss 0.45022816049134756, acc 0.7999326876332223,recall 0.6555679169315533,precision 0.7466662644059615,specificity 0.878677108015951,[tp,tn,fp,fn]: [49498, 121630, 16794, 26006]
VAL, loss 0.36710765696451214, acc 0.8387042247919422,f1 0.6090895946792616, recall 0.49857976960706957,precision 0.7825386996904025,specificity 0.9533133931538718,[tp,tn,fp,fn]: [12638, 71713, 3512, 12710]

TRAIN, epoch 5, loss 0.443985437198725, acc 0.8032281889233761,recall 0.661739775376139,precision 0.7511237390820668,specificity 0.880403687221869,[tp,tn,fp,fn]: [49964, 121869, 16555, 25540]
VAL, loss 0.36648272286376077, acc 0.841756733914669,f1 0.623821117072825, recall 0.520593340697491,precision 0.7781119169762368,specificity 0.9499767364572947,[tp,tn,fp,fn]: [13196, 71462, 3763, 12152]

TRAIN, epoch 6, loss 0.4399594496677186, acc 0.8051587449983172,recall 0.6680308328035601,precision 0.7521921975662134,specificity 0.8799557880136393,[tp,tn,fp,fn]: [50439, 121807, 16617, 25065]
VAL, loss 0.35892421005070985, acc 0.8434271623596791,f1 0.6278800482075763, recall 0.5241044658355689,precision 0.7828982261771466,specificity 0.9510269192422732,[tp,tn,fp,fn]: [13285, 71541, 3684, 12063]

TRAIN, epoch 7, loss 0.43791326284653753, acc 0.8062291986088778,recall 0.6704015681288409,precision 0.753412219989581,specificity 0.8803169970525342,[tp,tn,fp,fn]: [50618, 121857, 16567, 24886]
VAL, loss 0.3600562968635478, acc 0.8450777047517724,f1 0.6354212977045651, recall 0.5356635632002524,precision 0.7808384610960952,specificity 0.9493386507145231,[tp,tn,fp,fn]: [13578, 71414, 3811, 11770]

TRAIN, epoch 8, loss 0.43546473011020626, acc 0.8079774503571295,recall 0.677858126721763,precision 0.7533597303384018,specificity 0.8789516268855112,[tp,tn,fp,fn]: [51181, 121668, 16756, 24323]
VAL, loss 0.35765591833089705, acc 0.8472353414932438,f1 0.6452878976774253, recall 0.5513255483667351,precision 0.7778581765557163,specificity 0.9469458291791293,[tp,tn,fp,fn]: [13975, 71234, 3991, 11373]

TRAIN, epoch 9, loss 0.4335195400718797, acc 0.8091881380651434,recall 0.679182559864378,precision 0.7554877869118124,specificity 0.8801002716291972,[tp,tn,fp,fn]: [51281, 121827, 16597, 24223]
VAL, loss 0.3540427231602943, acc 0.8499000725840932,f1 0.6623725174449814, recall 0.5841881016253748,precision 0.7647180334641603,specificity 0.9394350282485876,[tp,tn,fp,fn]: [14808, 70669, 4556, 10540]

TRAIN, epoch 10, loss 0.4315500432812576, acc 0.8101884746269773,recall 0.6848378893833439,precision 0.7546630082606031,specificity 0.8785615211235046,[tp,tn,fp,fn]: [51708, 121614, 16810, 23796]
VAL, loss 0.3557181397533088, acc 0.8478418661072057,f1 0.6482149835635963, recall 0.5562174530534953,precision 0.7766760315099432,specificity 0.9461083416417414,[tp,tn,fp,fn]: [14099, 71171, 4054, 11249]

TRAIN, epoch 11, loss 0.4300079840142388, acc 0.8111934856587263,recall 0.689539627039627,precision 0.7543940996623825,specificity 0.8775501358145986,[tp,tn,fp,fn]: [52063, 121474, 16950, 23441]
VAL, loss 0.3530816132753891, acc 0.8494625794199239,f1 0.6592392527571461, recall 0.5777576140129399,precision 0.7674772036474165,specificity 0.9410169491525424,[tp,tn,fp,fn]: [14645, 70788, 4437, 10703]

TRAIN, epoch 12, loss 0.4292777247039004, acc 0.8112542537676227,recall 0.6919765840220385,precision 0.7531859070464768,specificity 0.8763148009015778,[tp,tn,fp,fn]: [52247, 121303, 17121, 23257]
VAL, loss 0.35177725126022613, acc 0.8504171099599296,f1 0.6627661959201973, recall 0.5832018305191731,precision 0.7674696293219812,specificity 0.9404586241276172,[tp,tn,fp,fn]: [14783, 70746, 4479, 10565]

TRAIN, epoch 13, loss 0.42758913527478865, acc 0.8124228712464007,recall 0.6959763721127358,precision 0.7536932388629127,specificity 0.875939143501127,[tp,tn,fp,fn]: [52549, 121251, 17173, 22955]
VAL, loss 0.3505921348736868, acc 0.8517693615582711,f1 0.67268256268388, recall 0.604347483036137,precision 0.7584414298445391,specificity 0.9351412429378531,[tp,tn,fp,fn]: [15319, 70346, 4879, 10029]

TRAIN, epoch 14, loss 0.42634969345005186, acc 0.8138111888111889,recall 0.6979630218266581,precision 0.7558121190390821,specificity 0.8770010980754782,[tp,tn,fp,fn]: [52699, 121398, 17026, 22805]
VAL, loss 0.34919492931715357, acc 0.8525051455161922,f1 0.6852268386877732, recall 0.6369733312292883,precision 0.7413903939755717,specificity 0.9251312728481224,[tp,tn,fp,fn]: [16146, 69593, 5632, 9202]

TRAIN, epoch 15, loss 0.42501324653482836, acc 0.8143113570921058,recall 0.6985722610722611,precision 0.7566346291780233,specificity 0.8774417731029301,[tp,tn,fp,fn]: [52745, 121459, 16965, 22759]
VAL, loss 0.3487926038177885, acc 0.8524454873574419,f1 0.6796338672768879, recall 0.6209957393088212,precision 0.750500619815009,specificity 0.9304353605849119,[tp,tn,fp,fn]: [15741, 69992, 5233, 9607]

TRAIN, epoch 16, loss 0.4249500652881671, acc 0.8139747952582177,recall 0.6979232888323798,precision 0.7562137649962689,specificity 0.8772756169450384,[tp,tn,fp,fn]: [52696, 121436, 16988, 22808]
VAL, loss 0.35002687726162673, acc 0.8513915265528521,f1 0.6737251135172895, recall 0.6087659775919204,precision 0.7542033235581622,specificity 0.9331472249916916,[tp,tn,fp,fn]: [15431, 70196, 5029, 9917]

TRAIN, epoch 17, loss 0.42341328384293064, acc 0.8149611084103062,recall 0.6996450519177791,precision 0.7575466421923623,specificity 0.8778607755880483,[tp,tn,fp,fn]: [52826, 121517, 16907, 22678]
VAL, loss 0.35079702173299676, acc 0.8515804440555617,f1 0.6725026876412383, recall 0.6046236389458735,precision 0.7575502941031091,specificity 0.9347956131605184,[tp,tn,fp,fn]: [15326, 70320, 4905, 10022]

TRAIN, epoch 18, loss 0.4235170101913044, acc 0.8153350660035152,recall 0.7008502860775588,precision 0.7577432519510274,specificity 0.8777813095994914,[tp,tn,fp,fn]: [52917, 121506, 16918, 22587]
VAL, loss 0.352414018412115, acc 0.8512920962882682,f1 0.6690711156348188, recall 0.5964573141865236,precision 0.7618159830696362,specificity 0.9371618477899635,[tp,tn,fp,fn]: [15119, 70498, 4727, 10229]

TRAIN, epoch 19, loss 0.4229650353891438, acc 0.8151480872069108,recall 0.7005853994490359,precision 0.7574568626047111,specificity 0.8776368259839334,[tp,tn,fp,fn]: [52897, 121486, 16938, 22607]
VAL, loss 0.3491209112584467, acc 0.8519881081403557,f1 0.6761519383892441, recall 0.6130661196149597,precision 0.7537103501794549,specificity 0.9324958457959455,[tp,tn,fp,fn]: [15540, 70147, 5078, 9808]

TRAIN, epoch 20, loss 0.42272779211663286, acc 0.815325717063685,recall 0.7014197923288832,precision 0.7574045736023912,specificity 0.8774562214644859,[tp,tn,fp,fn]: [52960, 121461, 16963, 22544]
VAL, loss 0.35154013286766683, acc 0.8517295894524375,f1 0.6724652960815323, recall 0.6039135237494082,precision 0.7585728444003964,specificity 0.935234297108674,[tp,tn,fp,fn]: [15308, 70353, 4872, 10040]

TRAIN, epoch 21, loss 0.42199319649315964, acc 0.8157697917056206,recall 0.7028501801229073,precision 0.757638056079036,specificity 0.8773623071143732,[tp,tn,fp,fn]: [53068, 121448, 16976, 22436]
VAL, loss 0.34926164838623885, acc 0.8527835502570272,f1 0.6829821856800274, recall 0.6292015149124192,precision 0.7468158831241806,specificity 0.9281222997673646,[tp,tn,fp,fn]: [15949, 69818, 5407, 9399]

TRAIN, epoch 22, loss 0.42218518577219905, acc 0.8160362364907819,recall 0.7011416613689341,precision 0.7592106584061151,specificity 0.8787060047390626,[tp,tn,fp,fn]: [52939, 121634, 16790, 22565]
VAL, loss 0.35329894467961004, acc 0.85047676811868,f1 0.6650033415014479, recall 0.5888433012466466,precision 0.76379080953843,specificity 0.9386374210701229,[tp,tn,fp,fn]: [14926, 70609, 4616, 10422]

TRAIN, epoch 23, loss 0.42178456249057317, acc 0.8158212108746868,recall 0.7026515151515151,precision 0.7578675199634302,specificity 0.8775501358145986,[tp,tn,fp,fn]: [53053, 121474, 16950, 22451]
VAL, loss 0.3486413764871294, acc 0.8524852594632755,f1 0.6751477994306984, recall 0.6082136657724475,precision 0.7586359610274579,specificity 0.9347956131605184,[tp,tn,fp,fn]: [15417, 70320, 4905, 9931]

TRAIN, epoch 24, loss 0.4217401145696239, acc 0.8162980068060282,recall 0.7029826234371689,precision 0.7587882946634072,specificity 0.878106397734497,[tp,tn,fp,fn]: [53078, 121551, 16873, 22426]
VAL, loss 0.3490329074003743, acc 0.8521372535372317,f1 0.6787080047531598, recall 0.619654410604387,precision 0.7502029899221474,specificity 0.9304752409438352,[tp,tn,fp,fn]: [15707, 69995, 5230, 9641]

TRAIN, epoch 25, loss 0.42131594437511666, acc 0.8164195430238211,recall 0.7036845730027548,precision 0.7586782996101726,specificity 0.8779113448534936,[tp,tn,fp,fn]: [53131, 121524, 16900, 22373]
VAL, loss 0.3480297075935584, acc 0.8536187644795323,f1 0.690310909167403, recall 0.6473094524222819,precision 0.7394321766561515,specificity 0.9231372549019607,[tp,tn,fp,fn]: [16408, 69443, 5782, 8940]

TRAIN, epoch 26, loss 0.4208238628191374, acc 0.8161016790695935,recall 0.7032475100656919,precision 0.7581854268701897,specificity 0.8776584985262671,[tp,tn,fp,fn]: [53098, 121489, 16935, 22406]
VAL, loss 0.3501976203046461, acc 0.8512423811559763,f1 0.6669486431735714, recall 0.5909736468360423,precision 0.7653400091963419,specificity 0.9389431704885344,[tp,tn,fp,fn]: [14980, 70632, 4593, 10368]

TRAIN, epoch 27, loss 0.42133797781794025, acc 0.8159193747429041,recall 0.7030356007628735,precision 0.7578812107367219,specificity 0.8774923423683755,[tp,tn,fp,fn]: [53082, 121466, 16958, 22422]
VAL, loss 0.3488214652165143, acc 0.8530321259184871,f1 0.6828043520247216, recall 0.6276234811424964,precision 0.7486235941838031,specificity 0.9289863742107012,[tp,tn,fp,fn]: [15909, 69883, 5342, 9439]

TRAIN, epoch 28, loss 0.4208786892492392, acc 0.8160689577801877,recall 0.7024263615172706,precision 0.7585674237656617,specificity 0.8780558284690516,[tp,tn,fp,fn]: [53036, 121544, 16880, 22468]
VAL, loss 0.35083662382375663, acc 0.8512026090501427,f1 0.6677028977461973, recall 0.5931434432696859,precision 0.7637019352872454,specificity 0.9381588567630442,[tp,tn,fp,fn]: [15035, 70573, 4652, 10313]

TRAIN, epoch 29, loss 0.4212827134193013, acc 0.8159707939119704,recall 0.7019628099173554,precision 0.7585984799690841,specificity 0.8781569669999422,[tp,tn,fp,fn]: [53001, 121558, 16866, 22503]
VAL, loss 0.34877179358343996, acc 0.8535591063207819,f1 0.6844225412470538, recall 0.6300694334858766,precision 0.7490385517306068,specificity 0.9288667331339315,[tp,tn,fp,fn]: [15971, 69874, 5351, 9377]

TRAIN, epoch 30, loss 0.4212315038115712, acc 0.8166205452301709,recall 0.7018436109345201,precision 0.7601778797876919,specificity 0.8792261457550714,[tp,tn,fp,fn]: [52992, 121706, 16718, 22512]
VAL, loss 0.3484543699802243, acc 0.853131556183071,f1 0.6832772262366791, recall 0.62857030140445,precision 0.7484146742449153,specificity 0.9288002658690595,[tp,tn,fp,fn]: [15933, 69869, 5356, 9415]

TRAIN, epoch 31, loss 0.4206459851832625, acc 0.8161811450581504,recall 0.7021614748887476,precision 0.758976120941419,specificity 0.8783736924232792,[tp,tn,fp,fn]: [53016, 121588, 16836, 22488]
VAL, loss 0.34950180201052755, acc 0.8529724677597367,f1 0.6808675946908385, recall 0.6222976171690074,precision 0.7516081383713727,specificity 0.9307012296444002,[tp,tn,fp,fn]: [15774, 70012, 5213, 9574]

TRAIN, epoch 32, loss 0.42046277850408265, acc 0.8164896600725478,recall 0.702995867768595,precision 0.7592258839684174,specificity 0.8783953649656129,[tp,tn,fp,fn]: [53079, 121591, 16833, 22425]
VAL, loss 0.3500459470042924, acc 0.8524952024897339,f1 0.680176781287054, recall 0.6223370680132555,precision 0.7498692779388696,specificity 0.9300498504486541,[tp,tn,fp,fn]: [15775, 69963, 5262, 9573]

TRAIN, epoch 33, loss 0.4202509132949413, acc 0.8169524325941439,recall 0.7032342657342657,precision 0.7601683631834386,specificity 0.8789805236086228,[tp,tn,fp,fn]: [53097, 121672, 16752, 22407]
VAL, loss 0.3488222673200055, acc 0.8523361140663995,f1 0.6761171570017229, recall 0.6115275366892852,precision 0.7559619604974397,specificity 0.9334795613160518,[tp,tn,fp,fn]: [15501, 70221, 5004, 9847]

TRAIN, epoch 34, loss 0.42025186084741645, acc 0.8164055196140758,recall 0.7027839584657767,precision 0.7591490457523821,specificity 0.8783809166040571,[tp,tn,fp,fn]: [53063, 121589, 16835, 22441]
VAL, loss 0.34915548672784646, acc 0.8537679098764082,f1 0.6899416018383825, recall 0.6455341644311188,precision 0.740910119990944,specificity 0.9239348620804254,[tp,tn,fp,fn]: [16363, 69503, 5722, 8985]

TRAIN, epoch 35, loss 0.4202438481964235, acc 0.8172702965483715,recall 0.7028501801229073,precision 0.7611261707040718,specificity 0.8796812691440791,[tp,tn,fp,fn]: [53068, 121769, 16655, 22436]
VAL, loss 0.3481816003302641, acc 0.8535988784266155,f1 0.6864164927375731, recall 0.6357503550575982,precision 0.7458576321392206,specificity 0.9270056497175141,[tp,tn,fp,fn]: [16115, 69734, 5491, 9233]

TRAIN, epoch 36, loss 0.4201155570701201, acc 0.8164616132530571,recall 0.7019892985802076,precision 0.7597253676575982,specificity 0.8789010576200659,[tp,tn,fp,fn]: [53003, 121661, 16763, 22501]
VAL, loss 0.34866857433173476, acc 0.8526344048601513,f1 0.6753411754397494, recall 0.6081347640839514,precision 0.7592474018617938,specificity 0.9350216018610834,[tp,tn,fp,fn]: [15415, 70337, 4888, 9933]

TRAIN, epoch 37, loss 0.42011983056667745, acc 0.8170739688119367,recall 0.702810447128629,precision 0.7606903768689345,specificity 0.879399526093741,[tp,tn,fp,fn]: [53065, 121730, 16694, 22439]
VAL, loss 0.3486978002155185, acc 0.8529824107861951,f1 0.6827038626609443, recall 0.6275445794540003,precision 0.7484942593638246,specificity 0.928946493851778,[tp,tn,fp,fn]: [15907, 69880, 5345, 9441]

TRAIN, epoch 38, loss 0.42004241788134533, acc 0.8166532665195767,recall 0.7015257469802925,precision 0.7604335654296174,specificity 0.8794500953591863,[tp,tn,fp,fn]: [52968, 121737, 16687, 22536]
VAL, loss 0.34786338336448624, acc 0.8527736072305688,f1 0.6786047622148423, recall 0.6166955972857819,precision 0.7543309366404478,specificity 0.9323230309072782,[tp,tn,fp,fn]: [15632, 70134, 5091, 9716]

TRAIN, epoch 39, loss 0.41995608765708675, acc 0.8168168729666055,recall 0.7030091121000211,precision 0.7599793826241338,specificity 0.878893833439288,[tp,tn,fp,fn]: [53080, 121660, 16764, 22424]
VAL, loss 0.3476431830108741, acc 0.8528630944686943,f1 0.6815579944049924, recall 0.6247435695123875,precision 0.7497396079916675,specificity 0.9297308075772682,[tp,tn,fp,fn]: [15836, 69939, 5286, 9512]

TRAIN, epoch 40, loss 0.42049265659553997, acc 0.8169337347144834,recall 0.702280673871583,precision 0.7606621813539142,specificity 0.8794717679015199,[tp,tn,fp,fn]: [53025, 121740, 16684, 22479]
VAL, loss 0.34748906072335417, acc 0.8532309864476549,f1 0.6813599568267673, recall 0.6226132239229919,precision 0.7523478095056491,specificity 0.9309405117979395,[tp,tn,fp,fn]: [15782, 70030, 5195, 9566]

TRAIN, epoch 41, loss 0.41981814577626664, acc 0.8163307280954339,recall 0.7023468955287137,precision 0.7592200206161952,specificity 0.8785037276772814,[tp,tn,fp,fn]: [53030, 121606, 16818, 22474]
VAL, loss 0.34824568378711435, acc 0.8539468843526593,f1 0.6918025219781373, recall 0.6503866182736311,precision 0.7388517904360686,specificity 0.9225390495181123,[tp,tn,fp,fn]: [16486, 69398, 5827, 8862]

TRAIN, epoch 42, loss 0.4200543300627432, acc 0.8170225496428705,recall 0.7027707141343505,precision 0.7605928559142251,specificity 0.8793417326475178,[tp,tn,fp,fn]: [53062, 121722, 16702, 22442]
VAL, loss 0.3479248769995433, acc 0.8532111003947381,f1 0.6825502634125363, recall 0.62612434906107,precision 0.7501536134612657,specificity 0.9297308075772682,[tp,tn,fp,fn]: [15871, 69939, 5286, 9477]

TRAIN, epoch 43, loss 0.419715364442696, acc 0.8168449197860963,recall 0.7022012078830261,precision 0.7604997418096276,specificity 0.8793778535514073,[tp,tn,fp,fn]: [53019, 121727, 16697, 22485]
VAL, loss 0.3485827453585371, acc 0.8526841199924433,f1 0.679944698868055, recall 0.620877386776077,precision 0.7514323911382735,specificity 0.930794283815221,[tp,tn,fp,fn]: [15738, 70019, 5206, 9610]

TRAIN, epoch 44, loss 0.4195719958131821, acc 0.8171487603305785,recall 0.70201578724306,precision 0.761314508136679,specificity 0.8799485638328614,[tp,tn,fp,fn]: [53005, 121806, 16618, 22499]
VAL, loss 0.34746201998567106, acc 0.8536983086911994,f1 0.6866428145497913, recall 0.6359870601230866,precision 0.7460662717512032,specificity 0.9270588235294117,[tp,tn,fp,fn]: [16121, 69738, 5487, 9227]

TRAIN, epoch 45, loss 0.4195594005566707, acc 0.8168869900153323,recall 0.7022144522144522,precision 0.7605904546041401,specificity 0.8794356469976304,[tp,tn,fp,fn]: [53020, 121735, 16689, 22484]
VAL, loss 0.3466323273293814, acc 0.8541954600141191,f1 0.6910370401584426, recall 0.6469543948240493,precision 0.7415664285068283,specificity 0.9240279162512463,[tp,tn,fp,fn]: [16399, 69510, 5715, 8949]

TRAIN, epoch 46, loss 0.41949515016771444, acc 0.8170973411615123,recall 0.7015389913117186,precision 0.7614645927374141,specificity 0.8801291683523088,[tp,tn,fp,fn]: [52969, 121831, 16593, 22535]
VAL, loss 0.34791197567717685, acc 0.8541059727759935,f1 0.6917760739418128, recall 0.6495976013886697,precision 0.7398121939165206,specificity 0.9230176138251911,[tp,tn,fp,fn]: [16466, 69434, 5791, 8882]

TRAIN, epoch 47, loss 0.4196291205728425, acc 0.8171394113907483,recall 0.7018303666030938,precision 0.7613977613977614,specificity 0.8800352540021962,[tp,tn,fp,fn]: [52991, 121818, 16606, 22513]
VAL, loss 0.34840664547352534, acc 0.853280701579947,f1 0.6812132734185966, recall 0.6219820104150229,precision 0.7529130850047755,specificity 0.9312196743104021,[tp,tn,fp,fn]: [15766, 70051, 5174, 9582]

TRAIN, epoch 48, loss 0.41939661003305695, acc 0.8169056878949927,recall 0.7015389913117186,precision 0.7610160481588437,specificity 0.879832976940415,[tp,tn,fp,fn]: [52969, 121790, 16634, 22535]
VAL, loss 0.34957441715653337, acc 0.8543346623845366,f1 0.6975639966969447, recall 0.6665220135710904,precision 0.731638662740343,specificity 0.9176204719175806,[tp,tn,fp,fn]: [16895, 69028, 6197, 8453]

TRAIN, epoch 49, loss 0.41981067785992593, acc 0.8169477581242287,recall 0.7014197923288832,precision 0.7611820167873979,specificity 0.8799630121944172,[tp,tn,fp,fn]: [52960, 121808, 16616, 22544]
VAL, loss 0.34901509129688324, acc 0.8523858291986915,f1 0.6760778495374411, recall 0.6112119299353006,precision 0.7563464167154853,specificity 0.9336523762047192,[tp,tn,fp,fn]: [15493, 70234, 4991, 9855]



 * BEST_ACC: 0.8543346623845366
 * TIME: Time 4816.620 (4816.620)

pooling_ratio 0.2, dropout0.2, hidden_dim 64, outdim 128
epochs 100, lr 1e-05, weight_decay 0.0001
TRAIN, epoch 0, loss 0.576017565854463, acc 0.7356961220597584,recall 0.43024210637847,precision 0.7060728568944531,specificity 0.9023074033404612,[tp,tn,fp,fn]: [32485, 124901, 13523, 43019]
VAL, loss 0.4345507266540022, acc 0.8166207630278505,f1 0.4972056377961342, recall 0.3597522486981221,precision 0.8046413129797936,specificity 0.970568295114656,[tp,tn,fp,fn]: [9119, 73011, 2214, 16229]

TRAIN, epoch 1, loss 0.5061395331631557, acc 0.7719232639018735,recall 0.5605001059546514,precision 0.7305620770611794,specificity 0.8872449864185401,[tp,tn,fp,fn]: [42320, 122816, 15608, 33184]
VAL, loss 0.4180453190817052, acc 0.8233621349666411,f1 0.5306100879858378, recall 0.39612592709483985,precision 0.8033442675414033,specificity 0.9673246925889,[tp,tn,fp,fn]: [10041, 72767, 2458, 15307]

TRAIN, epoch 2, loss 0.48781548002521286, acc 0.7814358101791257,recall 0.5990146217418945,precision 0.7329238846845679,specificity 0.8809382765994336,[tp,tn,fp,fn]: [45228, 121943, 16481, 30276]
VAL, loss 0.3966735189395611, acc 0.830560886122518,f1 0.5685932001721475, recall 0.4430329809057914,precision 0.7934713488306366,specificity 0.9611432369557993,[tp,tn,fp,fn]: [11230, 72302, 2923, 14118]

TRAIN, epoch 3, loss 0.47616113802399795, acc 0.7873817359111477,recall 0.6149475524475524,precision 0.7388412392788377,specificity 0.8814367450731088,[tp,tn,fp,fn]: [46431, 122012, 16412, 29073]
VAL, loss 0.38710370264485816, acc 0.8334244777425353,f1 0.5849005178522758, recall 0.4656383146599337,precision 0.7862900539604291,specificity 0.9573546028580924,[tp,tn,fp,fn]: [11803, 72017, 3208, 13545]

TRAIN, epoch 4, loss 0.4699259064775376, acc 0.7901116263415728,recall 0.625529773257046,precision 0.7396213414347683,specificity 0.8798835462058603,[tp,tn,fp,fn]: [47230, 121797, 16627, 28274]
VAL, loss 0.37738083787566545, acc 0.8363874996271365,f1 0.5967801220319047, recall 0.4803929304087107,precision 0.787594592846517,specificity 0.9563443004320372,[tp,tn,fp,fn]: [12177, 71941, 3284, 13171]

TRAIN, epoch 5, loss 0.4642524491327024, acc 0.7929677274597061,recall 0.6306553295189659,precision 0.7437831927522649,specificity 0.8815017627001098,[tp,tn,fp,fn]: [47617, 122021, 16403, 27887]
VAL, loss 0.3775206863171644, acc 0.837511061616935,f1 0.5989299563147302, recall 0.4813792015149124,precision 0.7924405766982725,specificity 0.9575141242937854,[tp,tn,fp,fn]: [12202, 72029, 3196, 13146]

TRAIN, epoch 6, loss 0.45978723080507466, acc 0.7957537115291126,recall 0.6363901250264886,precision 0.7473946181365687,specificity 0.8826793041669074,[tp,tn,fp,fn]: [48050, 122184, 16240, 27454]
VAL, loss 0.371357103688758, acc 0.8410308929832062,f1 0.6194420641721413, recall 0.5133343853558466,precision 0.7808449351896304,specificity 0.9514523097374543,[tp,tn,fp,fn]: [13012, 71573, 3652, 12336]

TRAIN, epoch 7, loss 0.45682207835085714, acc 0.7971700759133914,recall 0.6429328247510065,precision 0.7471181223547518,specificity 0.8812994856383286,[tp,tn,fp,fn]: [48544, 121993, 16431, 26960]
VAL, loss 0.36783038409378266, acc 0.8420152526025871,f1 0.6231172466140088, recall 0.5181868391983588,precision 0.7813336505859259,specificity 0.9511332668660685,[tp,tn,fp,fn]: [13135, 71549, 3676, 12213]

TRAIN, epoch 8, loss 0.4527976139624845, acc 0.7993203320743427,recall 0.6500317863954228,precision 0.7483190266363761,specificity 0.8807504478992082,[tp,tn,fp,fn]: [49080, 121917, 16507, 26424]
VAL, loss 0.36910811239177715, acc 0.8408022033746632,f1 0.6174467780087449, recall 0.5097443585292726,precision 0.7828536807028174,specificity 0.9523562645397142,[tp,tn,fp,fn]: [12921, 71641, 3584, 12427]

TRAIN, epoch 9, loss 0.45067476146771535, acc 0.7997223364870424,recall 0.650588048315321,precision 0.7489822367919494,specificity 0.8810683118534358,[tp,tn,fp,fn]: [49122, 121961, 16463, 26382]
VAL, loss 0.3640641029550229, acc 0.8427908086663418,f1 0.625784005112305, recall 0.5215401609594446,precision 0.7821096846713601,specificity 0.9510402126952476,[tp,tn,fp,fn]: [13220, 71542, 3683, 12128]

TRAIN, epoch 10, loss 0.44741034111553657, acc 0.8014098201263977,recall 0.655369251960161,precision 0.7503563521669244,specificity 0.8810683118534358,[tp,tn,fp,fn]: [49483, 121961, 16463, 26021]
VAL, loss 0.3638902660131285, acc 0.8438149403915564,f1 0.6294933484290971, recall 0.5264320656462048,precision 0.7827311121539183,specificity 0.950761050182785,[tp,tn,fp,fn]: [13344, 71521, 3704, 12004]

TRAIN, epoch 11, loss 0.4456875905807469, acc 0.8029523951983845,recall 0.6602564102564102,precision 0.7513036139494228,specificity 0.8807865688030977,[tp,tn,fp,fn]: [49852, 121922, 16502, 25652]
VAL, loss 0.3607214992396263, acc 0.8457438875244847,f1 0.6409627401064568, recall 0.5463152911472305,precision 0.7752771246221027,specificity 0.9466400797607178,[tp,tn,fp,fn]: [13848, 71211, 4014, 11500]

TRAIN, epoch 12, loss 0.44460387977022564, acc 0.8031767697543098,recall 0.660587518542064,precision 0.7516577249984929,specificity 0.8809527249609894,[tp,tn,fp,fn]: [49877, 121945, 16479, 25627]
VAL, loss 0.3582403940324289, acc 0.8466387599057401,f1 0.6437217037789892, recall 0.5497080637525643,precision 0.77652697280428,specificity 0.9466932535726155,[tp,tn,fp,fn]: [13934, 71215, 4010, 11414]

TRAIN, epoch 13, loss 0.4420604053828324, acc 0.8054158408436484,recall 0.6659647171010807,precision 0.7539924125417985,specificity 0.8814800901577761,[tp,tn,fp,fn]: [50283, 122018, 16406, 25221]
VAL, loss 0.3601184647045492, acc 0.8450478756723971,f1 0.6353766963032288, recall 0.5356635632002524,precision 0.780703771849126,specificity 0.9492987703555998,[tp,tn,fp,fn]: [13578, 71411, 3814, 11770]

TRAIN, epoch 14, loss 0.44037999569542774, acc 0.8055981451703377,recall 0.6675937698664971,precision 0.7534979669935422,specificity 0.8808732589724325,[tp,tn,fp,fn]: [50406, 121934, 16490, 25098]
VAL, loss 0.35622613662600017, acc 0.8462211527944876,f1 0.6412433310136859, recall 0.5452895691967808,precision 0.7781781330931201,specificity 0.9476237952808242,[tp,tn,fp,fn]: [13822, 71285, 3940, 11526]

TRAIN, epoch 15, loss 0.43970977170301273, acc 0.8063974795258217,recall 0.669964505191778,precision 0.7540658587123414,specificity 0.8808154655262094,[tp,tn,fp,fn]: [50585, 121926, 16498, 24919]
VAL, loss 0.3583041387471837, acc 0.8460222922653197,f1 0.637058216930721, recall 0.5361764241754774,precision 0.7846997690531178,specificity 0.9504287138584248,[tp,tn,fp,fn]: [13591, 71496, 3729, 11757]

TRAIN, epoch 16, loss 0.43823408460185537, acc 0.8069490669758049,recall 0.6710637847001484,precision 0.7547630751813618,specificity 0.8810683118534358,[tp,tn,fp,fn]: [50668, 121961, 16463, 24836]
VAL, loss 0.3561282359420253, acc 0.8479611824247064,f1 0.6518046225663213, recall 0.5646204828783336,precision 0.7708299671460117,specificity 0.943436357593885,[tp,tn,fp,fn]: [14312, 70970, 4255, 11036]

TRAIN, epoch 17, loss 0.43658286243034083, acc 0.8082205227927153,recall 0.6741232252595889,precision 0.7560642295866075,specificity 0.8813645032653297,[tp,tn,fp,fn]: [50899, 122002, 16422, 24605]
VAL, loss 0.35692601153712067, acc 0.8470563670169926,f1 0.6423622413392235, recall 0.5449739624427963,precision 0.7821311289774657,specificity 0.9488467929544699,[tp,tn,fp,fn]: [13814, 71377, 3848, 11534]

TRAIN, epoch 18, loss 0.43604854911344, acc 0.8091787891253132,recall 0.6757125450307269,precision 0.7574529366351921,specificity 0.8819785586314512,[tp,tn,fp,fn]: [51019, 122087, 16337, 24485]
VAL, loss 0.3576569309504234, acc 0.8465194435882394,f1 0.6392783697887456, recall 0.5396086476250592,precision 0.7841091492776886,specificity 0.9499368560983715,[tp,tn,fp,fn]: [13678, 71459, 3766, 11670]

TRAIN, epoch 19, loss 0.4346238685560977, acc 0.809001159268539,recall 0.6766528925619835,precision 0.7564854299928927,specificity 0.8811911229266601,[tp,tn,fp,fn]: [51090, 121978, 16446, 24414]
VAL, loss 0.3570496212913794, acc 0.8458333747626102,f1 0.6341520964583186, recall 0.5301404450055232,precision 0.7889391181823519,specificity 0.9522100365569957,[tp,tn,fp,fn]: [13438, 71630, 3595, 11910]

TRAIN, epoch 20, loss 0.4341946549919512, acc 0.8093283721625968,recall 0.6742821572367027,precision 0.7586427847648567,specificity 0.8829899439403571,[tp,tn,fp,fn]: [50911, 122227, 16197, 24593]
VAL, loss 0.35263100739795494, acc 0.8491543455997136,f1 0.6535431272694056, recall 0.5645021303455894,precision 0.7759340599750556,specificity 0.9450714523097374,[tp,tn,fp,fn]: [14309, 71093, 4132, 11039]

TRAIN, epoch 21, loss 0.433001327155117, acc 0.8098051680939381,recall 0.676176096630642,precision 0.7586934553884562,specificity 0.8826937525284633,[tp,tn,fp,fn]: [51054, 122186, 16238, 24450]
VAL, loss 0.3551250376174284, acc 0.847951239398248,f1 0.6471945367294204, recall 0.5533375414233864,precision 0.7793954212047122,specificity 0.9472249916915919,[tp,tn,fp,fn]: [14026, 71255, 3970, 11322]

TRAIN, epoch 22, loss 0.4320036009862907, acc 0.8106091769193373,recall 0.6804010383555839,precision 0.7581835355234806,specificity 0.881631797954112,[tp,tn,fp,fn]: [51373, 122039, 16385, 24131]
VAL, loss 0.354222558559975, acc 0.8483390174301254,f1 0.6504571808327795, recall 0.5598863815685655,precision 0.7759855650937723,specificity 0.9455367231638419,[tp,tn,fp,fn]: [14192, 71128, 4097, 11156]

TRAIN, epoch 23, loss 0.4303286470441329, acc 0.8112589282375379,recall 0.6799109980928163,precision 0.7600266489007328,specificity 0.8829032537710224,[tp,tn,fp,fn]: [51336, 122215, 16209, 24168]
VAL, loss 0.3537160779014371, acc 0.8479214103188728,f1 0.6455306032584764, recall 0.5494319078428278,precision 0.7823717768664682,specificity 0.9485011631771353,[tp,tn,fp,fn]: [13927, 71351, 3874, 11421]

TRAIN, epoch 24, loss 0.4305933075025887, acc 0.8109363898133951,recall 0.6801626403899131,precision 0.7591054218648376,specificity 0.8822675258625672,[tp,tn,fp,fn]: [51355, 122127, 16297, 24149]
VAL, loss 0.35215513430986284, acc 0.8495321806051326,f1 0.654962493444903, recall 0.566632475934985,precision 0.7759170223110583,specificity 0.944858757062147,[tp,tn,fp,fn]: [14363, 71077, 4148, 10985]

TRAIN, epoch 25, loss 0.4293960936751729, acc 0.8115347219625294,recall 0.6818579148124603,precision 0.7595603422838595,specificity 0.8822675258625672,[tp,tn,fp,fn]: [51483, 122127, 16297, 24021]
VAL, loss 0.35176859188880416, acc 0.8496017817903413,f1 0.6537246463074036, recall 0.5632791541738993,precision 0.7787716810297808,specificity 0.9460817547357926,[tp,tn,fp,fn]: [14278, 71169, 4056, 11070]

TRAIN, epoch 26, loss 0.4283001402097019, acc 0.8120068434239557,recall 0.683420745920746,precision 0.7597879702569388,specificity 0.8821447147893429,[tp,tn,fp,fn]: [51601, 122110, 16314, 23903]
VAL, loss 0.35322865430162065, acc 0.8505662553568055,f1 0.6604920143673617, recall 0.5767318920624901,precision 0.7727152597917437,specificity 0.9428381522100365,[tp,tn,fp,fn]: [14619, 70925, 4300, 10729]

TRAIN, epoch 27, loss 0.4283089157392973, acc 0.8119227029654837,recall 0.6840167408349227,precision 0.7592431971539039,specificity 0.8816895914003352,[tp,tn,fp,fn]: [51646, 122047, 16377, 23858]
VAL, loss 0.3521510553321552, acc 0.850248078510137,f1 0.6567293447293447, recall 0.5683683130819,precision 0.7776218491930695,specificity 0.9452309737454304,[tp,tn,fp,fn]: [14407, 71105, 4120, 10941]

TRAIN, epoch 28, loss 0.42687429047875514, acc 0.8131661119629034,recall 0.6864139648230557,precision 0.7608303116604765,specificity 0.8823036467664567,[tp,tn,fp,fn]: [51827, 122132, 16292, 23677]
VAL, loss 0.3515376387060079, acc 0.8503574518011793,f1 0.6578145605020235, recall 0.5706959128925359,precision 0.776322850703016,specificity 0.9445928880026587,[tp,tn,fp,fn]: [14466, 71057, 4168, 10882]

TRAIN, epoch 29, loss 0.42703152779580444, acc 0.8132969971205265,recall 0.6862285441830897,precision 0.7612506060561539,specificity 0.8826070623591284,[tp,tn,fp,fn]: [51813, 122174, 16250, 23691]
VAL, loss 0.34970986042782704, acc 0.8517892476111879,f1 0.6630498666304987, recall 0.5785860817421493,precision 0.7763896241397565,specificity 0.9438484546360917,[tp,tn,fp,fn]: [14666, 71001, 4224, 10682]

TRAIN, epoch 30, loss 0.4263311318836128, acc 0.8134325567480648,recall 0.6856325492689129,precision 0.7619215824796891,specificity 0.883141651736693,[tp,tn,fp,fn]: [51768, 122248, 16176, 23736]
VAL, loss 0.3522836420986823, acc 0.8498603004782596,f1 0.6551881622214103, recall 0.5659618115827679,precision 0.7778139232270657,specificity 0.9455234297108674,[tp,tn,fp,fn]: [14346, 71127, 4098, 11002]

TRAIN, epoch 31, loss 0.4261354333561069, acc 0.813189484312479,recall 0.6857517482517482,precision 0.7612697385832329,specificity 0.8827009767092412,[tp,tn,fp,fn]: [51777, 122187, 16237, 23727]
VAL, loss 0.3509696657956965, acc 0.8499299016634684,f1 0.6560627122120183, recall 0.5678949029509232,precision 0.7766387914755867,specificity 0.9449651046859422,[tp,tn,fp,fn]: [14395, 71085, 4140, 10953]

TRAIN, epoch 32, loss 0.42478671218929775, acc 0.8135307206162821,recall 0.6846789574062301,precision 0.762714114991369,specificity 0.8838135005490377,[tp,tn,fp,fn]: [51696, 122341, 16083, 23808]
VAL, loss 0.3523929090776225, acc 0.8490847444145049,f1 0.6490148922393858, recall 0.5536136973331229,precision 0.7841417076441662,specificity 0.9486473911598537,[tp,tn,fp,fn]: [14033, 71362, 3863, 11315]

TRAIN, epoch 33, loss 0.42402913993594576, acc 0.8143487528514266,recall 0.6866258741258742,precision 0.7635423723821025,specificity 0.884015777610819,[tp,tn,fp,fn]: [51843, 122369, 16055, 23661]
VAL, loss 0.35193826071912454, acc 0.8503773378540961,f1 0.6570803518526959, recall 0.5687628215243806,precision 0.7778677026006259,specificity 0.9452708541043536,[tp,tn,fp,fn]: [14417, 71108, 4117, 10931]

TRAIN, epoch 34, loss 0.4243114774868459, acc 0.8142038442840582,recall 0.6869569824115279,precision 0.7630003383397814,specificity 0.8836112234872565,[tp,tn,fp,fn]: [51868, 122313, 16111, 23636]
VAL, loss 0.3533118427582888, acc 0.849721098107842,f1 0.6555763183081901, recall 0.5674609436641944,precision 0.7760871911082335,specificity 0.944832170156198,[tp,tn,fp,fn]: [14384, 71075, 4150, 10964]

TRAIN, epoch 35, loss 0.4231798936225309, acc 0.8145964997569276,recall 0.6881092392456029,precision 0.7632696234703021,specificity 0.8835895509449229,[tp,tn,fp,fn]: [51955, 122310, 16114, 23549]
VAL, loss 0.35143973450883753, acc 0.8512622672088931,f1 0.6630779972521904, recall 0.5807164273315449,precision 0.772662852343709,specificity 0.9424260551678298,[tp,tn,fp,fn]: [14720, 70894, 4331, 10628]

TRAIN, epoch 36, loss 0.42245543375318756, acc 0.8154145319920721,recall 0.689711803348167,precision 0.7642949395326993,specificity 0.8839796567069295,[tp,tn,fp,fn]: [52076, 122364, 16060, 23428]
VAL, loss 0.34850344453060134, acc 0.8517892476111879,f1 0.6651390573752077, recall 0.5840302982483825,precision 0.7724094751121778,specificity 0.9420139581256232,[tp,tn,fp,fn]: [14804, 70863, 4362, 10544]

TRAIN, epoch 37, loss 0.4215886732955186, acc 0.8156108597285068,recall 0.6893012290739563,precision 0.7650076434619003,specificity 0.8845070219037161,[tp,tn,fp,fn]: [52045, 122437, 15987, 23459]
VAL, loss 0.3500996360480895, acc 0.85103357760035,f1 0.6589729582081398, recall 0.5710509704907685,precision 0.7788958243650452,specificity 0.9453772017281489,[tp,tn,fp,fn]: [14475, 71116, 4109, 10873]

TRAIN, epoch 38, loss 0.4213450769872406, acc 0.8161904939979806,recall 0.6901356219538037,precision 0.7659111620660258,specificity 0.884947696931168,[tp,tn,fp,fn]: [52108, 122498, 15926, 23396]
VAL, loss 0.3497672459586609, acc 0.8512821532618098,f1 0.661077247286488, recall 0.5754694650465519,precision 0.7766065058829793,specificity 0.9442206713193753,[tp,tn,fp,fn]: [14587, 71029, 4196, 10761]

TRAIN, epoch 39, loss 0.4221176689056098, acc 0.8148395721925134,recall 0.6873940453485908,precision 0.7642727768042528,specificity 0.8843553141073802,[tp,tn,fp,fn]: [51901, 122416, 16008, 23603]
VAL, loss 0.34937067505019226, acc 0.8526344048601513,f1 0.6707103023839677, recall 0.595471043080322,precision 0.7677127307868369,specificity 0.939288800265869,[tp,tn,fp,fn]: [15094, 70658, 4567, 10254]

TRAIN, epoch 40, loss 0.42096408166938337, acc 0.8154051830522419,recall 0.6893144734053825,precision 0.764505420253239,specificity 0.8841819337687107,[tp,tn,fp,fn]: [52046, 122392, 16032, 23458]
VAL, loss 0.34821665880375857, acc 0.8526940630189017,f1 0.6690938330615801, recall 0.5908947451475461,precision 0.7711476085053802,specificity 0.9409106015287471,[tp,tn,fp,fn]: [14978, 70780, 4445, 10370]

TRAIN, epoch 41, loss 0.4205975285027914, acc 0.8165130324221234,recall 0.6912349014621741,precision 0.7660389543673217,specificity 0.8848465584002774,[tp,tn,fp,fn]: [52191, 122484, 15940, 23313]
VAL, loss 0.3512472271574476, acc 0.8514014695793105,f1 0.6623590809479701, recall 0.5783099258324128,precision 0.7749933914882369,specificity 0.9434230641409106,[tp,tn,fp,fn]: [14659, 70969, 4256, 10689]

TRAIN, epoch 42, loss 0.4196274171930829, acc 0.8167140346284731,recall 0.6929699088789998,precision 0.765501097293343,specificity 0.8842108304918223,[tp,tn,fp,fn]: [52322, 122396, 16028, 23182]
VAL, loss 0.34950196286418667, acc 0.852753721177652,f1 0.6669814927252693, recall 0.5850560201988323,precision 0.77558705088646,specificity 0.9429577932868063,[tp,tn,fp,fn]: [14830, 70934, 4291, 10518]

TRAIN, epoch 43, loss 0.41897499258728366, acc 0.8168589431958416,recall 0.6935923924560288,precision 0.7654831684036659,specificity 0.8840952435993759,[tp,tn,fp,fn]: [52369, 122380, 16044, 23135]
VAL, loss 0.3491837660303039, acc 0.8540363715907848,f1 0.6733567709492235, recall 0.5969307243175004,precision 0.7722261916913341,specificity 0.9406713193752078,[tp,tn,fp,fn]: [15131, 70762, 4463, 10217]

TRAIN, epoch 44, loss 0.4193198938166648, acc 0.8168963389551624,recall 0.6923076923076923,precision 0.7663280116110305,specificity 0.8848537825810553,[tp,tn,fp,fn]: [52272, 122485, 15939, 23232]
VAL, loss 0.35035267527220676, acc 0.8535292772414067,f1 0.6701301027834382, recall 0.5903029824838252,precision 0.7749236107514631,specificity 0.9422266533732137,[tp,tn,fp,fn]: [14963, 70879, 4346, 10385]

TRAIN, epoch 45, loss 0.41849458227205383, acc 0.8170412475225309,recall 0.6922017376562831,precision 0.7667390411360836,specificity 0.8851355256313934,[tp,tn,fp,fn]: [52264, 122524, 15900, 23240]
VAL, loss 0.3488501372922409, acc 0.8529724677597367,f1 0.6685792410964431, recall 0.5884093419599179,precision 0.7740412060823084,specificity 0.9421203057494184,[tp,tn,fp,fn]: [14915, 70871, 4354, 10433]

TRAIN, epoch 46, loss 0.41831519787863713, acc 0.8177424180097976,recall 0.6934069718160627,precision 0.7677136488943633,specificity 0.8855617522972895,[tp,tn,fp,fn]: [52355, 122583, 15841, 23149]
VAL, loss 0.3491131627848609, acc 0.8527934932834856,f1 0.6668316943087966, recall 0.5845037083793593,precision 0.7761538058567762,specificity 0.9431970754403456,[tp,tn,fp,fn]: [14816, 70952, 4273, 10532]

TRAIN, epoch 47, loss 0.4170674648730615, acc 0.8177657903593732,recall 0.6932877728332274,precision 0.7678406407228668,specificity 0.8856628908281801,[tp,tn,fp,fn]: [52346, 122597, 15827, 23158]
VAL, loss 0.3467693154305534, acc 0.8536983086911994,f1 0.6736169646422075, recall 0.599021619062648,precision 0.769433465085639,specificity 0.939514788966434,[tp,tn,fp,fn]: [15184, 70675, 4550, 10164]

TRAIN, epoch 48, loss 0.41759738082781606, acc 0.8176395796716652,recall 0.6931288408561136,precision 0.767630837831495,specificity 0.8855545281165116,[tp,tn,fp,fn]: [52334, 122582, 15842, 23170]
VAL, loss 0.3490659082334618, acc 0.853409960923906,f1 0.6707314349525405, recall 0.5923938772289727,precision 0.7729448705409996,specificity 0.9413625789298771,[tp,tn,fp,fn]: [15016, 70814, 4411, 10332]

TRAIN, epoch 49, loss 0.4171026799195207, acc 0.8182238884110542,recall 0.693698347107438,precision 0.7687012929832543,specificity 0.8861469109402994,[tp,tn,fp,fn]: [52377, 122664, 15760, 23127]
VAL, loss 0.3483381507251303, acc 0.853966770405576,f1 0.6728005881435605, recall 0.5957077481458103,precision 0.7728133476636471,specificity 0.9409903622465936,[tp,tn,fp,fn]: [15100, 70786, 4439, 10248]

TRAIN, epoch 50, loss 0.4157020199771844, acc 0.8185604502449422,recall 0.6957909514727697,precision 0.7682689636010003,specificity 0.8855256313934,[tp,tn,fp,fn]: [52535, 122578, 15846, 22969]
VAL, loss 0.34908055741815786, acc 0.8530420689449455,f1 0.6692032229185317, recall 0.5897901215086003,precision 0.7733291951169046,specificity 0.9417480890661349,[tp,tn,fp,fn]: [14950, 70843, 4382, 10398]

TRAIN, epoch 51, loss 0.41600120838148236, acc 0.8191260611046707,recall 0.695645263827082,precision 0.7697177525718808,specificity 0.8864792232560827,[tp,tn,fp,fn]: [52524, 122710, 15714, 22980]
VAL, loss 0.34915202538277207, acc 0.853966770405576,f1 0.6747137383446656, recall 0.6009152595865551,precision 0.7691763874160481,specificity 0.9392356264539714,[tp,tn,fp,fn]: [15232, 70654, 4571, 10116]

TRAIN, epoch 52, loss 0.4155673076980673, acc 0.8182005160614786,recall 0.6954995761813944,precision 0.7675768117636741,specificity 0.8851283014506155,[tp,tn,fp,fn]: [52513, 122523, 15901, 22991]
VAL, loss 0.349535117082425, acc 0.8535292772414067,f1 0.6699675142825137, recall 0.5898690231970964,precision 0.7752372064084616,specificity 0.9423728813559322,[tp,tn,fp,fn]: [14952, 70890, 4335, 10396]

TRAIN, epoch 53, loss 0.41527721748217955, acc 0.8185043566059609,recall 0.6926652892561983,precision 0.7699974970922101,specificity 0.8871438478876496,[tp,tn,fp,fn]: [52299, 122802, 15622, 23205]
VAL, loss 0.3477541480699044, acc 0.8544738647549541,f1 0.6765095924321457, recall 0.603755720372416,precision 0.769199839163651,specificity 0.9389564639415088,[tp,tn,fp,fn]: [15304, 70633, 4592, 10044]

TRAIN, epoch 54, loss 0.4148641266857943, acc 0.8187521035114618,recall 0.6946916719643992,precision 0.7693842227242057,specificity 0.8864214298098596,[tp,tn,fp,fn]: [52452, 122702, 15722, 23052]
VAL, loss 0.35003907324189215, acc 0.8528332653893193,f1 0.6653704415455224, recall 0.5805191731103045,precision 0.7792723613832547,specificity 0.9445928880026587,[tp,tn,fp,fn]: [14715, 71057, 4168, 10633]

TRAIN, epoch 55, loss 0.4150525950457359, acc 0.818635241763584,recall 0.692996397541852,precision 0.7701161267533079,specificity 0.8871655204299832,[tp,tn,fp,fn]: [52324, 122805, 15619, 23180]
VAL, loss 0.3482251230172402, acc 0.8534298469768228,f1 0.6671183072510896, recall 0.5827284203881963,precision 0.7800897808291524,specificity 0.9446460618145563,[tp,tn,fp,fn]: [14771, 71061, 4164, 10577]

TRAIN, epoch 56, loss 0.41425236360145257, acc 0.8189203844284059,recall 0.6955922865013774,precision 0.769253302867856,specificity 0.8861902560249668,[tp,tn,fp,fn]: [52520, 122670, 15754, 22984]
VAL, loss 0.34722347671963305, acc 0.8548318137074563,f1 0.6764901395967207, recall 0.6022171374467413,precision 0.7716611060560105,specificity 0.9399534729145895,[tp,tn,fp,fn]: [15265, 70708, 4517, 10083]

TRAIN, epoch 57, loss 0.4137250286363672, acc 0.8200095359186268,recall 0.6984795507522781,precision 0.770156402879799,specificity 0.8862986187366353,[tp,tn,fp,fn]: [52738, 122685, 15739, 22766]
VAL, loss 0.3476244008754876, acc 0.8549809591043321,f1 0.6814876285733005, recall 0.615551522802588,precision 0.7632441422491807,specificity 0.9356596876038551,[tp,tn,fp,fn]: [15603, 70385, 4840, 9745]

TRAIN, epoch 58, loss 0.41372327992511415, acc 0.8201123742567593,recall 0.6991285229921593,precision 0.7700173588318527,specificity 0.886103565855632,[tp,tn,fp,fn]: [52787, 122658, 15766, 22717]
VAL, loss 0.3471178633287929, acc 0.8550903323953745,f1 0.6802685270501513, recall 0.6116458892220293,precision 0.766235049915983,specificity 0.9371219674310403,[tp,tn,fp,fn]: [15504, 70495, 4730, 9844]

TRAIN, epoch 59, loss 0.41217814759186194, acc 0.8204536105605624,recall 0.6973537825810553,precision 0.7719023045798393,specificity 0.8875989712766572,[tp,tn,fp,fn]: [52653, 122865, 15559, 22851]
VAL, loss 0.3489281703436192, acc 0.8543048333051614,f1 0.6739938149375932, recall 0.5975619378254695,precision 0.7728455533445584,specificity 0.9408175473579262,[tp,tn,fp,fn]: [15147, 70773, 4452, 10201]

TRAIN, epoch 60, loss 0.41180450627260917, acc 0.8208462660334318,recall 0.6988106590379317,precision 0.7719757710540177,specificity 0.8874111425764318,[tp,tn,fp,fn]: [52763, 122839, 15585, 22741]
VAL, loss 0.3457986034204595, acc 0.8554085092420431,f1 0.6820864850684274, recall 0.6154331702698438,precision 0.7649308620182407,specificity 0.936271186440678,[tp,tn,fp,fn]: [15600, 70431, 4794, 9748]

TRAIN, epoch 61, loss 0.4116954717729814, acc 0.8209070341423282,recall 0.7000291375291375,precision 0.7713918767057313,specificity 0.8868404322949778,[tp,tn,fp,fn]: [52855, 122760, 15664, 22649]
VAL, loss 0.34661739944675907, acc 0.8562536664910065,f1 0.6856148744155703, recall 0.6219031087265268,precision 0.7638707176430682,specificity 0.9352210036556996,[tp,tn,fp,fn]: [15764, 70352, 4873, 9584]

TRAIN, epoch 62, loss 0.4117302426020114, acc 0.8203554466923451,recall 0.6977776011866921,precision 0.7714101644288914,specificity 0.8872160896954285,[tp,tn,fp,fn]: [52685, 122812, 15612, 22819]
VAL, loss 0.3459529121594386, acc 0.8560050908295467,f1 0.6828990584628858, recall 0.6151964652043553,precision 0.7673457336876292,specificity 0.9371485543369891,[tp,tn,fp,fn]: [15594, 70497, 4728, 9754]

TRAIN, epoch 63, loss 0.41113757404427465, acc 0.8210940129389327,recall 0.6978305785123967,precision 0.7731668305281231,specificity 0.8883286135352251,[tp,tn,fp,fn]: [52689, 122966, 15458, 22815]
VAL, loss 0.34620293118166684, acc 0.8554085092420431,f1 0.6806903517632076, recall 0.6114880858450371,precision 0.7675547192235317,specificity 0.937600531738119,[tp,tn,fp,fn]: [15500, 70531, 4694, 9848]

TRAIN, epoch 64, loss 0.4106946095363404, acc 0.8219073707041622,recall 0.6994861199406653,precision 0.7741377541298389,specificity 0.8886825983933422,[tp,tn,fp,fn]: [52814, 123015, 15409, 22690]
VAL, loss 0.34689864654753266, acc 0.8562636095174649,f1 0.6838698390482856, recall 0.6168534006627742,precision 0.7672227674190383,specificity 0.9369358590893985,[tp,tn,fp,fn]: [15636, 70481, 4744, 9712]

TRAIN, epoch 65, loss 0.4102184215853037, acc 0.8218653004749261,recall 0.6996980292434838,precision 0.7739071838743701,specificity 0.8885019938738947,[tp,tn,fp,fn]: [52830, 122990, 15434, 22674]
VAL, loss 0.3453794982241229, acc 0.8560349199089219,f1 0.6865949479425961, recall 0.6256903897743412,precision 0.7606349815356578,specificity 0.9336523762047192,[tp,tn,fp,fn]: [15860, 70234, 4991, 9488]

TRAIN, epoch 66, loss 0.4099325153464436, acc 0.8223047006469466,recall 0.7009429963975419,precision 0.774218087129524,specificity 0.8885019938738947,[tp,tn,fp,fn]: [52924, 122990, 15434, 22580]
VAL, loss 0.34962097231508, acc 0.8546926113370388,f1 0.6745936317078602, recall 0.5976013886697176,precision 0.7743584500562315,specificity 0.9413226985709539,[tp,tn,fp,fn]: [15148, 70811, 4414, 10200]

TRAIN, epoch 67, loss 0.4097162398795023, acc 0.8218699749448413,recall 0.7002940241576605,precision 0.7735578540810206,specificity 0.8881841299196671,[tp,tn,fp,fn]: [52875, 122946, 15478, 22629]
VAL, loss 0.3465250761927228, acc 0.8561840653057978,f1 0.6838469945355192, recall 0.6171295565725107,precision 0.7667385550436232,specificity 0.9367364572947823,[tp,tn,fp,fn]: [15643, 70466, 4759, 9705]

TRAIN, epoch 68, loss 0.4092957320628707, acc 0.8225057028532964,recall 0.7020025429116338,precision 0.7740635268346112,specificity 0.8882346991851124,[tp,tn,fp,fn]: [53004, 122953, 15471, 22500]
VAL, loss 0.34797815637634466, acc 0.8550207312101658,f1 0.6768323766040915, recall 0.6023749408237337,precision 0.7722927520105205,specificity 0.9401528747092057,[tp,tn,fp,fn]: [15269, 70723, 4502, 10079]

TRAIN, epoch 69, loss 0.4081791830996355, acc 0.8225898433117684,recall 0.7028766687857597,precision 0.7737392293224861,specificity 0.8878879385077733,[tp,tn,fp,fn]: [53070, 122905, 15519, 22434]
VAL, loss 0.3477230586962962, acc 0.8552593638451672,f1 0.6816541649353774, recall 0.6148414076061228,precision 0.7647578389518622,specificity 0.936271186440678,[tp,tn,fp,fn]: [15585, 70431, 4794, 9763]

TRAIN, epoch 70, loss 0.4077937806122038, acc 0.8225991922515987,recall 0.7029826234371689,precision 0.7736979432386338,specificity 0.8878445934231058,[tp,tn,fp,fn]: [53078, 122899, 15525, 22426]
VAL, loss 0.34789288534068213, acc 0.8546528392312052,f1 0.6740400481648308, recall 0.5962600599652833,precision 0.7751564263001334,specificity 0.9417215021601861,[tp,tn,fp,fn]: [15114, 70841, 4384, 10234]

TRAIN, epoch 71, loss 0.40761367755051053, acc 0.823244269099884,recall 0.7036448400084764,precision 0.7748559760810909,specificity 0.888480321331561,[tp,tn,fp,fn]: [53128, 122987, 15437, 22376]
VAL, loss 0.3456950918120476, acc 0.8566116154435087,f1 0.6874715558156167, recall 0.6257298406185893,precision 0.7627314258235153,specificity 0.9344101030242605,[tp,tn,fp,fn]: [15861, 70291, 4934, 9487]

TRAIN, epoch 72, loss 0.4068973431354159, acc 0.8232582925096295,recall 0.7025588048315321,precision 0.7755489926606041,specificity 0.8890943766976824,[tp,tn,fp,fn]: [53046, 123072, 15352, 22458]
VAL, loss 0.3477030253748269, acc 0.8570192795283028,f1 0.6863001745200699, recall 0.6205617800220925,precision 0.7676166308803436,specificity 0.9366965769358591,[tp,tn,fp,fn]: [15730, 70463, 4762, 9618]

TRAIN, epoch 73, loss 0.4068505472749241, acc 0.8243334205901051,recall 0.706002331002331,precision 0.7760598648963429,specificity 0.8888776512743455,[tp,tn,fp,fn]: [53306, 123042, 15382, 22198]
VAL, loss 0.34665243879656826, acc 0.8568800771578853,f1 0.6924096076587744, recall 0.639143127662932,precision 0.7553618052965312,specificity 0.9302492522432702,[tp,tn,fp,fn]: [16201, 69978, 5247, 9147]

TRAIN, epoch 74, loss 0.40638236359844504, acc 0.8235387607045361,recall 0.7025058275058275,precision 0.7762622566954486,specificity 0.8895567242674681,[tp,tn,fp,fn]: [53042, 123136, 15288, 22462]
VAL, loss 0.3485021491380465, acc 0.8562039513587145,f1 0.6861681350635823, recall 0.6237178475619378,precision 0.7625156747371468,specificity 0.9345430375540047,[tp,tn,fp,fn]: [15810, 70301, 4924, 9538]

TRAIN, epoch 75, loss 0.40599898000242446, acc 0.8240950226244343,recall 0.7054195804195804,precision 0.7758372055760295,specificity 0.8888270820089001,[tp,tn,fp,fn]: [53262, 123035, 15389, 22242]
VAL, loss 0.34642550420812906, acc 0.8563530967555905,f1 0.681931265273772, recall 0.6109752248698123,precision 0.7715339012603996,specificity 0.9390362246593553,[tp,tn,fp,fn]: [15487, 70639, 4586, 9861]

TRAIN, epoch 76, loss 0.40514325699048903, acc 0.8240389289854531,recall 0.7047176308539945,precision 0.7761278935776069,specificity 0.8891232734207941,[tp,tn,fp,fn]: [53209, 123076, 15348, 22295]
VAL, loss 0.34462127908254586, acc 0.857377228480805,f1 0.6910884265839686, recall 0.6329887959602335,precision 0.7609314236934459,specificity 0.9329877035559987,[tp,tn,fp,fn]: [16045, 70184, 5041, 9303]

TRAIN, epoch 77, loss 0.4046296966173526, acc 0.8248896825100034,recall 0.7045057215511761,precision 0.7783240419647952,specificity 0.8905536612148183,[tp,tn,fp,fn]: [53193, 123274, 15150, 22311]
VAL, loss 0.34463270050286593, acc 0.8574170005866386,f1 0.6895163036417961, recall 0.6281757929619693,precision 0.7641328342451291,specificity 0.9346626786307743,[tp,tn,fp,fn]: [15923, 70310, 4915, 9425]

TRAIN, epoch 78, loss 0.40465530477078865, acc 0.8248850080400882,recall 0.7072737868192414,precision 0.776620808004421,specificity 0.8890365832514593,[tp,tn,fp,fn]: [53402, 123064, 15360, 22102]
VAL, loss 0.34571200267699675, acc 0.8569297922901773,f1 0.6912032963495505, recall 0.6353163957708695,precision 0.7578709586333474,specificity 0.9316051844466601,[tp,tn,fp,fn]: [16104, 70080, 5145, 9244]

TRAIN, epoch 79, loss 0.40334895585408087, acc 0.825338431621854,recall 0.7065585929222293,precision 0.7781554035328268,specificity 0.8901274345489222,[tp,tn,fp,fn]: [53348, 123215, 15209, 22156]
VAL, loss 0.344643172152733, acc 0.8573473994014298,f1 0.6908840195634843, recall 0.6325153858292567,precision 0.761120341799193,specificity 0.9331073446327683,[tp,tn,fp,fn]: [16033, 70193, 5032, 9315]

TRAIN, epoch 80, loss 0.4033780785261535, acc 0.8261097191578475,recall 0.7079757363848272,precision 0.7791592572078244,specificity 0.8905464370340404,[tp,tn,fp,fn]: [53455, 123273, 15151, 22049]
VAL, loss 0.34544988401866733, acc 0.8563431537291321,f1 0.6835742444152431, recall 0.6156698753353321,precision 0.76831429696731,specificity 0.9374410103024261,[tp,tn,fp,fn]: [15606, 70519, 4706, 9742]

TRAIN, epoch 81, loss 0.4023949809377719, acc 0.8258479488426013,recall 0.7078035600762873,precision 0.7786292907512092,specificity 0.8902357972605907,[tp,tn,fp,fn]: [53442, 123230, 15194, 22062]
VAL, loss 0.3446468538896603, acc 0.8573871715072634,f1 0.6886896881036616, recall 0.6258876439955815,precision 0.7655006031363089,specificity 0.9353938185443669,[tp,tn,fp,fn]: [15865, 70365, 4860, 9483]

TRAIN, epoch 82, loss 0.40291585202754904, acc 0.8257217381548932,recall 0.7082538673447765,precision 0.7780477513785629,specificity 0.8897951222331387,[tp,tn,fp,fn]: [53476, 123169, 15255, 22028]
VAL, loss 0.3465540222726944, acc 0.8565420142582999,f1 0.6836519908787932, recall 0.6150386618273631,precision 0.7694965449160909,specificity 0.9379195746095048,[tp,tn,fp,fn]: [15590, 70555, 4670, 9758]

TRAIN, epoch 83, loss 0.4012629195442063, acc 0.8269464492726525,recall 0.7095518118245391,precision 0.7802228209422559,specificity 0.8909798878807144,[tp,tn,fp,fn]: [53574, 123333, 15091, 21930]
VAL, loss 0.34452977703312837, acc 0.8570888807135115,f1 0.6872647359603125, recall 0.6230471832097206,precision 0.7662413274465092,specificity 0.9359521435692921,[tp,tn,fp,fn]: [15793, 70407, 4818, 9555]

TRAIN, epoch 84, loss 0.4008029948378513, acc 0.8274653154332299,recall 0.7105054036872218,precision 0.7808960959562141,specificity 0.8912616309310524,[tp,tn,fp,fn]: [53646, 123372, 15052, 21858]
VAL, loss 0.3464056628206181, acc 0.8566016724170503,f1 0.683644818811968, recall 0.6147625059176266,precision 0.7699110671936759,specificity 0.9380923894981722,[tp,tn,fp,fn]: [15583, 70568, 4657, 9765]

TRAIN, epoch 85, loss 0.4003873499798742, acc 0.8270633110205303,recall 0.7099491417673236,precision 0.7802620087336245,specificity 0.8909437669768249,[tp,tn,fp,fn]: [53604, 123328, 15096, 21900]
VAL, loss 0.34568953021147203, acc 0.8573672854543466,f1 0.6895223253901261, recall 0.6284124980274578,precision 0.7637976504435388,specificity 0.9345164506480559,[tp,tn,fp,fn]: [15929, 70299, 4926, 9419]

TRAIN, epoch 86, loss 0.3998189084222102, acc 0.8274840133128903,recall 0.7113265522356431,precision 0.7804353512162515,specificity 0.8908426284459342,[tp,tn,fp,fn]: [53708, 123314, 15110, 21796]
VAL, loss 0.34651670894342906, acc 0.8572579121633043,f1 0.688819525729397, recall 0.6268344642575351,precision 0.764408736649668,specificity 0.9349019607843138,[tp,tn,fp,fn]: [15889, 70328, 4897, 9459]

TRAIN, epoch 87, loss 0.399212214262545, acc 0.8276709921094948,recall 0.7117238821784276,precision 0.7806444115168948,specificity 0.8909148702537132,[tp,tn,fp,fn]: [53738, 123324, 15100, 21766]
VAL, loss 0.3450404039037278, acc 0.8575363169041392,f1 0.6906735751295338, recall 0.6310557045920783,precision 0.7627312607285905,specificity 0.9338517779993353,[tp,tn,fp,fn]: [15996, 70249, 4976, 9352]

TRAIN, epoch 88, loss 0.3990245248286103, acc 0.8279795071238921,recall 0.7113000635727909,precision 0.7816557023927345,specificity 0.8916228399699474,[tp,tn,fp,fn]: [53706, 123422, 15002, 21798]
VAL, loss 0.34665002556401026, acc 0.8576655762480984,f1 0.6897418669672077, recall 0.6277418336752406,precision 0.7653311529026983,specificity 0.9351412429378531,[tp,tn,fp,fn]: [15912, 70346, 4879, 9436]

TRAIN, epoch 89, loss 0.39783519977099574, acc 0.8288349351183576,recall 0.7140813731722823,precision 0.7820146493581841,specificity 0.8914277870889441,[tp,tn,fp,fn]: [53916, 123395, 15029, 21588]
VAL, loss 0.34443717895473, acc 0.8575661459835144,f1 0.6885124703733502, recall 0.6245857661353953,precision 0.7670171018845986,specificity 0.9360717846460618,[tp,tn,fp,fn]: [15832, 70416, 4809, 9516]

TRAIN, epoch 90, loss 0.39692518587360465, acc 0.8286479563217531,recall 0.7100286077558805,precision 0.784081435654425,specificity 0.8933494191758654,[tp,tn,fp,fn]: [53610, 123661, 14763, 21894]
VAL, loss 0.3461366848189283, acc 0.8569496783430941,f1 0.686181699203839, recall 0.6205223291778444,precision 0.7673805922817973,specificity 0.9366168162180126,[tp,tn,fp,fn]: [15729, 70457, 4768, 9619]

TRAIN, epoch 91, loss 0.39655775198993165, acc 0.8295735013649452,recall 0.7143727484636575,precision 0.7836294692798303,specificity 0.8924102756747385,[tp,tn,fp,fn]: [53938, 123531, 14893, 21566]
VAL, loss 0.3466943241707313, acc 0.8576158611158065,f1 0.690177412375595, recall 0.6292409657566672,precision 0.7641816788041396,specificity 0.9345696244599535,[tp,tn,fp,fn]: [15950, 70303, 4922, 9398]

TRAIN, epoch 92, loss 0.39637919180386355, acc 0.828933098986575,recall 0.7118165924984107,precision 0.7836604356828323,specificity 0.8928148297983008,[tp,tn,fp,fn]: [53745, 123587, 14837, 21759]
VAL, loss 0.3467161976701894, acc 0.8573573424278882,f1 0.6886583619080688, recall 0.6259270948398296,precision 0.7653642064640618,specificity 0.9353406447324693,[tp,tn,fp,fn]: [15866, 70361, 4864, 9482]

TRAIN, epoch 93, loss 0.3953249921231569, acc 0.8297838525111252,recall 0.715034965034965,precision 0.7837296402752374,specificity 0.892374154770849,[tp,tn,fp,fn]: [53988, 123526, 14898, 21516]
VAL, loss 0.34398817878512866, acc 0.8584311892853946,f1 0.6930539386883974, recall 0.6341328704434275,precision 0.7640460119783249,specificity 0.9340112994350283,[tp,tn,fp,fn]: [16074, 70261, 4964, 9274]

TRAIN, epoch 94, loss 0.39526287674333255, acc 0.830026924946711,recall 0.7169024157660522,precision 0.7831616412986863,specificity 0.8917312026816159,[tp,tn,fp,fn]: [54129, 123437, 14987, 21375]
VAL, loss 0.3450026847178766, acc 0.8587294800791465,f1 0.6960075313449442, recall 0.6416679816948083,precision 0.7604020570359982,specificity 0.9318710535061482,[tp,tn,fp,fn]: [16265, 70100, 5125, 9083]

TRAIN, epoch 95, loss 0.3946783594723874, acc 0.8304943719382222,recall 0.7165845518118246,precision 0.7844942582067046,specificity 0.8926270010980755,[tp,tn,fp,fn]: [54105, 123561, 14863, 21399]
VAL, loss 0.3448690193059948, acc 0.8578544937508079,f1 0.6927573608424673, recall 0.6358292567460944,precision 0.7608818808422245,specificity 0.9326686606846128,[tp,tn,fp,fn]: [16117, 70160, 5065, 9231]

TRAIN, epoch 96, loss 0.3942298001521037, acc 0.8305037208780525,recall 0.716094511549057,precision 0.7848226209138942,specificity 0.8929087441484136,[tp,tn,fp,fn]: [54068, 123600, 14824, 21436]
VAL, loss 0.3452418325451952, acc 0.8584212462589363,f1 0.6934091251641797, recall 0.6352374940823734,precision 0.7633088409575729,specificity 0.9336257892987704,[tp,tn,fp,fn]: [16102, 70232, 4993, 9246]

TRAIN, epoch 97, loss 0.39297077712497, acc 0.8314993829699712,recall 0.7195247933884298,precision 0.7851062907351475,specificity 0.8925764318326301,[tp,tn,fp,fn]: [54327, 123554, 14870, 21177]
VAL, loss 0.34643469212843386, acc 0.8570093365018444,f1 0.6841215103125617, recall 0.6143679974751459,precision 0.7717429010357302,specificity 0.9387703555998671,[tp,tn,fp,fn]: [15573, 70619, 4606, 9775]

TRAIN, epoch 98, loss 0.39241021301287116, acc 0.8314806850903108,recall 0.718399025217207,precision 0.7857629181092552,specificity 0.89316159047564,[tp,tn,fp,fn]: [54242, 123635, 14789, 21262]
VAL, loss 0.3452033334489864, acc 0.8584510753383114,f1 0.6921280276816609, recall 0.6312924096575667,precision 0.7659391154508903,specificity 0.9349950149551346,[tp,tn,fp,fn]: [16002, 70335, 4890, 9346]

TRAIN, epoch 99, loss 0.3917520812929829, acc 0.8308870274110915,recall 0.7160415342233524,precision 0.7857911107235255,specificity 0.893530023695313,[tp,tn,fp,fn]: [54064, 123686, 14738, 21440]
VAL, loss 0.3442318456214909, acc 0.8575760890099728,f1 0.6821268474546182, recall 0.6063200252485403,precision 0.7795982550471746,specificity 0.9422399468261881,[tp,tn,fp,fn]: [15369, 70880, 4345, 9979]



 * BEST_ACC: 0.8587294800791465
 * TIME: Time 9614.174 (9614.174)

