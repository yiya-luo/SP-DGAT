pooling_ratio 0.2, dropout0.2, hidden_dim 64, outdim 128
epochs 100, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.5392840831802045, acc 0.7561235555887962,recall 0.4876430387794024,precision 0.7319007673040989,specificity 0.9025674738484656,[tp,tn,fp,fn]: [36819, 124937, 13487, 38685]
VAL, loss 0.42636639498177226, acc 0.8261660684279081,f1 0.5536749125628654, recall 0.42780495502603755,precision 0.7844896187513565,specificity 0.9603988035892324,[tp,tn,fp,fn]: [10844, 72246, 2979, 14504]

TRAIN, epoch 1, loss 0.47756794538045355, acc 0.7873162933323361,recall 0.636244437380801,precision 0.7270594645316544,specificity 0.8697191238513553,[tp,tn,fp,fn]: [48039, 120390, 18034, 27465]
VAL, loss 0.4021630703740044, acc 0.8334045916896184,f1 0.5870406427920045, recall 0.4698201041502288,precision 0.782200328407225,specificity 0.9559189099368561,[tp,tn,fp,fn]: [11909, 71909, 3316, 13439]

TRAIN, epoch 2, loss 0.46532678029276947, acc 0.7920936015855802,recall 0.6494225471498198,precision 0.7314031711937471,specificity 0.8699141767323586,[tp,tn,fp,fn]: [49034, 120417, 18007, 26470]
VAL, loss 0.38627704023666226, acc 0.8385451363686078,f1 0.611103127844039, recall 0.5033138709168377,precision 0.7776423259783006,specificity 0.9515054835493519,[tp,tn,fp,fn]: [12758, 71577, 3648, 12590]

TRAIN, epoch 3, loss 0.45739808329237386, acc 0.7966652331625593,recall 0.6603491205763933,precision 0.7363283269091607,specificity 0.8710194763913772,[tp,tn,fp,fn]: [49859, 120570, 17854, 25645]
VAL, loss 0.378066388732817, acc 0.8432283018305111,f1 0.6335045675367843, recall 0.5375966545684078,precision 0.7710632037571437,specificity 0.9462146892655368,[tp,tn,fp,fn]: [13627, 71179, 4046, 11721]

TRAIN, epoch 4, loss 0.4532249479854006, acc 0.7992315171459556,recall 0.6642826870099597,precision 0.7402225567460669,specificity 0.872839969947408,[tp,tn,fp,fn]: [50156, 120822, 17602, 25348]
VAL, loss 0.37595493137924907, acc 0.8424229166873813,f1 0.6275790759975561, recall 0.5267871232444374,precision 0.7760664884342671,specificity 0.9487803256895979,[tp,tn,fp,fn]: [13353, 71372, 3853, 11995]

TRAIN, epoch 5, loss 0.4490511128236957, acc 0.8008722560861599,recall 0.6686003390548845,precision 0.7417387854655519,specificity 0.8730205744668554,[tp,tn,fp,fn]: [50482, 120847, 17577, 25022]
VAL, loss 0.37151920150036805, acc 0.8444910661907271,f1 0.6373585605639028, recall 0.5422124033454316,precision 0.7730033745781777,specificity 0.9463476237952808,[tp,tn,fp,fn]: [13744, 71189, 4036, 11604]

TRAIN, epoch 6, loss 0.44536572701465327, acc 0.8030599080064321,recall 0.671739245602882,precision 0.7451553661940792,specificity 0.8746893602265503,[tp,tn,fp,fn]: [50719, 121078, 17346, 24785]
VAL, loss 0.3644066290438958, acc 0.8479910115040816,f1 0.6602968625011111, recall 0.5861606438377781,precision 0.755901505901506,specificity 0.9362180126287803,[tp,tn,fp,fn]: [14858, 70427, 4798, 10490]

TRAIN, epoch 7, loss 0.44299357539606826, acc 0.8049530683220523,recall 0.6767720915448188,precision 0.7468430283542824,specificity 0.8748699647459978,[tp,tn,fp,fn]: [51099, 121103, 17321, 24405]
VAL, loss 0.36211162193882607, acc 0.8484981058534596,f1 0.6563986920735144, recall 0.5741675871863657,precision 0.7661209664683898,specificity 0.9409371884346959,[tp,tn,fp,fn]: [14554, 70782, 4443, 10794]

TRAIN, epoch 8, loss 0.4405833974874598, acc 0.8056448898694888,recall 0.6784408773045136,precision 0.7475483042437686,specificity 0.8750288967231116,[tp,tn,fp,fn]: [51225, 121125, 17299, 24279]
VAL, loss 0.35793727934144187, acc 0.850427052986388,f1 0.6679909068838421, recall 0.5970096260059965,precision 0.7581283502830519,specificity 0.9358192090395481,[tp,tn,fp,fn]: [15133, 70397, 4828, 10215]

TRAIN, epoch 9, loss 0.43844600094336095, acc 0.8073510713885046,recall 0.6784408773045136,precision 0.7515515192417729,specificity 0.877665722707045,[tp,tn,fp,fn]: [51225, 121490, 16934, 24279]
VAL, loss 0.3582291678513905, acc 0.8510435206268084,f1 0.6688037494749409, recall 0.5967334700962601,precision 0.7606738747799849,specificity 0.9367364572947823,[tp,tn,fp,fn]: [15126, 70466, 4759, 10222]

TRAIN, epoch 10, loss 0.4360237917633145, acc 0.8086552484948207,recall 0.6818579148124603,precision 0.7527194572782034,specificity 0.8778174305033809,[tp,tn,fp,fn]: [51483, 121511, 16913, 24021]
VAL, loss 0.35512892066704627, acc 0.851689817346604,f1 0.6693709269849715, recall 0.5956682973015622,precision 0.7638874835576243,specificity 0.937959454968428,[tp,tn,fp,fn]: [15099, 70558, 4667, 10249]

TRAIN, epoch 11, loss 0.4341514233224907, acc 0.8099874724206275,recall 0.6867583174401356,precision 0.7531190541894817,specificity 0.8772033751372594,[tp,tn,fp,fn]: [51853, 121426, 16998, 23651]
VAL, loss 0.3535282462705299, acc 0.8526940630189017,f1 0.6761111475481514, recall 0.6100284046078586,precision 0.758250380032364,specificity 0.9344632768361582,[tp,tn,fp,fn]: [15463, 70295, 4930, 9885]

TRAIN, epoch 12, loss 0.43351643894414243, acc 0.8106185258591676,recall 0.6840564738292011,precision 0.7561193418047667,specificity 0.8796523724209675,[tp,tn,fp,fn]: [51649, 121765, 16659, 23855]
VAL, loss 0.35455653511446544, acc 0.8519284499816054,f1 0.6685953355883923, recall 0.5926305822944611,precision 0.7668981008780886,specificity 0.9393020937188434,[tp,tn,fp,fn]: [15022, 70659, 4566, 10326]

TRAIN, epoch 13, loss 0.43161864461424837, acc 0.8107353876070453,recall 0.6848643780461963,precision 0.7559388933557488,specificity 0.879392301912963,[tp,tn,fp,fn]: [51710, 121729, 16695, 23794]
VAL, loss 0.35389782853244756, acc 0.8527636642041104,f1 0.6725777207800822, recall 0.6000078901688496,precision 0.7651172150115706,specificity 0.9379328680624792,[tp,tn,fp,fn]: [15209, 70556, 4669, 10139]

TRAIN, epoch 14, loss 0.4302420843080417, acc 0.8122919860887775,recall 0.6863344988344988,precision 0.7587928661375817,specificity 0.8809960700456568,[tp,tn,fp,fn]: [51821, 121951, 16473, 23683]
VAL, loss 0.3525085440814595, acc 0.8535193342149483,f1 0.6772554002541296, recall 0.6097916995423702,precision 0.7615035964134398,specificity 0.9356463941508807,[tp,tn,fp,fn]: [15457, 70384, 4841, 9891]

TRAIN, epoch 15, loss 0.4288651619271892, acc 0.8125818032235145,recall 0.6872616020343293,precision 0.7589510325864389,specificity 0.8809382765994336,[tp,tn,fp,fn]: [51891, 121943, 16481, 23613]
VAL, loss 0.351097717083458, acc 0.8539071122468257,f1 0.6839875255403807, recall 0.6273078743885119,precision 0.7519269872795196,specificity 0.9302625456962446,[tp,tn,fp,fn]: [15901, 69979, 5246, 9447]

TRAIN, epoch 16, loss 0.4276576901005092, acc 0.8128202011891852,recall 0.6887847001483365,precision 0.758646846873131,specificity 0.880475929029648,[tp,tn,fp,fn]: [52006, 121879, 16545, 23498]
VAL, loss 0.3504788761895011, acc 0.8540264285643264,f1 0.6807714888342865, recall 0.6175635158592394,precision 0.7583934886875636,specificity 0.9337055500166168,[tp,tn,fp,fn]: [15654, 70238, 4987, 9694]

TRAIN, epoch 17, loss 0.4260032392367077, acc 0.8137971654014434,recall 0.6898310023310024,precision 0.7603649635036497,specificity 0.881415072530775,[tp,tn,fp,fn]: [52085, 122009, 16415, 23419]
VAL, loss 0.3519177986371253, acc 0.8538673401409921,f1 0.6787611199755196, recall 0.6125532586397349,precision 0.7610155369308435,specificity 0.9351811232967764,[tp,tn,fp,fn]: [15527, 70349, 4876, 9821]

TRAIN, epoch 18, loss 0.42531076964450787, acc 0.8151340637971654,recall 0.691314367450731,precision 0.7626903182442503,specificity 0.8826720799861296,[tp,tn,fp,fn]: [52197, 122183, 16241, 23307]
VAL, loss 0.35221391798730195, acc 0.8530221828920287,f1 0.6728198317839752, recall 0.5996133817263689,precision 0.7663876563130294,specificity 0.938411432369558,[tp,tn,fp,fn]: [15199, 70592, 4633, 10149]

TRAIN, epoch 19, loss 0.4250670022155543, acc 0.8145217082382857,recall 0.6921222716677262,precision 0.7607692419676523,specificity 0.8812850372767728,[tp,tn,fp,fn]: [52258, 121991, 16433, 23246]
VAL, loss 0.34983836140894364, acc 0.8544042635697453,f1 0.68255035012032, recall 0.6210351901530693,precision 0.7575917994128688,specificity 0.9330408773678963,[tp,tn,fp,fn]: [15742, 70188, 5037, 9606]

TRAIN, epoch 20, loss 0.42388621302408136, acc 0.8151714595564863,recall 0.6911951684678957,precision 0.7628486230485879,specificity 0.8827948910593538,[tp,tn,fp,fn]: [52188, 122200, 16224, 23316]
VAL, loss 0.350570912732568, acc 0.8538872261939089,f1 0.6777058888035968, recall 0.6095155436326337,precision 0.7630760112609275,specificity 0.9362313060817548,[tp,tn,fp,fn]: [15450, 70428, 4797, 9898]

TRAIN, epoch 21, loss 0.42273582826421763, acc 0.8157838151153659,recall 0.6919368510277601,precision 0.7638793443773486,specificity 0.8833367046176963,[tp,tn,fp,fn]: [52244, 122275, 16149, 23260]
VAL, loss 0.35105076105144245, acc 0.8535292772414067,f1 0.6731456211586679, recall 0.598429856398927,precision 0.7691800618629887,specificity 0.9394882020604852,[tp,tn,fp,fn]: [15169, 70673, 4552, 10179]

TRAIN, epoch 22, loss 0.422163551859481, acc 0.8160409109606971,recall 0.6912481457936004,precision 0.7648972652929624,specificity 0.8841096919609316,[tp,tn,fp,fn]: [52192, 122382, 16042, 23312]
VAL, loss 0.34905060637900187, acc 0.8548417567339147,f1 0.6804001838919416, recall 0.6130661196149597,precision 0.7643500073778958,specificity 0.9363110667996012,[tp,tn,fp,fn]: [15540, 70434, 4791, 9808]

