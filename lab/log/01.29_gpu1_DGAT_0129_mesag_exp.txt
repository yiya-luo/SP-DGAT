pooling_ratio 0.2, dropout0.5, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.6198250952826526, acc 0.6693700684342395,recall 0.16079942784488238,precision 0.6223281562355836,specificity 0.9467722360284344,[tp,tn,fp,fn]: [12141, 131056, 7368, 63363]
VAL, loss 0.5368434031005609, acc 0.7480238234913943,f1 0.29578169288056466, recall 0.2099573930882121,precision 0.5002820078962211,specificity 0.9293320039880358,[tp,tn,fp,fn]: [5322, 69909, 5316, 20026]

TRAIN, epoch 1, loss 0.6086030961763644, acc 0.6731376911858196,recall 0.22427950837041746,precision 0.5986072324931953,specificity 0.917969427266948,[tp,tn,fp,fn]: [16934, 127069, 11355, 58570]
VAL, loss 0.5342140176803709, acc 0.7452000039772105,f1 0.31330725119245406, recall 0.23062963547419915,precision 0.4883876357560568,specificity 0.9185908939847125,[tp,tn,fp,fn]: [5846, 69101, 6124, 19502]

TRAIN, epoch 2, loss 0.6060497682558466, acc 0.6735677424180098,recall 0.24580154693791056,precision 0.5901675835532801,specificity 0.9068947581344275,[tp,tn,fp,fn]: [18559, 125536, 12888, 56945]
VAL, loss 0.5335895973127569, acc 0.7438378093524107,f1 0.3254169830588358, recall 0.24514754615748777,precision 0.4838433387837733,specificity 0.9118777002326355,[tp,tn,fp,fn]: [6214, 68596, 6629, 19134]

TRAIN, epoch 3, loss 0.6046647928842659, acc 0.6740959575184174,recall 0.2611252383979657,precision 0.5859486447931527,specificity 0.8993527134023002,[tp,tn,fp,fn]: [19716, 124492, 13932, 55788]
VAL, loss 0.5328759590201738, acc 0.7439670686963697,f1 0.33770576131687247, recall 0.2589947924885593,precision 0.48514631983446643,specificity 0.9073845131272849,[tp,tn,fp,fn]: [6565, 68258, 6967, 18783]

TRAIN, epoch 4, loss 0.6033880996599786, acc 0.6752365281777046,recall 0.27797202797202797,precision 0.583843329253366,specificity 0.8919262555626192,[tp,tn,fp,fn]: [20988, 123464, 14960, 54516]
VAL, loss 0.532158233232087, acc 0.7452497191095026,f1 0.35801448294870825, recall 0.28183683130819,precision 0.49062564384314267,specificity 0.9014024592888003,[tp,tn,fp,fn]: [7144, 67808, 7417, 18204]

TRAIN, epoch 5, loss 0.6006132405709456, acc 0.675923675255226,recall 0.3098643780461962,precision 0.5760149691016077,specificity 0.8755923828237878,[tp,tn,fp,fn]: [23396, 121203, 17221, 52108]
VAL, loss 0.5282023581626782, acc 0.7368279756992433,f1 0.3909241531664212, recall 0.3350954710430803,precision 0.469074442235476,specificity 0.8721967431040213,[tp,tn,fp,fn]: [8494, 65611, 9614, 16854]

TRAIN, epoch 6, loss 0.5899969592513823, acc 0.6812993156576044,recall 0.3747086247086247,precision 0.5743518950851622,specificity 0.8485306016297752,[tp,tn,fp,fn]: [28292, 117457, 20967, 47212]
VAL, loss 0.509830925029918, acc 0.7501615741799489,f1 0.45514669210920056, recall 0.41403661038346223,precision 0.5053204294862536,specificity 0.8634230641409106,[tp,tn,fp,fn]: [10495, 64951, 10274, 14853]

TRAIN, epoch 7, loss 0.5751020898726602, acc 0.7019417748027373,recall 0.41656071201525746,precision 0.6147411215135938,specificity 0.8576041726868173,[tp,tn,fp,fn]: [31452, 118713, 19711, 44052]
VAL, loss 0.5006417019944572, acc 0.7702365445994451,f1 0.47116440864152326, recall 0.40610699068960077,precision 0.5610420754305646,specificity 0.892934529744101,[tp,tn,fp,fn]: [10294, 67171, 8054, 15054]

TRAIN, epoch 8, loss 0.5685301603685521, acc 0.7127491492464755,recall 0.4046805467260013,precision 0.6493189111078054,specificity 0.8807865688030977,[tp,tn,fp,fn]: [30555, 121922, 16502, 44949]
VAL, loss 0.49395047448268875, acc 0.7768486571942768,f1 0.47288442116635737, recall 0.39715164904528955,precision 0.5843055313715247,specificity 0.9047922897972749,[tp,tn,fp,fn]: [10067, 68063, 7162, 15281]

TRAIN, epoch 9, loss 0.5655843175869374, acc 0.7174002468120115,recall 0.3955552023733842,precision 0.6683824187628682,specificity 0.892952089233081,[tp,tn,fp,fn]: [29866, 123606, 14818, 45638]
VAL, loss 0.4904226853691032, acc 0.7805574060632575,f1 0.47399780733114066, recall 0.39229919520277734,precision 0.5986754966887418,specificity 0.9113858424725823,[tp,tn,fp,fn]: [9944, 68559, 6666, 15404]

TRAIN, epoch 10, loss 0.5626878978284098, acc 0.7205648629445421,recall 0.39425725789362154,precision 0.6794640615370569,specificity 0.8985508293359533,[tp,tn,fp,fn]: [29768, 124381, 14043, 45736]
VAL, loss 0.48739680068371133, acc 0.7829735614926472,f1 0.47484541539349906, recall 0.38930093103992425,precision 0.608572309589886,specificity 0.9156264539714191,[tp,tn,fp,fn]: [9868, 68878, 6347, 15480]

TRAIN, epoch 11, loss 0.5607736326673572, acc 0.7224720466699076,recall 0.3935553083280356,precision 0.6863062105919578,specificity 0.9018811766745651,[tp,tn,fp,fn]: [29715, 124842, 13582, 45789]
VAL, loss 0.48428559536113874, acc 0.7853797738955783,f1 0.4798168454030607, recall 0.3927331544895061,precision 0.6165231931628167,specificity 0.9176869391824526,[tp,tn,fp,fn]: [9955, 69033, 6192, 15393]

TRAIN, epoch 12, loss 0.5579582134901927, acc 0.7233041023147975,recall 0.3951313837677474,precision 0.6881011140069654,specificity 0.9023074033404612,[tp,tn,fp,fn]: [29834, 124901, 13523, 45670]
VAL, loss 0.47903408181874696, acc 0.7866524812822527,f1 0.48377240466738847, recall 0.3966387880700647,precision 0.6199667016094222,specificity 0.9180724493187106,[tp,tn,fp,fn]: [10054, 69062, 6163, 15294]

TRAIN, epoch 13, loss 0.549241289981778, acc 0.7286750682472608,recall 0.4127331002331002,precision 0.6945794142557838,specificity 0.9010070508004392,[tp,tn,fp,fn]: [31163, 124721, 13703, 44341]
VAL, loss 0.46094244845349225, acc 0.7923796645222873,f1 0.4942230834443503, recall 0.4024775130187786,precision 0.6401455731944532,specificity 0.923762047191758,[tp,tn,fp,fn]: [10202, 69490, 5735, 15146]

TRAIN, epoch 14, loss 0.5295875438541505, acc 0.7409782730638346,recall 0.45748569612205975,precision 0.7050538863487916,specificity 0.8956105877593481,[tp,tn,fp,fn]: [34542, 123974, 14450, 40962]
VAL, loss 0.4325277924202218, acc 0.8044107265369433,f1 0.5305138547459367, recall 0.4384566829730156,precision 0.6715002114675851,specificity 0.9277234961781323,[tp,tn,fp,fn]: [11114, 69788, 5437, 14234]

TRAIN, epoch 15, loss 0.5103189270224703, acc 0.7594798249878464,recall 0.5195221445221445,precision 0.7210396676592772,specificity 0.8903658325145929,[tp,tn,fp,fn]: [39226, 123248, 15176, 36278]
VAL, loss 0.42005847320499906, acc 0.8143338669424199,f1 0.5549066812862012, recall 0.4592078270474988,precision 0.7009936766034327,specificity 0.9339980059820538,[tp,tn,fp,fn]: [11640, 70260, 4965, 13708]

TRAIN, epoch 16, loss 0.49645340496152535, acc 0.7717877042743353,recall 0.5523018648018648,precision 0.7352210017807084,specificity 0.891507253077501,[tp,tn,fp,fn]: [41701, 123406, 15018, 33803]
VAL, loss 0.4087619919996206, acc 0.822019826394758,f1 0.5759901459162403, recall 0.4796433643679975,precision 0.7207730614180697,specificity 0.9373878364905284,[tp,tn,fp,fn]: [12158, 70515, 4710, 13190]

TRAIN, epoch 17, loss 0.4860353429214675, acc 0.7785002430724356,recall 0.5705922865013774,precision 0.7422172452407615,specificity 0.8919045830202855,[tp,tn,fp,fn]: [43082, 123461, 14963, 32422]
VAL, loss 0.399109844831019, acc 0.8286219959631312,f1 0.595513001032573, recall 0.5005523118194729,precision 0.7349397590361446,specificity 0.9391691591890994,[tp,tn,fp,fn]: [12688, 70649, 4576, 12660]

TRAIN, epoch 18, loss 0.47729661737203927, acc 0.784675217830298,recall 0.5868430811612629,precision 0.7487410862144716,specificity 0.892583656013408,[tp,tn,fp,fn]: [44309, 123555, 14869, 31195]
VAL, loss 0.39437568282422886, acc 0.8324798902289879,f1 0.6091858037578288, recall 0.5180290358213666,precision 0.7392748564350862,specificity 0.9384380192755069,[tp,tn,fp,fn]: [13131, 70594, 4631, 12217]

TRAIN, epoch 19, loss 0.4711490734101572, acc 0.7884054448225571,recall 0.5997033269760542,precision 0.7506382414376181,specificity 0.8913338727388315,[tp,tn,fp,fn]: [45280, 123382, 15042, 30224]
VAL, loss 0.39158472429117586, acc 0.8353832539548388,f1 0.6163507438476156, recall 0.5246567776550418,precision 0.7468830731214198,specificity 0.9400864074443337,[tp,tn,fp,fn]: [13299, 70718, 4507, 12049]

TRAIN, epoch 20, loss 0.4668893562325775, acc 0.7919346696084664,recall 0.6106563890654799,precision 0.7531239280638996,specificity 0.8908137317228226,[tp,tn,fp,fn]: [46107, 123310, 15114, 29397]
VAL, loss 0.38824865275454684, acc 0.8371232835850576,f1 0.6256883668852684, recall 0.5401215086002841,precision 0.7434699972848221,specificity 0.9372017281488867,[tp,tn,fp,fn]: [13691, 70501, 4724, 11657]

TRAIN, epoch 21, loss 0.4619653859641699, acc 0.7946178153397405,recall 0.6187486755668574,precision 0.7551116067820718,specificity 0.8905464370340404,[tp,tn,fp,fn]: [46718, 123273, 15151, 28786]
VAL, loss 0.38402322220868745, acc 0.8389130283475684,f1 0.6369523809523809, recall 0.5606753984535269,precision 0.7372516470405146,specificity 0.9326686606846128,[tp,tn,fp,fn]: [14212, 70160, 5065, 11136]

TRAIN, epoch 22, loss 0.46018412597453756, acc 0.7968896077184847,recall 0.6247086247086248,precision 0.7573174060337492,specificity 0.8908065075420447,[tp,tn,fp,fn]: [47168, 123309, 15115, 28336]
VAL, loss 0.3828937471665674, acc 0.8393704075646545,f1 0.6364188778610492, recall 0.5577954868234181,precision 0.7408435944458999,specificity 0.9342505815885677,[tp,tn,fp,fn]: [14139, 70279, 4946, 11209]

TRAIN, epoch 23, loss 0.4573001728692759, acc 0.7968428630193336,recall 0.6266290527654164,precision 0.7560040266526054,specificity 0.8896867595214702,[tp,tn,fp,fn]: [47313, 123154, 15270, 28191]
VAL, loss 0.3805675548099005, acc 0.8400664194167421,f1 0.6421818343603319, recall 0.5694334858765978,precision 0.7362407549094618,specificity 0.9312595546693253,[tp,tn,fp,fn]: [14434, 70054, 5171, 10914]

TRAIN, epoch 24, loss 0.4555813642106913, acc 0.7985583934781796,recall 0.6323108709472346,precision 0.7569204426546596,specificity 0.8892388603132405,[tp,tn,fp,fn]: [47742, 123092, 15332, 27762]
VAL, loss 0.378286477691052, acc 0.8406630010042456,f1 0.6452212800814717, recall 0.574877702382831,precision 0.7351798597447152,specificity 0.9302226653373213,[tp,tn,fp,fn]: [14572, 69976, 5249, 10776]

TRAIN, epoch 25, loss 0.4534726440248981, acc 0.7992128192662952,recall 0.6356484424666243,precision 0.7565497020713138,specificity 0.8884297520661157,[tp,tn,fp,fn]: [47994, 122980, 15444, 27510]
VAL, loss 0.3787288030580282, acc 0.8407823173217464,f1 0.6444636870267989, recall 0.5725501025721951,precision 0.7370372251282312,specificity 0.9311665004985045,[tp,tn,fp,fn]: [14513, 70047, 5178, 10835]

TRAIN, epoch 26, loss 0.45129435661820627, acc 0.8008582326764145,recall 0.6392111676202585,precision 0.7585659499559915,specificity 0.8890293590706814,[tp,tn,fp,fn]: [48263, 123063, 15361, 27241]
VAL, loss 0.375332128260819, acc 0.8414186710150836,f1 0.6518065713350071, recall 0.5889222029351429,precision 0.7297257662413844,specificity 0.9265004985044866,[tp,tn,fp,fn]: [14928, 69696, 5529, 10420]

TRAIN, epoch 27, loss 0.4497057961069527, acc 0.8018351968886728,recall 0.6421646535282899,precision 0.7592427303048809,specificity 0.8889282205397908,[tp,tn,fp,fn]: [48486, 123049, 15375, 27018]
VAL, loss 0.37593942532007507, acc 0.8416970757559186,f1 0.6509241597053214, recall 0.5856083320183052,precision 0.7326390602635605,specificity 0.9279893652376204,[tp,tn,fp,fn]: [14844, 69808, 5417, 10504]

TRAIN, epoch 28, loss 0.4486475577184049, acc 0.8025176694962791,recall 0.6443499682136046,precision 0.759637754703724,specificity 0.8887909611050107,[tp,tn,fp,fn]: [48651, 123030, 15394, 26853]
VAL, loss 0.3751543551925227, acc 0.8421445119465463,f1 0.6557675628794449, recall 0.5965756667192678,precision 0.727999229732332,specificity 0.9248919906945829,[tp,tn,fp,fn]: [15122, 69575, 5650, 10226]

TRAIN, epoch 29, loss 0.44805850137466313, acc 0.8028542313301672,recall 0.6460717312990041,precision 0.7594382949574207,specificity 0.8883719586198925,[tp,tn,fp,fn]: [48781, 122972, 15452, 26723]
VAL, loss 0.372676135858983, acc 0.8428305807721754,f1 0.6575977472110907, recall 0.5988243648414076,precision 0.7291636643128212,specificity 0.9250515121302758,[tp,tn,fp,fn]: [15179, 69587, 5638, 10169]

TRAIN, epoch 30, loss 0.4461762682358492, acc 0.8038452189521709,recall 0.649263615172706,precision 0.7599956591166303,specificity 0.8881624573773335,[tp,tn,fp,fn]: [49022, 122943, 15481, 26482]
VAL, loss 0.3734338112930094, acc 0.8427908086663418,f1 0.6583399961103789, recall 0.6009547104308032,precision 0.7278417506808734,specificity 0.9242804918577601,[tp,tn,fp,fn]: [15233, 69529, 5696, 10115]

TRAIN, epoch 31, loss 0.44561032224515496, acc 0.8033403762013388,recall 0.6494490358126722,precision 0.7586132211203762,specificity 0.8872811073224296,[tp,tn,fp,fn]: [49036, 122821, 15603, 26468]
VAL, loss 0.37163096379459853, acc 0.8433177890686367,f1 0.6625406887099538, recall 0.610265109673347,precision 0.7246112047967023,specificity 0.921847789963443,[tp,tn,fp,fn]: [15469, 69346, 5879, 9879]

TRAIN, epoch 32, loss 0.44423575012196437, acc 0.8052943046258554,recall 0.6533561135833863,precision 0.7611516563546311,specificity 0.8881696815581113,[tp,tn,fp,fn]: [49331, 122944, 15480, 26173]
VAL, loss 0.37160605212621634, acc 0.8438447694709316,f1 0.6608797046058171, recall 0.6037162695281679,precision 0.7300004770309593,specificity 0.9247590561648388,[tp,tn,fp,fn]: [15303, 69565, 5660, 10045]

TRAIN, epoch 33, loss 0.44374744423860246, acc 0.8053503982648368,recall 0.6542567281203645,precision 0.7607453607453607,specificity 0.8877651274345489,[tp,tn,fp,fn]: [49399, 122888, 15536, 26105]
VAL, loss 0.37023489953691857, acc 0.8443220347409345,f1 0.6640633381251744, recall 0.6105018147388354,precision 0.7279269956253822,specificity 0.9231106679960119,[tp,tn,fp,fn]: [15475, 69441, 5784, 9873]

TRAIN, epoch 34, loss 0.44291189989981766, acc 0.8060842900415093,recall 0.655369251960161,precision 0.7619098943737874,specificity 0.8882924926313356,[tp,tn,fp,fn]: [49483, 122961, 15463, 26021]
VAL, loss 0.3704224590040201, acc 0.8445606673759359,f1 0.6672201289992975, recall 0.6182736310557045,precision 0.7245827361412918,specificity 0.920810900631439,[tp,tn,fp,fn]: [15672, 69268, 5957, 9676]

TRAIN, epoch 35, loss 0.44171108731575864, acc 0.8060796155715941,recall 0.6566407077770714,precision 0.7611262070341884,specificity 0.8875917470958793,[tp,tn,fp,fn]: [49579, 122864, 15560, 25925]
VAL, loss 0.37005162795266144, acc 0.8444711801378103,f1 0.6667660843630165, recall 0.617366261637999,precision 0.7247591700629863,specificity 0.9209970089730808,[tp,tn,fp,fn]: [15649, 69282, 5943, 9699]

TRAIN, epoch 36, loss 0.44178077032337737, acc 0.806575109382596,recall 0.6580446069082433,precision 0.7615142922829335,specificity 0.8875917470958793,[tp,tn,fp,fn]: [49685, 122864, 15560, 25819]
VAL, loss 0.37017147832517616, acc 0.8450081035665636,f1 0.6677607741165438, recall 0.6179974751459681,precision 0.7262401483541956,specificity 0.9215021601861083,[tp,tn,fp,fn]: [15665, 69320, 5905, 9683]

TRAIN, epoch 37, loss 0.4408141625491002, acc 0.8068602520474178,recall 0.6595147276965458,precision 0.7613368804085252,specificity 0.8872305380569844,[tp,tn,fp,fn]: [49796, 122814, 15610, 25708]
VAL, loss 0.3682853176856239, acc 0.8454953118630248,f1 0.6707490200233076, recall 0.6244279627584031,precision 0.7244930654094384,specificity 0.9199867065470256,[tp,tn,fp,fn]: [15828, 69206, 6019, 9520]

TRAIN, epoch 38, loss 0.44037782699778005, acc 0.8067948094686063,recall 0.6594485060394152,precision 0.7612138816694695,specificity 0.8871655204299832,[tp,tn,fp,fn]: [49791, 122805, 15619, 25713]
VAL, loss 0.368435828319701, acc 0.8453561094926073,f1 0.670954365625066, recall 0.6255720372415969,precision 0.7234362881518317,specificity 0.919415088069126,[tp,tn,fp,fn]: [15857, 69163, 6062, 9491]

TRAIN, epoch 39, loss 0.43995445929385485, acc 0.8072949777495232,recall 0.66094511549057,precision 0.7615559523264509,specificity 0.8871221753453158,[tp,tn,fp,fn]: [49904, 122799, 15625, 25600]
VAL, loss 0.3679281525280073, acc 0.8456146281805256,f1 0.671393198027555, recall 0.6257692914628373,precision 0.7241930329178652,specificity 0.9196942505815886,[tp,tn,fp,fn]: [15862, 69184, 6041, 9486]

TRAIN, epoch 40, loss 0.43873764457563014, acc 0.8080241950562806,recall 0.6624947022674296,precision 0.7624338866279513,specificity 0.8874039183956539,[tp,tn,fp,fn]: [50021, 122838, 15586, 25483]
VAL, loss 0.36749286892451183, acc 0.8457041154186511,f1 0.671951631997294, recall 0.6269922676345274,precision 0.7238568045181272,specificity 0.9194017946161516,[tp,tn,fp,fn]: [15893, 69162, 6063, 9455]

TRAIN, epoch 41, loss 0.43823060106243267, acc 0.8084261994689802,recall 0.6647594829413012,precision 0.7620667142401651,specificity 0.8867898630295324,[tp,tn,fp,fn]: [50192, 122753, 15671, 25312]
VAL, loss 0.36720828867816596, acc 0.8461714376621956,f1 0.6737796520822351, recall 0.630306138551365,precision 0.7236943425284232,specificity 0.9189099368560983,[tp,tn,fp,fn]: [15977, 69125, 6100, 9371]

TRAIN, epoch 42, loss 0.43787250907841674, acc 0.8085056654575371,recall 0.6647197499470227,precision 0.7622873633049818,specificity 0.8869343466450904,[tp,tn,fp,fn]: [50189, 122773, 15651, 25315]
VAL, loss 0.36623766742587505, acc 0.846559215694073,f1 0.6733691741099775, recall 0.6275445794540003,precision 0.7264133710841173,specificity 0.9203589232303091,[tp,tn,fp,fn]: [15907, 69234, 5991, 9441]

TRAIN, epoch 43, loss 0.437289435683796, acc 0.8086552484948207,recall 0.6656998304725578,precision 0.7620686518284917,specificity 0.8866309310524186,[tp,tn,fp,fn]: [50263, 122731, 15693, 25241]
VAL, loss 0.36597571000131596, acc 0.8464398993765723,f1 0.6751367269667649, recall 0.6331071484929778,precision 0.7231434751261716,specificity 0.9183250249252243,[tp,tn,fp,fn]: [16048, 69081, 6144, 9300]

TRAIN, epoch 44, loss 0.4366500951066379, acc 0.8091600912456527,recall 0.6659249841068023,precision 0.7631826599071067,specificity 0.8872883315032075,[tp,tn,fp,fn]: [50280, 122822, 15602, 25224]
VAL, loss 0.36697169144384073, acc 0.8462410388474044,f1 0.6757391486684841, recall 0.6356714533691021,precision 0.7211977441589831,specificity 0.9171950814223995,[tp,tn,fp,fn]: [16113, 68996, 6229, 9235]

TRAIN, epoch 45, loss 0.43618362348726347, acc 0.8093657679219176,recall 0.667580525535071,precision 0.762695194286406,specificity 0.8867031728601976,[tp,tn,fp,fn]: [50405, 122741, 15683, 25099]
VAL, loss 0.36584474540282425, acc 0.8466785320115737,f1 0.6772032656478961, recall 0.6381174057124822,precision 0.7213897065382214,specificity 0.9169557992688601,[tp,tn,fp,fn]: [16175, 68978, 6247, 9173]

TRAIN, epoch 46, loss 0.4351086217242338, acc 0.8097303765752963,recall 0.6684811400720492,precision 0.7630544552958607,specificity 0.8867754146679766,[tp,tn,fp,fn]: [50473, 122751, 15673, 25031]
VAL, loss 0.36564230477500365, acc 0.8467481331967824,f1 0.6771132292866868, recall 0.6375650938930093,precision 0.7218921695626926,specificity 0.9172349617813227,[tp,tn,fp,fn]: [16161, 68999, 6226, 9187]

TRAIN, epoch 47, loss 0.4353397682625106, acc 0.8099641000710519,recall 0.6697658402203857,precision 0.7628601599034546,specificity 0.8864358781714153,[tp,tn,fp,fn]: [50570, 122704, 15720, 24934]
VAL, loss 0.3659497524486908, acc 0.8468873355672,f1 0.6773524420139544, recall 0.6376834464257535,precision 0.7222842843737433,specificity 0.9173811897640413,[tp,tn,fp,fn]: [16164, 69010, 6215, 9184]

TRAIN, epoch 48, loss 0.4342400030798948, acc 0.8100342171197786,recall 0.6708783640601822,precision 0.7623677437803832,specificity 0.8859374096977403,[tp,tn,fp,fn]: [50654, 122635, 15789, 24850]
VAL, loss 0.36536093922186635, acc 0.8469370506994919,f1 0.679131232282808, recall 0.642693703645258,precision 0.719948736079194,specificity 0.9157593885011632,[tp,tn,fp,fn]: [16291, 68888, 6337, 9057]

TRAIN, epoch 49, loss 0.43416891471462576, acc 0.8103567555439213,recall 0.6711829836829837,precision 0.7629780186690756,specificity 0.8862697220135237,[tp,tn,fp,fn]: [50677, 122681, 15743, 24827]
VAL, loss 0.3645902298095355, acc 0.8475137462340787,f1 0.6790691834428493, recall 0.6400899479248856,precision 0.723103663428113,specificity 0.9174077766699901,[tp,tn,fp,fn]: [16225, 69012, 6213, 9123]



 * BEST_ACC: 0.8475137462340787
 * TIME: Time 2911.528 (2911.528)

