pooling_ratio 0.2, dropout0.5, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.6150925861019805, acc 0.6720859354549195,recall 0.27621053189235006,precision 0.5736329629222137,specificity 0.8880179737617754,[tp,tn,fp,fn]: [20855, 122923, 15501, 54649]
VAL, loss 0.5219070353052117, acc 0.7463434520199258,f1 0.3173218443094543, recall 0.2339040555467887,precision 0.49322019798685635,specificity 0.9190162844798937,[tp,tn,fp,fn]: [5929, 69133, 6092, 19419]

TRAIN, epoch 1, loss 0.5808723732098552, acc 0.7046342694738417,recall 0.3664044289044289,precision 0.6431776439681026,specificity 0.8891232734207941,[tp,tn,fp,fn]: [27665, 123076, 15348, 47839]
VAL, loss 0.4916559120494089, acc 0.7588915514104183,f1 0.3828985876065657, recall 0.29678870127820733,precision 0.5393991539399154,specificity 0.9146028580923895,[tp,tn,fp,fn]: [7523, 68801, 6424, 17825]

TRAIN, epoch 2, loss 0.5512889106790503, acc 0.7284273213417598,recall 0.4741338207247298,precision 0.6606078500119946,specificity 0.8671328671328671,[tp,tn,fp,fn]: [35799, 120032, 18392, 39705]
VAL, loss 0.4897080693978188, acc 0.7673331808735943,f1 0.3973731650785475, recall 0.3043632633738362,precision 0.572244474113633,specificity 0.9233366566965769,[tp,tn,fp,fn]: [7715, 69458, 5767, 17633]

TRAIN, epoch 3, loss 0.5436808996178094, acc 0.7352286750682473,recall 0.48802712439076074,precision 0.6719918298865667,specificity 0.8700658845286945,[tp,tn,fp,fn]: [36848, 120438, 17986, 38656]
VAL, loss 0.48637166367705864, acc 0.7746611913734303,f1 0.4027093271486177, recall 0.3014044500552312,precision 0.6065899166335847,specificity 0.9341309405117979,[tp,tn,fp,fn]: [7640, 70270, 4955, 17708]

TRAIN, epoch 4, loss 0.5398566048609186, acc 0.7389121573613552,recall 0.49272886204704386,precision 0.6794323909708525,specificity 0.8731939548055251,[tp,tn,fp,fn]: [37203, 120871, 17553, 38301]
VAL, loss 0.4812926169305836, acc 0.7767691129826096,f1 0.39824171111528045, recall 0.29308032191888905,precision 0.6211019145556391,specificity 0.9397540711199734,[tp,tn,fp,fn]: [7429, 70693, 4532, 17919]

TRAIN, epoch 5, loss 0.5374029885634386, acc 0.7411839497400995,recall 0.4950995973723246,precision 0.6843010910155964,specificity 0.8754117783043402,[tp,tn,fp,fn]: [37382, 121178, 17246, 38122]
VAL, loss 0.4850900588523806, acc 0.7788472055124138,f1 0.4017751479289941, recall 0.29465835568881177,precision 0.6312542258282623,specificity 0.9420006646726488,[tp,tn,fp,fn]: [7469, 70862, 4363, 17879]

TRAIN, epoch 6, loss 0.5353193762441397, acc 0.7435258591675704,recall 0.49614589955499044,precision 0.6900801326333241,specificity 0.878460382592614,[tp,tn,fp,fn]: [37461, 121600, 16824, 38043]
VAL, loss 0.4786770475837879, acc 0.7802491722430474,f1 0.4065730472840534, recall 0.29868234180211456,precision 0.6364859184531315,specificity 0.9425191093386507,[tp,tn,fp,fn]: [7571, 70901, 4324, 17777]

TRAIN, epoch 7, loss 0.5333321317565062, acc 0.7450357129501515,recall 0.49909938546302185,precision 0.6926187325393325,specificity 0.879182800670404,[tp,tn,fp,fn]: [37684, 121700, 16724, 37820]
VAL, loss 0.4794442800805954, acc 0.7816909110795144,f1 0.40867223269593317, recall 0.29931355531008363,precision 0.6439483958580886,specificity 0.9442339647723497,[tp,tn,fp,fn]: [7587, 71030, 4195, 17761]

TRAIN, epoch 8, loss 0.5316919206286826, acc 0.7457135110878427,recall 0.5022382920110193,precision 0.692785501580284,specificity 0.8785181760388372,[tp,tn,fp,fn]: [37921, 121608, 16816, 37583]
VAL, loss 0.4778918137788188, acc 0.7831425929424398,f1 0.41216106948412484, recall 0.3016411551207196,precision 0.6505019567806705,specificity 0.9453904951811233,[tp,tn,fp,fn]: [7646, 71117, 4108, 17702]

TRAIN, epoch 9, loss 0.5311226504759604, acc 0.746606334841629,recall 0.5040924984106803,precision 0.6942144238135192,specificity 0.87888660925851,[tp,tn,fp,fn]: [38061, 121659, 16765, 37443]
VAL, loss 0.4747509991266981, acc 0.7845445596730732,f1 0.4166375016825952, recall 0.30527063279154176,precision 0.6559294735949818,specificity 0.9460418743768694,[tp,tn,fp,fn]: [7738, 71166, 4059, 17610]

TRAIN, epoch 10, loss 0.5292758702661198, acc 0.7483732844695411,recall 0.5057347955075228,precision 0.6981314904197747,specificity 0.8807215511760966,[tp,tn,fp,fn]: [38185, 121913, 16511, 37319]
VAL, loss 0.47110347863864455, acc 0.7871198035257971,f1 0.4230043658707487, recall 0.3096102256588291,precision 0.667460452457901,specificity 0.9480225988700565,[tp,tn,fp,fn]: [7848, 71315, 3910, 17500]

TRAIN, epoch 11, loss 0.5276578703050923, acc 0.7487238697131745,recall 0.5064764780673872,precision 0.6986826959969306,specificity 0.8808588106108767,[tp,tn,fp,fn]: [38241, 121932, 16492, 37263]
VAL, loss 0.46903903077776565, acc 0.7885018842035139,f1 0.425713437187829, recall 0.3110304560517595,precision 0.674364896073903,specificity 0.9493918245264208,[tp,tn,fp,fn]: [7884, 71418, 3807, 17464]

TRAIN, epoch 12, loss 0.5270630345330813, acc 0.7493315508021391,recall 0.5059996821360457,precision 0.7006106618253837,specificity 0.882058024620008,[tp,tn,fp,fn]: [38205, 122098, 16326, 37299]
VAL, loss 0.46609229902695515, acc 0.7900629393574816,f1 0.4321445860900436, recall 0.31694808268896957,precision 0.6788913300659117,specificity 0.9494848786972416,[tp,tn,fp,fn]: [8034, 71425, 3800, 17314]

TRAIN, epoch 13, loss 0.5271243155905323, acc 0.7508928237537863,recall 0.5073903369357915,precision 0.7041373352693587,specificity 0.8837123620181472,[tp,tn,fp,fn]: [38310, 122327, 16097, 37194]
VAL, loss 0.4677780847991473, acc 0.7901325405426903,f1 0.42797907802379465, recall 0.3115038661827363,precision 0.6835771794649814,specificity 0.9514124293785311,[tp,tn,fp,fn]: [7896, 71570, 3655, 17452]

TRAIN, epoch 14, loss 0.5246352388457939, acc 0.7515332261321566,recall 0.5085690824327188,precision 0.7052416985013223,specificity 0.8840591226954864,[tp,tn,fp,fn]: [38399, 122375, 16049, 37105]
VAL, loss 0.46620311233988376, acc 0.791942171358118,f1 0.4328499796720423, recall 0.3150149913208143,precision 0.6915216073438989,specificity 0.9526487205051513,[tp,tn,fp,fn]: [7985, 71663, 3562, 17363]

TRAIN, epoch 15, loss 0.5247391629943913, acc 0.75251486481433,recall 0.5097743165924984,precision 0.7072767364939361,specificity 0.8849188002080564,[tp,tn,fp,fn]: [38490, 122494, 15930, 37014]
VAL, loss 0.4621238759086968, acc 0.793990434808547,f1 0.4386159807082668, recall 0.3193151333438536,precision 0.7002335842200882,specificity 0.953938185443669,[tp,tn,fp,fn]: [8094, 71760, 3465, 17254]

TRAIN, epoch 16, loss 0.5224107137338363, acc 0.7538377398003067,recall 0.5110060394151303,precision 0.7102516429504998,specificity 0.8862913945558574,[tp,tn,fp,fn]: [38583, 122684, 15740, 36921]
VAL, loss 0.4644852852588631, acc 0.794368269813966,f1 0.43839782756279694, recall 0.31844721477039606,precision 0.7033196828439487,specificity 0.9547357926221336,[tp,tn,fp,fn]: [8072, 71820, 3405, 17276]

TRAIN, epoch 17, loss 0.5212106836320913, acc 0.7557309001159268,recall 0.5129926891290527,precision 0.71439374377513,specificity 0.8881335606542218,[tp,tn,fp,fn]: [38733, 122939, 15485, 36771]
VAL, loss 0.4614208820761426, acc 0.7980869617094051,f1 0.4456334798394802, recall 0.3219977907527221,precision 0.7233891695471063,specificity 0.9585111332668661,[tp,tn,fp,fn]: [8162, 72104, 3121, 17186]

TRAIN, epoch 18, loss 0.5206499612102699, acc 0.7568153771362327,recall 0.5112709260436533,precision 0.7185161746640361,specificity 0.8907487140958216,[tp,tn,fp,fn]: [38603, 123301, 15123, 36901]
VAL, loss 0.4602145135509579, acc 0.8005926043769203,f1 0.45152468207302066, recall 0.32566671926779234,precision 0.7359365249175359,specificity 0.9606247922897972,[tp,tn,fp,fn]: [8255, 72263, 2962, 17093]

TRAIN, epoch 19, loss 0.5212070665611904, acc 0.7578390860476422,recall 0.5113503920322102,precision 0.7214073506605131,specificity 0.8922874646015142,[tp,tn,fp,fn]: [38609, 123514, 14910, 36895]
VAL, loss 0.45650365444401814, acc 0.8028894434888091,f1 0.4566087385560002, recall 0.32858608174214926,precision 0.7480689779055146,specificity 0.9627118644067797,[tp,tn,fp,fn]: [8329, 72420, 2805, 17019]

TRAIN, epoch 20, loss 0.5203833184666286, acc 0.7580681350734827,recall 0.5098008052553508,precision 0.7230445563152754,specificity 0.8934866786106456,[tp,tn,fp,fn]: [38492, 123680, 14744, 37012]
VAL, loss 0.4617273270824251, acc 0.8031081900708937,f1 0.45058542811164753, recall 0.3203408552943033,precision 0.7593042827753881,specificity 0.9657826520438684,[tp,tn,fp,fn]: [8120, 72651, 2574, 17228]

TRAIN, epoch 21, loss 0.520174378662859, acc 0.7591105418645525,recall 0.5109398177579996,precision 0.7253548932969822,specificity 0.8944763913772178,[tp,tn,fp,fn]: [38578, 123817, 14607, 36926]
VAL, loss 0.4590513995015894, acc 0.8039632903463156,f1 0.4527285849108977, recall 0.32172163484298566,precision 0.7637197977149279,specificity 0.9664606181455633,[tp,tn,fp,fn]: [8155, 72702, 2523, 17193]

TRAIN, epoch 22, loss 0.5195999882959543, acc 0.7602464380539247,recall 0.5087280144098326,precision 0.730136100973236,specificity 0.8974383054961568,[tp,tn,fp,fn]: [38411, 124227, 14197, 37093]
VAL, loss 0.45733460983711305, acc 0.8053453710240323,f1 0.45747540529305813, recall 0.3256272684235443,precision 0.7687435969078886,specificity 0.9669923562645397,[tp,tn,fp,fn]: [8254, 72742, 2483, 17094]

TRAIN, epoch 23, loss 0.518419233915279, acc 0.7610457724094087,recall 0.510357067175249,precision 0.7314313915304748,specificity 0.897785066173496,[tp,tn,fp,fn]: [38534, 124275, 14149, 36970]
VAL, loss 0.45455594619438877, acc 0.8068268819663329,f1 0.46298855658134785, recall 0.3304008205775604,precision 0.7733148661126501,specificity 0.9673645729478232,[tp,tn,fp,fn]: [8375, 72770, 2455, 16973]

TRAIN, epoch 24, loss 0.5180311454942386, acc 0.7615038704610897,recall 0.5109000847637212,precision 0.7324320732147265,specificity 0.8981968444778362,[tp,tn,fp,fn]: [38575, 124332, 14092, 36929]
VAL, loss 0.4556899379487723, acc 0.8073538623686277,f1 0.4609220667204585, recall 0.3267713429067382,precision 0.7819314641744548,specificity 0.9692921236291127,[tp,tn,fp,fn]: [8283, 72915, 2310, 17065]

TRAIN, epoch 25, loss 0.5171708599162581, acc 0.7629856774241801,recall 0.5105027548209367,precision 0.7371390323197552,specificity 0.9007036352077674,[tp,tn,fp,fn]: [38545, 124679, 13745, 36959]
VAL, loss 0.4518774437816705, acc 0.8084873673848846,f1 0.46676448603305554, recall 0.33257061701120405,precision 0.782511835143414,specificity 0.9688534396809572,[tp,tn,fp,fn]: [8430, 72882, 2343, 16918]

TRAIN, epoch 26, loss 0.5168878028857397, acc 0.7624387644441121,recall 0.5090856113583386,precision 0.7364589121146514,specificity 0.9006313933999884,[tp,tn,fp,fn]: [38438, 124669, 13755, 37066]
VAL, loss 0.4523293822985249, acc 0.8079703300090482,f1 0.46288622521344935, recall 0.3283099258324128,precision 0.7844283155811104,specificity 0.9695978730475241,[tp,tn,fp,fn]: [8322, 72938, 2287, 17026]

TRAIN, epoch 27, loss 0.5165291071954516, acc 0.7637148947309376,recall 0.5110855054036872,precision 0.7389414423040098,specificity 0.9015127434548922,[tp,tn,fp,fn]: [38589, 124791, 13633, 36915]
VAL, loss 0.45337714422672526, acc 0.808218905670508,f1 0.46140958337987265, recall 0.3259428751775288,precision 0.7895642201834863,specificity 0.9707278165503489,[tp,tn,fp,fn]: [8262, 73023, 2202, 17086]

TRAIN, epoch 28, loss 0.5162711206328061, acc 0.7635746606334841,recall 0.5085690824327188,precision 0.7402644972239358,specificity 0.9026686123793561,[tp,tn,fp,fn]: [38399, 124951, 13473, 37105]
VAL, loss 0.45091069678921175, acc 0.8098197329303093,f1 0.4670511856000446, recall 0.33063752564304877,precision 0.7950858552319514,specificity 0.9712861415752742,[tp,tn,fp,fn]: [8381, 73065, 2160, 16967]

TRAIN, epoch 29, loss 0.515695287013686, acc 0.7641402714932126,recall 0.5122112735749099,precision 0.739450488518384,specificity 0.9015560885395596,[tp,tn,fp,fn]: [38674, 124797, 13627, 36830]
VAL, loss 0.45150664805995266, acc 0.8096507014805167,f1 0.4643836382966818, recall 0.3274025564147073,precision 0.7984414085049066,specificity 0.9721502160186108,[tp,tn,fp,fn]: [8299, 73130, 2095, 17049]

TRAIN, epoch 30, loss 0.5151169785301855, acc 0.7643973673385438,recall 0.5098670269124814,precision 0.7418677252755723,specificity 0.9032320984800324,[tp,tn,fp,fn]: [38497, 125029, 13395, 37007]
VAL, loss 0.4511883824114872, acc 0.8097203026657254,f1 0.46498364505577455, recall 0.3280732207669244,precision 0.7980040303233855,specificity 0.9720172814888667,[tp,tn,fp,fn]: [8316, 73120, 2105, 17032]

TRAIN, epoch 31, loss 0.5146623231599586, acc 0.7657436146740959,recall 0.5105557321466412,precision 0.7455132668059101,specificity 0.9049370051436167,[tp,tn,fp,fn]: [38549, 125265, 13159, 36955]
VAL, loss 0.44657351572569964, acc 0.8105754029411473,f1 0.47011375963062885, recall 0.33339908474041346,precision 0.7968882602545969,specificity 0.9713659022931206,[tp,tn,fp,fn]: [8451, 73071, 2154, 16897]

TRAIN, epoch 32, loss 0.5140514593710874, acc 0.7661923637859467,recall 0.5121582962492054,precision 0.7457476761677017,specificity 0.9047564006241692,[tp,tn,fp,fn]: [38670, 125240, 13184, 36834]
VAL, loss 0.44849038102215666, acc 0.8100782516182276,f1 0.46479307349603516, recall 0.32720530219346694,precision 0.8020500918673242,specificity 0.9727883017613825,[tp,tn,fp,fn]: [8294, 73178, 2047, 17054]

TRAIN, epoch 33, loss 0.5136550140627828, acc 0.766042780748663,recall 0.5107941301123119,precision 0.746265479876161,specificity 0.9052693174594001,[tp,tn,fp,fn]: [38567, 125311, 13113, 36937]
VAL, loss 0.44733840063414765, acc 0.8107245483380231,f1 0.46597093643045506, recall 0.3276392614801957,precision 0.8064672751990678,specificity 0.9735061482220007,[tp,tn,fp,fn]: [8305, 73232, 1993, 17043]

TRAIN, epoch 34, loss 0.5137987119265464, acc 0.7659212445308702,recall 0.5091650773468955,precision 0.7470656820831714,specificity 0.9059700629948564,[tp,tn,fp,fn]: [38444, 125408, 13016, 37060]
VAL, loss 0.44549927139094536, acc 0.8102572260944786,f1 0.4621628477213156, recall 0.3234574719899006,precision 0.8091384585019245,specificity 0.9742904619474909,[tp,tn,fp,fn]: [8199, 73291, 1934, 17149]

TRAIN, epoch 35, loss 0.5118158094515008, acc 0.7668421151041472,recall 0.5088207247298157,precision 0.7501903887836597,specificity 0.907581055308328,[tp,tn,fp,fn]: [38418, 125631, 12793, 37086]
VAL, loss 0.4468807793317905, acc 0.809988764380102,f1 0.46093088857545833, recall 0.3223133975067066,precision 0.8087507424272421,specificity 0.9743170488534397,[tp,tn,fp,fn]: [8170, 73293, 1932, 17178]

TRAIN, epoch 36, loss 0.5121960096978726, acc 0.7664494596312779,recall 0.5094299639754185,precision 0.7485161616751318,specificity 0.9066419118072011,[tp,tn,fp,fn]: [38464, 125501, 12923, 37040]
VAL, loss 0.4413023978933579, acc 0.8108538076819822,f1 0.4652104242219785, recall 0.3264162853085056,precision 0.8093514623887313,specificity 0.9740910601528747,[tp,tn,fp,fn]: [8274, 73276, 1949, 17074]

TRAIN, epoch 37, loss 0.5119893242585214, acc 0.7670664896600725,recall 0.5087809917355371,precision 0.7509236272650859,specificity 0.907949488528001,[tp,tn,fp,fn]: [38415, 125682, 12742, 37089]
VAL, loss 0.4421242413011679, acc 0.811380788084277,f1 0.4686274509803922, recall 0.3300063121350797,precision 0.8080564142194745,specificity 0.9735859089398471,[tp,tn,fp,fn]: [8365, 73238, 1987, 16983]

TRAIN, epoch 38, loss 0.5113585290406495, acc 0.7670664896600725,recall 0.5101186692095783,precision 0.7499367199517124,specificity 0.9072198462694331,[tp,tn,fp,fn]: [38516, 125581, 12843, 36988]
VAL, loss 0.44186116376993945, acc 0.8108637507084406,f1 0.46459130826390455, recall 0.3255878175792962,precision 0.8107072691552063,specificity 0.9743835161183118,[tp,tn,fp,fn]: [8253, 73298, 1927, 17095]

TRAIN, epoch 39, loss 0.5104974533461636, acc 0.7675199132418383,recall 0.5081982411527866,precision 0.7527858432080358,specificity 0.9089680980176847,[tp,tn,fp,fn]: [38371, 125823, 12601, 37133]
VAL, loss 0.4400192225865887, acc 0.8111023833434421,f1 0.4660183259317555, recall 0.32704749881647466,precision 0.8103616813294232,specificity 0.9742107012296444,[tp,tn,fp,fn]: [8290, 73285, 1940, 17058]

TRAIN, epoch 40, loss 0.5095571902899266, acc 0.7679078942447927,recall 0.5102776011866921,precision 0.7524559107864773,specificity 0.9084335086401202,[tp,tn,fp,fn]: [38528, 125749, 12675, 36976]
VAL, loss 0.4366306297028942, acc 0.8121165720421982,f1 0.47120389544971175, recall 0.3321366577244753,precision 0.8106104371269016,specificity 0.9738517779993353,[tp,tn,fp,fn]: [8419, 73258, 1967, 16929]

TRAIN, epoch 41, loss 0.5090367384108657, acc 0.7680995475113123,recall 0.5120258529349438,precision 0.7517598102127329,specificity 0.9077761081893313,[tp,tn,fp,fn]: [38660, 125658, 12766, 36844]
VAL, loss 0.43971931534650927, acc 0.811708907957404,f1 0.4700120343679159, recall 0.33126873915101784,precision 0.8087258017913898,specificity 0.9735992023928215,[tp,tn,fp,fn]: [8397, 73239, 1986, 16951]

TRAIN, epoch 42, loss 0.508920910836229, acc 0.7681182453909726,recall 0.5119066539521085,precision 0.7519064664228464,specificity 0.907870022539444,[tp,tn,fp,fn]: [38651, 125671, 12753, 36853]
VAL, loss 0.43738949541171235, acc 0.8123452616507413,f1 0.47135934567659166, recall 0.331939403503235,precision 0.8127112914131169,specificity 0.9742239946826188,[tp,tn,fp,fn]: [8414, 73286, 1939, 16934]

TRAIN, epoch 43, loss 0.5080238080814663, acc 0.7687913690587488,recall 0.5106351981351981,precision 0.7549737604762278,specificity 0.90960382592614,[tp,tn,fp,fn]: [38555, 125911, 12513, 36949]
VAL, loss 0.4371074414688359, acc 0.8128125838942858,f1 0.47524807670866315, recall 0.3363184472147704,precision 0.8097454407294833,specificity 0.9733732136922566,[tp,tn,fp,fn]: [8525, 73222, 2003, 16823]

TRAIN, epoch 44, loss 0.5091927663093061, acc 0.7685436221532478,recall 0.5103703115066751,precision 0.7543900863334704,specificity 0.9093654279604693,[tp,tn,fp,fn]: [38535, 125878, 12546, 36969]
VAL, loss 0.4348851373851819, acc 0.8132401340319967,f1 0.4768403754560901, recall 0.33769922676345276,precision 0.8109900521080057,specificity 0.9734795613160518,[tp,tn,fp,fn]: [8560, 73230, 1995, 16788]

TRAIN, epoch 45, loss 0.5081603903295411, acc 0.7690391159642497,recall 0.5115358126721763,precision 0.7550781020898907,specificity 0.9094954632144715,[tp,tn,fp,fn]: [38623, 125896, 12528, 36881]
VAL, loss 0.4391615486539547, acc 0.8117785091426128,f1 0.469480410290903, recall 0.33044027142180843,precision 0.8105283530094832,specificity 0.9739714190761051,[tp,tn,fp,fn]: [8376, 73267, 1958, 16972]

TRAIN, epoch 46, loss 0.5080481271877779, acc 0.7680855241015668,recall 0.5120655859292222,precision 0.7516865947312141,specificity 0.9077327631046639,[tp,tn,fp,fn]: [38663, 125652, 12772, 36841]
VAL, loss 0.43689413800181176, acc 0.8134489375876229,f1 0.4779342200456342, recall 0.33880385040239863,precision 0.8109537299338999,specificity 0.973386507145231,[tp,tn,fp,fn]: [8588, 73223, 2002, 16760]

TRAIN, epoch 47, loss 0.5075237348646194, acc 0.7684080625257096,recall 0.511509324009324,precision 0.7531102531102531,specificity 0.9085346471710108,[tp,tn,fp,fn]: [38621, 125763, 12661, 36883]
VAL, loss 0.43148977631904356, acc 0.8135185387728316,f1 0.4781725605854039, recall 0.33900110462363897,precision 0.8111960728783159,specificity 0.9734130940511798,[tp,tn,fp,fn]: [8593, 73225, 2000, 16755]

TRAIN, epoch 48, loss 0.5064680308113592, acc 0.7692447926405146,recall 0.5142376562831108,precision 0.75370280500825,specificity 0.9083395942900075,[tp,tn,fp,fn]: [38827, 125736, 12688, 36677]
VAL, loss 0.4341336988918605, acc 0.8135185387728316,f1 0.4781725605854039, recall 0.33900110462363897,precision 0.8111960728783159,specificity 0.9734130940511798,[tp,tn,fp,fn]: [8593, 73225, 2000, 16755]

TRAIN, epoch 49, loss 0.5073847362568168, acc 0.7688287648180696,recall 0.5129926891290527,precision 0.7533258129765054,specificity 0.908375715193897,[tp,tn,fp,fn]: [38733, 125741, 12683, 36771]
VAL, loss 0.4385310427185156, acc 0.8135682539051237,f1 0.4783261921985421, recall 0.33911945715638314,precision 0.8114026807626958,specificity 0.9734396809571286,[tp,tn,fp,fn]: [8596, 73227, 1998, 16752]

pooling_ratio 0.2, dropout0.5, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
pooling_ratio 0.2, dropout0.5, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
pooling_ratio 0.2, dropout0.5, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
pooling_ratio 0.2, dropout0.5, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
