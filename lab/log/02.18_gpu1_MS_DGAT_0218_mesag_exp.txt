pooling_ratio 0.2, dropout0.2, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
pooling_ratio 0.2, dropout0.2, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.5807092111908922, acc 0.7210463333457986,recall 0.3937142403051494,precision 0.6814055838261587,specificity 0.8995911113679709,[tp,tn,fp,fn]: [29727, 124525, 13899, 45777]
VAL, loss 0.5189994404738105, acc 0.7903811162041502,f1 0.549645390070922, recall 0.5075351112513807,precision 0.599375698844577,specificity 0.8856895978730476,[tp,tn,fp,fn]: [12865, 66626, 8599, 12483]

TRAIN, epoch 1, loss 0.5014700588131579, acc 0.7696514715231293,recall 0.6042461326552235,precision 0.7016764072593048,specificity 0.8598725654510778,[tp,tn,fp,fn]: [45623, 119027, 19397, 29881]
VAL, loss 0.3998708890917002, acc 0.8285225656985473,f1 0.6845205429334504, recall 0.7381252958813319,precision 0.6381745003069786,specificity 0.8589830508474576,[tp,tn,fp,fn]: [18710, 64617, 10608, 6638]

TRAIN, epoch 2, loss 0.45576102213996683, acc 0.8003206686361767,recall 0.6789309175672812,precision 0.7350760715258758,specificity 0.8665332601283015,[tp,tn,fp,fn]: [51262, 119949, 18475, 24242]
VAL, loss 0.3880788745350641, acc 0.8334642498483689,f1 0.6930337408133718, recall 0.7458971121982011,precision 0.6471675509156255,specificity 0.8629710867397806,[tp,tn,fp,fn]: [18907, 64917, 10308, 6441]

TRAIN, epoch 3, loss 0.44189592377775105, acc 0.8085804569761789,recall 0.6876456876456877,precision 0.74935773460728,specificity 0.8745448766109923,[tp,tn,fp,fn]: [51920, 121058, 17366, 23584]
VAL, loss 0.4041800346439336, acc 0.8424428027402981,f1 0.699806766945781, recall 0.7286570932617958,precision 0.6731540199723012,specificity 0.8807843137254902,[tp,tn,fp,fn]: [18470, 66257, 8968, 6878]

TRAIN, epoch 4, loss 0.4364678462353825, acc 0.8115487453722748,recall 0.6928639542275906,precision 0.7533806650441395,specificity 0.8762859041784662,[tp,tn,fp,fn]: [52314, 121299, 17125, 23190]
VAL, loss 0.40439885014001803, acc 0.8432979030157199,f1 0.7025629411542672, recall 0.7342985639892694,precision 0.6734568347926767,specificity 0.8800265869059488,[tp,tn,fp,fn]: [18613, 66200, 9025, 6735]

TRAIN, epoch 5, loss 0.4323013459712012, acc 0.8135868142552635,recall 0.6961617927527018,precision 0.7562912763845124,specificity 0.8776368259839334,[tp,tn,fp,fn]: [52563, 121486, 16938, 22941]
VAL, loss 0.4053221890810095, acc 0.8436856810475972,f1 0.7045757775063421, recall 0.7395849771185103,precision 0.6727311874259877,specificity 0.8787637088733798,[tp,tn,fp,fn]: [18747, 66105, 9120, 6601]

TRAIN, epoch 6, loss 0.42945309616740934, acc 0.8144188699001533,recall 0.6995920745920746,precision 0.7563179221374264,specificity 0.8770516673409235,[tp,tn,fp,fn]: [52822, 121405, 17019, 22682]
VAL, loss 0.39538348405670515, acc 0.8436160798623885,f1 0.7057987280209503, recall 0.7442796275840303,precision 0.6711013090495163,specificity 0.8770887337986042,[tp,tn,fp,fn]: [18866, 65979, 9246, 6482]

TRAIN, epoch 7, loss 0.4270341748674789, acc 0.8159147002729891,recall 0.7044792328883238,precision 0.7570702685776911,specificity 0.8766976824828064,[tp,tn,fp,fn]: [53191, 121356, 17068, 22313]
VAL, loss 0.3928703194789496, acc 0.8467183041174072,f1 0.7063954595665257, recall 0.7316159065804008,precision 0.6828558804035644,specificity 0.8855034895314058,[tp,tn,fp,fn]: [18545, 66612, 8613, 6803]

TRAIN, epoch 8, loss 0.4254827494463645, acc 0.8164803111327176,recall 0.7045057215511761,precision 0.7583616093068347,specificity 0.8775573599953765,[tp,tn,fp,fn]: [53193, 121475, 16949, 22311]
VAL, loss 0.39764829158119785, acc 0.8451671919898979,f1 0.7078095095132659, recall 0.7440823733627899,precision 0.674908752594289,specificity 0.8792289797274843,[tp,tn,fp,fn]: [18861, 66140, 9085, 6487]

TRAIN, epoch 9, loss 0.425228332824355, acc 0.8166298941700011,recall 0.7052606484424666,precision 0.7582877648667122,specificity 0.8773767554759291,[tp,tn,fp,fn]: [53250, 121450, 16974, 22254]
VAL, loss 0.39341819758007385, acc 0.843198472751136,f1 0.7081575246132207, recall 0.7548130029982641,precision 0.6669339096486335,specificity 0.8729810568295114,[tp,tn,fp,fn]: [19133, 65670, 9555, 6215]

TRAIN, epoch 10, loss 0.4232911233734181, acc 0.8174806476945514,recall 0.7084260436533164,precision 0.758494044242768,specificity 0.8769649771715887,[tp,tn,fp,fn]: [53489, 121393, 17031, 22015]
VAL, loss 0.39708712677990216, acc 0.8428405237986338,f1 0.7075670675300647, recall 0.7543790437115354,precision 0.6662253501498153,specificity 0.8726487205051512,[tp,tn,fp,fn]: [19122, 65645, 9580, 6226]

TRAIN, epoch 11, loss 0.42264798085979577, acc 0.817709696720392,recall 0.7093266581902945,precision 0.7585225260951464,specificity 0.8768277177368087,[tp,tn,fp,fn]: [53557, 121374, 17050, 21947]
VAL, loss 0.39386859076555636, acc 0.8408121464011216,f1 0.7091417774871012, recall 0.7699621271895218,precision 0.6572265625,specificity 0.8646859421734796,[tp,tn,fp,fn]: [19517, 65046, 10179, 5831]

TRAIN, epoch 12, loss 0.42170576949665395, acc 0.8179901649152986,recall 0.7092339478703115,precision 0.7592190889370932,specificity 0.8773117378489279,[tp,tn,fp,fn]: [53550, 121441, 16983, 21954]
VAL, loss 0.3948441099544725, acc 0.8429399540632178,f1 0.7101864083370028, recall 0.7635316395770869,precision 0.6638084785292907,specificity 0.8696975739448322,[tp,tn,fp,fn]: [19354, 65423, 9802, 5994]

TRAIN, epoch 13, loss 0.42110178967647577, acc 0.818551101305112,recall 0.7097372324645052,precision 0.7602320929506732,specificity 0.8779041206727157,[tp,tn,fp,fn]: [53588, 121523, 16901, 21916]
VAL, loss 0.39376459507546285, acc 0.84496833146073,f1 0.7099162790697674, recall 0.7526826574088685,precision 0.6717484684177171,specificity 0.8760651379195746,[tp,tn,fp,fn]: [19079, 65902, 9323, 6269]

TRAIN, epoch 14, loss 0.4202088839114147, acc 0.81867731199282,recall 0.7112338419156601,precision 0.7596904708012675,specificity 0.8772828411258163,[tp,tn,fp,fn]: [53701, 121437, 16987, 21803]
VAL, loss 0.39150565597607495, acc 0.8464597854294891,f1 0.7098895318253551, recall 0.7453448003787281,precision 0.6776542324246771,specificity 0.8805317381189764,[tp,tn,fp,fn]: [18893, 66238, 8987, 6455]

TRAIN, epoch 15, loss 0.41967195557306886, acc 0.8186913354025653,recall 0.7102140283958466,precision 0.7602898016475025,specificity 0.8778607755880483,[tp,tn,fp,fn]: [53624, 121517, 16907, 21880]
VAL, loss 0.38979559050570284, acc 0.8486273651974188,f1 0.7102398172820709, recall 0.7360738519804324,precision 0.6861576934392468,specificity 0.8865536723163842,[tp,tn,fp,fn]: [18658, 66691, 8534, 6690]

TRAIN, epoch 16, loss 0.41893611636993117, acc 0.8189811525373023,recall 0.7117768595041323,precision 0.7600876882822997,specificity 0.8774562214644859,[tp,tn,fp,fn]: [53742, 121461, 16963, 21762]
VAL, loss 0.3960459915280085, acc 0.8440635160530162,f1 0.7099447002903697, recall 0.7571800536531482,precision 0.6682566762995718,specificity 0.8733399800598205,[tp,tn,fp,fn]: [19193, 65697, 9528, 6155]

TRAIN, epoch 17, loss 0.4185613463327151, acc 0.8198833252309188,recall 0.7116179275270185,precision 0.7622574055158324,specificity 0.8789371785239554,[tp,tn,fp,fn]: [53730, 121666, 16758, 21774]
VAL, loss 0.3919680495190222, acc 0.845902975947819,f1 0.7107610764809078, recall 0.7512229761716901,precision 0.674435078274421,specificity 0.8778065802592223,[tp,tn,fp,fn]: [19042, 66033, 9192, 6306]

TRAIN, epoch 18, loss 0.41814953272092414, acc 0.8197617890131259,recall 0.7133264462809917,precision 0.7610213078618663,specificity 0.8778174305033809,[tp,tn,fp,fn]: [53859, 121511, 16913, 21645]
VAL, loss 0.3934579791499442, acc 0.8455350839688585,f1 0.7100543123238582, recall 0.7504339592867287,precision 0.6737983068258298,specificity 0.8775805915586573,[tp,tn,fp,fn]: [19022, 66016, 9209, 6326]

TRAIN, epoch 19, loss 0.4178944437796522, acc 0.8196309038555027,recall 0.712902627675355,precision 0.760956231621805,specificity 0.8778463272264925,[tp,tn,fp,fn]: [53827, 121515, 16909, 21677]
VAL, loss 0.3912484184788039, acc 0.8462907539796963,f1 0.7106410856340665, recall 0.7488953763610541,precision 0.6761049969726111,specificity 0.8791093386507145,[tp,tn,fp,fn]: [18983, 66131, 9094, 6365]

TRAIN, epoch 20, loss 0.4173961032846069, acc 0.8199020231105792,recall 0.7131940029667302,precision 0.7614179463250473,specificity 0.878106397734497,[tp,tn,fp,fn]: [53849, 121551, 16873, 21655]
VAL, loss 0.3891175728056324, acc 0.8492040607320056,f1 0.7094302027052918, recall 0.7303929304087108,precision 0.6896371898979364,specificity 0.8892389498172151,[tp,tn,fp,fn]: [18514, 66893, 8332, 6834]

TRAIN, epoch 21, loss 0.4170371273147387, acc 0.8196355783254179,recall 0.7116179275270185,precision 0.7616846940077402,specificity 0.8785542969427267,[tp,tn,fp,fn]: [53730, 121613, 16811, 21774]
VAL, loss 0.3897297173055746, acc 0.847394429916578,f1 0.7108624392449419, recall 0.7443190784282784,precision 0.6802841277853898,specificity 0.8821269524759057,[tp,tn,fp,fn]: [18867, 66358, 8867, 6481]

TRAIN, epoch 22, loss 0.41628197603283484, acc 0.8201076997868442,recall 0.7130483153210426,precision 0.7619735054347826,specificity 0.8785037276772814,[tp,tn,fp,fn]: [53838, 121606, 16818, 21666]
VAL, loss 0.39224169401544046, acc 0.8459228620007357,f1 0.7119381343644272, recall 0.7554442165062333,precision 0.6731702172537439,specificity 0.8764107676969093,[tp,tn,fp,fn]: [19149, 65928, 9297, 6199]

TRAIN, epoch 23, loss 0.41639047028693776, acc 0.819556112336861,recall 0.7120152574698029,precision 0.7612789940241864,specificity 0.8782147604461654,[tp,tn,fp,fn]: [53760, 121566, 16858, 21744]
VAL, loss 0.38751299646239057, acc 0.8492736619172143,f1 0.7112956367722398, recall 0.7367050654884014,precision 0.6875805442026585,specificity 0.8872050515121302,[tp,tn,fp,fn]: [18674, 66740, 8485, 6674]

TRAIN, epoch 24, loss 0.4165500627843093, acc 0.8206172170075914,recall 0.7131542699724518,precision 0.7630911384153168,specificity 0.8792333699358493,[tp,tn,fp,fn]: [53846, 121707, 16717, 21658]
VAL, loss 0.39015623766256213, acc 0.846181380688654,f1 0.7117033171822587, recall 0.7533138709168377,precision 0.6744489968917773,specificity 0.8774742439348621,[tp,tn,fp,fn]: [19095, 66008, 9217, 6253]

TRAIN, epoch 25, loss 0.41584254109793933, acc 0.8205704723084403,recall 0.7122668997668997,precision 0.76348329760502,specificity 0.8796451482401896,[tp,tn,fp,fn]: [53779, 121764, 16660, 21725]
VAL, loss 0.38741684241573665, acc 0.8477921509749138,f1 0.7114093959731544, recall 0.7443585292725264,precision 0.6812536106296938,specificity 0.8826453971419076,[tp,tn,fp,fn]: [18868, 66397, 8828, 6480]

TRAIN, epoch 26, loss 0.41568706508800135, acc 0.8204302382109869,recall 0.7110881542699724,precision 0.7638246717218421,specificity 0.8800713749060857,[tp,tn,fp,fn]: [53690, 121823, 16601, 21814]
VAL, loss 0.3859326316529208, acc 0.848100384795124,f1 0.7100753420757974, recall 0.7380463941928357,precision 0.6841470104223807,specificity 0.8851844466600199,[tp,tn,fp,fn]: [18708, 66588, 8637, 6640]

TRAIN, epoch 27, loss 0.41483185324368066, acc 0.8207340787554691,recall 0.7115252172070354,precision 0.7642832754794286,specificity 0.8803025486909785,[tp,tn,fp,fn]: [53723, 121855, 16569, 21781]
VAL, loss 0.3890759191739881, acc 0.8479015242659561,f1 0.7109574287171929, recall 0.7421887328388828,precision 0.6822484134179511,specificity 0.8835227650382187,[tp,tn,fp,fn]: [18813, 66463, 8762, 6535]

TRAIN, epoch 28, loss 0.41449270047672865, acc 0.8207434276952994,recall 0.7124258317440135,precision 0.7637946213046318,specificity 0.879825752759637,[tp,tn,fp,fn]: [53791, 121789, 16635, 21713]
VAL, loss 0.389021490147887, acc 0.8490052002028378,f1 0.7101687151690969, recall 0.7339829572352848,precision 0.6878512274475007,specificity 0.8877633765370555,[tp,tn,fp,fn]: [18605, 66782, 8443, 6743]

TRAIN, epoch 29, loss 0.41450133122639443, acc 0.8205470999588647,recall 0.7093001695274422,precision 0.7651151494371107,specificity 0.8812272438305496,[tp,tn,fp,fn]: [53555, 121983, 16441, 21949]
VAL, loss 0.38647973235534056, acc 0.8474739741282451,f1 0.7114697362976339, recall 0.7461338172636894,precision 0.679883528650514,specificity 0.881621801262878,[tp,tn,fp,fn]: [18913, 66320, 8905, 6435]

TRAIN, epoch 30, loss 0.414274309606596, acc 0.8207013574660633,recall 0.709896164441619,precision 0.7651349692375773,specificity 0.8811405536612148,[tp,tn,fp,fn]: [53600, 121971, 16453, 21904]
VAL, loss 0.38648232028846763, acc 0.8491046304674217,f1 0.710525311868157, recall 0.7347719741202462,precision 0.6878277568505798,specificity 0.8876304420073114,[tp,tn,fp,fn]: [18625, 66772, 8453, 6723]

TRAIN, epoch 31, loss 0.41398958317794204, acc 0.8208415915635167,recall 0.7094193685102776,precision 0.7657360152106475,specificity 0.8816173495925562,[tp,tn,fp,fn]: [53564, 122037, 16387, 21940]
VAL, loss 0.3868906597185769, acc 0.8486472512503356,f1 0.7119009766068589, recall 0.7419520277733943,precision 0.6841894644935972,specificity 0.8845995347291459,[tp,tn,fp,fn]: [18807, 66544, 8681, 6541]

TRAIN, epoch 32, loss 0.41402387706393823, acc 0.8210285703601211,recall 0.7109821996185632,precision 0.7652786291644689,specificity 0.88105386349188,[tp,tn,fp,fn]: [53682, 121959, 16465, 21822]
VAL, loss 0.38582891396112956, acc 0.85103357760035,f1 0.7103920204128973, recall 0.7249092630582294,precision 0.6964448150394178,specificity 0.8935327351279495,[tp,tn,fp,fn]: [18375, 67216, 8009, 6973]

TRAIN, epoch 33, loss 0.4136166953277331, acc 0.8210612916495269,recall 0.7113530408984955,precision 0.7651433130092883,specificity 0.8809021556955441,[tp,tn,fp,fn]: [53710, 121938, 16486, 21794]
VAL, loss 0.3792962903564157, acc 0.8513318683941018,f1 0.7101426799007444, recall 0.7225816632475935,precision 0.6981247141332521,specificity 0.8947158524426719,[tp,tn,fp,fn]: [18316, 67305, 7920, 7032]

TRAIN, epoch 34, loss 0.4132268427844037, acc 0.8215474365206985,recall 0.7096842551388006,precision 0.7672394043528065,specificity 0.882563717274461,[tp,tn,fp,fn]: [53584, 122168, 16256, 21920]
VAL, loss 0.3811880895475887, acc 0.8495818957374246,f1 0.7112426035502959, recall 0.7350086791857345,precision 0.688965313216478,specificity 0.8881887670322366,[tp,tn,fp,fn]: [18631, 66814, 8411, 6717]

TRAIN, epoch 35, loss 0.4134862846334248, acc 0.8207854979245354,recall 0.7111543759271032,precision 0.7646137415450338,specificity 0.8805842917413166,[tp,tn,fp,fn]: [53695, 121894, 16530, 21809]
VAL, loss 0.3824758787326807, acc 0.8510136915474332,f1 0.7109456383348123, recall 0.726960706959129,precision 0.6956209890524726,specificity 0.8928148886673314,[tp,tn,fp,fn]: [18427, 67162, 8063, 6921]

TRAIN, epoch 36, loss 0.41310420917780816, acc 0.8211501065779141,recall 0.7101345624072897,precision 0.766048033374766,specificity 0.881704039761891,[tp,tn,fp,fn]: [53618, 122049, 16375, 21886]
VAL, loss 0.3780129619520794, acc 0.8525548606484842,f1 0.7090013540297101, recall 0.7126795013413287,precision 0.7053609777048925,specificity 0.8996876038551014,[tp,tn,fp,fn]: [18065, 67679, 7546, 7283]

TRAIN, epoch 37, loss 0.412513084093058, acc 0.8213230619647732,recall 0.710425937698665,precision 0.7662857142857142,specificity 0.8818124024735595,[tp,tn,fp,fn]: [53640, 122064, 16360, 21864]
VAL, loss 0.38153091920407967, acc 0.8503872808805544,f1 0.7113174606219903, recall 0.7313397506706644,precision 0.6923622782446311,specificity 0.8905018278497839,[tp,tn,fp,fn]: [18538, 66988, 8237, 6810]

TRAIN, epoch 38, loss 0.412758544328695, acc 0.8217016940278973,recall 0.7115119728756092,precision 0.7665482356634277,specificity 0.8818051782927816,[tp,tn,fp,fn]: [53722, 122063, 16361, 21782]
VAL, loss 0.3816116109844355, acc 0.8509242043093077,f1 0.7111453617185242, recall 0.7281047814423228,precision 0.694958014836013,specificity 0.8923097374543038,[tp,tn,fp,fn]: [18456, 67124, 8101, 6892]

TRAIN, epoch 39, loss 0.41257743227656146, acc 0.8210285703601211,recall 0.7109689552871371,precision 0.7652861928861644,specificity 0.8810610876726579,[tp,tn,fp,fn]: [53681, 121960, 16464, 21823]
VAL, loss 0.38458794356414777, acc 0.8495520666580494,f1 0.711444209241566, recall 0.735876597759192,precision 0.6885820812876076,specificity 0.8878564307078763,[tp,tn,fp,fn]: [18653, 66789, 8436, 6695]

TRAIN, epoch 40, loss nan, acc 0.7477843012602371,recall 0.41007098961644417,precision 0.7668416881315633,specificity 0.9319915621568514,[tp,tn,fp,fn]: [30962, 129010, 9414, 44542]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 41, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 42, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 43, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 44, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 45, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 46, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 47, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 48, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

pooling_ratio 0.2, dropout0.4, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.6012960190833816, acc 0.7044285927975767,recall 0.3322340538249629,precision 0.6619257461012745,specificity 0.907443795873548,[tp,tn,fp,fn]: [25085, 125612, 12812, 50419]
VAL, loss 0.5428051587958019, acc 0.7850615970489098,f1 0.4814201751229458, recall 0.39584977118510334,precision 0.6141886515272081,specificity 0.9162113659022931,[tp,tn,fp,fn]: [10034, 68922, 6303, 15314]

TRAIN, epoch 1, loss 0.5808007380715492, acc 0.7240333196215549,recall 0.40691883873702056,precision 0.6830439518907984,specificity 0.8970048546494828,[tp,tn,fp,fn]: [30724, 124167, 14257, 44780]
VAL, loss 0.5376521346342621, acc 0.787974903801219,f1 0.48695986911750555, recall 0.3992425437904371,precision 0.6240749876665023,specificity 0.918963110667996,[tp,tn,fp,fn]: [10120, 69129, 6096, 15228]

TRAIN, epoch 2, loss 0.5727274162750327, acc 0.7291705620582626,recall 0.4359636575545666,precision 0.681963205436314,specificity 0.8891016008784604,[tp,tn,fp,fn]: [32917, 123073, 15351, 42587]
VAL, loss 0.5273179426405098, acc 0.7920515446491603,f1 0.5119936531640844, recall 0.43281521224554204,precision 0.6266278272789582,specificity 0.9131006979062811,[tp,tn,fp,fn]: [10971, 68688, 6537, 14377]

TRAIN, epoch 3, loss 0.5254927407468847, acc 0.7524167009461127,recall 0.5437195380377199,precision 0.6891903235012675,specificity 0.8662515170779633,[tp,tn,fp,fn]: [41053, 119910, 18514, 34451]
VAL, loss 0.43438403862475394, acc 0.8197826454416195,f1 0.520058254998014, recall 0.387407290516017,precision 0.7908512523153741,specificity 0.9654769026254569,[tp,tn,fp,fn]: [9820, 72628, 2597, 15528]

TRAIN, epoch 4, loss 0.46435580793878917, acc 0.7946879323884671,recall 0.6460319983047256,precision 0.7393518658865613,specificity 0.8757729873432353,[tp,tn,fp,fn]: [48778, 121228, 17196, 26726]
VAL, loss 0.40935358992815146, acc 0.8324500611496127,f1 0.5743299568040012, recall 0.44847719741202463,precision 0.7983706720977597,specificity 0.9618344965104686,[tp,tn,fp,fn]: [11368, 72354, 2871, 13980]

TRAIN, epoch 5, loss 0.4447483677605248, acc 0.8075146778355334,recall 0.6795269124814579,precision 0.7513325913776945,specificity 0.8773261862104837,[tp,tn,fp,fn]: [51307, 121443, 16981, 24197]
VAL, loss 0.3982258976627716, acc 0.8378292384636036,f1 0.5989672977624784, recall 0.48051128294145495,precision 0.7949353870251925,specificity 0.9582319707544035,[tp,tn,fp,fn]: [12180, 72083, 3142, 13168]

TRAIN, epoch 6, loss 0.435289050801557, acc 0.8125350585243634,recall 0.69228120364484,precision 0.7560023141452126,specificity 0.8781280702768306,[tp,tn,fp,fn]: [52270, 121554, 16870, 23234]
VAL, loss 0.38682643803998484, acc 0.8432382448569695,f1 0.6280551099367746, recall 0.5251301877860186,precision 0.7811619718309859,specificity 0.9504287138584248,[tp,tn,fp,fn]: [13311, 71496, 3729, 12037]

TRAIN, epoch 7, loss 0.43018191720614557, acc 0.8158025129950264,recall 0.7010092180546726,precision 0.7587408076377241,specificity 0.8784170375079466,[tp,tn,fp,fn]: [52929, 121594, 16830, 22575]
VAL, loss 0.3809479510279626, acc 0.8453561094926073,f1 0.6389991411925818, recall 0.543040871074641,precision 0.7761488581900198,specificity 0.9472249916915919,[tp,tn,fp,fn]: [13765, 71255, 3970, 11583]

TRAIN, epoch 8, loss 0.42684398827398196, acc 0.8166906622788975,recall 0.7051282051282052,precision 0.7585018022253566,specificity 0.8775429116338207,[tp,tn,fp,fn]: [53240, 121473, 16951, 22264]
VAL, loss 0.38027423772416663, acc 0.8458930329213606,f1 0.640819447984983, recall 0.5454473725737731,precision 0.776610683592653,specificity 0.9471319375207711,[tp,tn,fp,fn]: [13826, 71248, 3977, 11522]

TRAIN, epoch 9, loss 0.424962379909579, acc 0.817293668897947,recall 0.7084392879847425,precision 0.758056744423344,specificity 0.8766687857596949,[tp,tn,fp,fn]: [53490, 121352, 17072, 22014]
VAL, loss 0.37399181480585714, acc 0.8488063396736699,f1 0.6573064094473992, recall 0.5753116616695597,precision 0.7665580319596299,specificity 0.9409637753406447,[tp,tn,fp,fn]: [14583, 70784, 4441, 10765]

TRAIN, epoch 10, loss 0.4230097584764369, acc 0.8180088627949591,recall 0.711313307904217,precision 0.758113010459749,specificity 0.8762064381899093,[tp,tn,fp,fn]: [53707, 121288, 17136, 21797]
VAL, loss 0.36830095378533206, acc 0.84936314915534,f1 0.6613919806892852, recall 0.583714691494398,precision 0.7629163658863566,specificity 0.9388767032236623,[tp,tn,fp,fn]: [14796, 70627, 4598, 10552]

TRAIN, epoch 11, loss 0.4221675073368058, acc 0.8184996821360457,recall 0.7120549904640814,precision 0.7588285109386027,specificity 0.8765604230480264,[tp,tn,fp,fn]: [53763, 121337, 17087, 21741]
VAL, loss 0.36896062888130304, acc 0.8497608702136756,f1 0.6649518825668544, recall 0.5915259586555153,precision 0.7591898734177215,specificity 0.9367763376537056,[tp,tn,fp,fn]: [14994, 70469, 4756, 10354]

TRAIN, epoch 12, loss 0.4211074308679302, acc 0.8192055270932276,recall 0.7146111464293282,precision 0.7590349581486953,specificity 0.8762570074553545,[tp,tn,fp,fn]: [53956, 121295, 17129, 21548]
VAL, loss 0.3683744061506341, acc 0.8510435206268084,f1 0.6729253542344388, recall 0.6079769607069592,precision 0.7534099242239062,specificity 0.9329478231970755,[tp,tn,fp,fn]: [15411, 70181, 5044, 9937]

pooling_ratio 0.2, dropout0.4, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.6484541711255896, acc 0.6486948879997009,recall 0.008277707141343505,precision 0.6944444444444444,specificity 0.9980133502860775,[tp,tn,fp,fn]: [625, 138149, 275, 74879]
VAL, loss 0.5680171583273171, acc 0.7689538941863124,f1 0.309839912085301, recall 0.205775603597917,precision 0.6268477346472779,specificity 0.9587238285144566,[tp,tn,fp,fn]: [5216, 72120, 3105, 20132]

TRAIN, epoch 1, loss 0.6287055019642963, acc 0.6684118021016416,recall 0.11118616232252596,precision 0.6868761250204549,specificity 0.9723530601629775,[tp,tn,fp,fn]: [8395, 134597, 3827, 67109]
VAL, loss 0.5401615032674011, acc 0.7683771986517256,f1 0.3727280071088134, recall 0.2730392930408711,precision 0.5870726948850623,specificity 0.9352874709205716,[tp,tn,fp,fn]: [6921, 70357, 4868, 18427]

pooling_ratio 0.2, dropout0.4, hidden_dim 128, outdim 256
epochs 50, lr 0.0001, weight_decay 0.001
TRAIN, epoch 0, loss 0.5503828104202725, acc 0.7408988070752777,recall 0.45759165077346897,precision 0.704742478327384,specificity 0.8954299832399006,[tp,tn,fp,fn]: [34550, 123949, 14475, 40954]
VAL, loss 0.4023738563679784, acc 0.8365664741033876,f1 0.6017107271802078, recall 0.48982168218399874,precision 0.7798505119025186,specificity 0.9534064473246926,[tp,tn,fp,fn]: [12416, 71720, 3505, 12932]

TRAIN, epoch 1, loss 0.44352205441994064, acc 0.8090993231367563,recall 0.6926652892561983,precision 0.747844365321093,specificity 0.8726087961625152,[tp,tn,fp,fn]: [52299, 120790, 17634, 23205]
VAL, loss 0.38146371105812044, acc 0.851133007864934,f1 0.6824063467820627, recall 0.6345668297301562,precision 0.7380471689455813,specificity 0.9241076769690927,[tp,tn,fp,fn]: [16085, 69516, 5709, 9263]

TRAIN, epoch 2, loss 0.43422566117949163, acc 0.8128342245989305,recall 0.710690824327188,precision 0.746771320418615,specificity 0.8685488065653355,[tp,tn,fp,fn]: [53660, 120228, 18196, 21844]
VAL, loss 0.41227563066525474, acc 0.8510534636532667,f1 0.6771551724137932, recall 0.6197727631371311,precision 0.7462473874216227,specificity 0.9289863742107012,[tp,tn,fp,fn]: [15710, 69883, 5342, 9638]

TRAIN, epoch 3, loss 0.429030443685787, acc 0.814115029355671,recall 0.7108894892985802,precision 0.7495252192369994,specificity 0.8704198693868115,[tp,tn,fp,fn]: [53675, 120487, 17937, 21829]
VAL, loss 0.40518867276067333, acc 0.8528432084157775,f1 0.6879217273954116, recall 0.6435221713744674,precision 0.7389019749954702,specificity 0.9233765370555002,[tp,tn,fp,fn]: [16312, 69461, 5764, 9036]

TRAIN, epoch 4, loss nan, acc 0.727721476384578,recall 0.34162428480610296,precision 0.7513107305138064,specificity 0.9383199445182916,[tp,tn,fp,fn]: [25794, 129886, 8538, 49710]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

pooling_ratio 0.2, dropout0.4, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.6151002050805772, acc 0.689320706031936,recall 0.2945009535918627,precision 0.6275860122491603,specificity 0.9046769346356123,[tp,tn,fp,fn]: [22236, 125229, 13195, 53268]
VAL, loss 0.5731185302515402, acc 0.7817207401588896,f1 0.46969587168152277, recall 0.38354110777970646,precision 0.6057698298959436,specificity 0.9158923230309073,[tp,tn,fp,fn]: [9722, 68898, 6327, 15626]

TRAIN, epoch 1, loss 0.5903305402445252, acc 0.7183818854941849,recall 0.3847080949353677,precision 0.6780978616117285,specificity 0.9003857712535398,[tp,tn,fp,fn]: [29047, 124635, 13789, 46457]
VAL, loss 0.5676198331100692, acc 0.7796724767084605,f1 0.47100670820501805, recall 0.3891825785071801,precision 0.5963968321141406,specificity 0.9112529079428382,[tp,tn,fp,fn]: [9865, 68549, 6676, 15483]

TRAIN, epoch 2, loss 0.583174221698252, acc 0.7234209640626753,recall 0.4071439923712651,precision 0.6809241128782173,specificity 0.8959356758943536,[tp,tn,fp,fn]: [30741, 124019, 14405, 44763]
VAL, loss 0.5511114158842113, acc 0.7852007994193273,f1 0.4741364621114384, recall 0.38421177213192365,precision 0.6190173520625437,specificity 0.9203190428713859,[tp,tn,fp,fn]: [9739, 69231, 5994, 15609]

TRAIN, epoch 3, loss 0.5782525504737851, acc 0.7261228076736098,recall 0.4222160415342234,precision 0.6805353940739476,specificity 0.8918901346587297,[tp,tn,fp,fn]: [31879, 123459, 14965, 43625]
VAL, loss 0.5531287608544881, acc 0.788810118023724,f1 0.48757539203860073, recall 0.3986507811267161,precision 0.6275617935660166,specificity 0.9202791625124627,[tp,tn,fp,fn]: [10105, 69228, 5997, 15243]

TRAIN, epoch 4, loss 0.5187369872528614, acc 0.7588955162484574,recall 0.5546858444585717,precision 0.6999181108678577,specificity 0.8702826099520314,[tp,tn,fp,fn]: [41881, 120468, 17956, 33623]
VAL, loss 0.43677036448286843, acc 0.8208465492726676,f1 0.5186728642410643, recall 0.38298879596023355,precision 0.8032434221413205,specificity 0.9683881688268527,[tp,tn,fp,fn]: [9708, 72847, 2378, 15640]

TRAIN, epoch 5, loss 0.45477584683789457, acc 0.80088160502599,recall 0.6700042381860564,precision 0.7410098287656184,specificity 0.8722692596659539,[tp,tn,fp,fn]: [50588, 120743, 17681, 24916]
VAL, loss 0.4063601892558893, acc 0.8292285205770933,f1 0.5556159279670884, recall 0.4235837146914944,precision 0.8072325389068491,specificity 0.9659155865736125,[tp,tn,fp,fn]: [10737, 72661, 2564, 14611]

TRAIN, epoch 6, loss 0.4396414861302026, acc 0.8097257021053812,recall 0.6920692943420216,precision 0.749601916538754,specificity 0.8739019245217592,[tp,tn,fp,fn]: [52254, 120969, 17455, 23250]
VAL, loss 0.39553793699152884, acc 0.8357014308015074,f1 0.5907672494922978, recall 0.47053021934669403,precision 0.7935462408516301,specificity 0.9587504154204054,[tp,tn,fp,fn]: [11927, 72122, 3103, 13421]

TRAIN, epoch 7, loss 0.4337228853853847, acc 0.8122873116188625,recall 0.6993934096206823,precision 0.7515192053168628,specificity 0.8738658036178697,[tp,tn,fp,fn]: [52807, 120964, 17460, 22697]
VAL, loss 0.3892231503125183, acc 0.8432680739363447,f1 0.635781787934102, recall 0.5427647151649045,precision 0.7672745524510624,specificity 0.9445264207377866,[tp,tn,fp,fn]: [13758, 71052, 4173, 11590]

TRAIN, epoch 8, loss 0.4306994736348409, acc 0.8138439101005946,recall 0.7036183513456241,precision 0.752791475372669,specificity 0.8739669421487604,[tp,tn,fp,fn]: [53126, 120978, 17446, 22378]
VAL, loss 0.39347855533065906, acc 0.8453660525190657,f1 0.6473949122568358, recall 0.5632397033296512,precision 0.7611152574901375,specificity 0.9404320372216683,[tp,tn,fp,fn]: [14277, 70744, 4481, 11071]

TRAIN, epoch 9, loss 0.4284632408620264, acc 0.8150919935679294,recall 0.7050884721339267,precision 0.7548456619450706,specificity 0.8750939143501127,[tp,tn,fp,fn]: [53237, 121134, 17290, 22267]
VAL, loss 0.384706651486067, acc 0.8470961391228262,f1 0.6519554589896795, recall 0.5682105097049077,precision 0.7646527925249522,specificity 0.94107012296444,[tp,tn,fp,fn]: [14403, 70792, 4433, 10945]

TRAIN, epoch 10, loss 0.4256408798757467, acc 0.8159801428518006,recall 0.7072737868192414,precision 0.7556851146928553,specificity 0.8752745188695602,[tp,tn,fp,fn]: [53402, 121159, 17265, 22102]
VAL, loss 0.38700118554368246, acc 0.8484185616417925,f1 0.6594133285672796, recall 0.5822155594129714,precision 0.7602122289187657,specificity 0.938118976404121,[tp,tn,fp,fn]: [14758, 70570, 4655, 10590]

TRAIN, epoch 11, loss 0.4244725040486558, acc 0.8167701282674544,recall 0.7074592074592074,precision 0.75739443609449,specificity 0.8763942668901347,[tp,tn,fp,fn]: [53416, 121314, 17110, 22088]
VAL, loss 0.37886699963756876, acc 0.8495222375786742,f1 0.6620064320171519, recall 0.5847009626005997,precision 0.7628680255301626,specificity 0.9387570621468927,[tp,tn,fp,fn]: [14821, 70618, 4607, 10527]

TRAIN, epoch 12, loss 0.4230079573088169, acc 0.8176536030814106,recall 0.7105451366815003,precision 0.7577221304182026,specificity 0.876076402935907,[tp,tn,fp,fn]: [53649, 121270, 17154, 21855]
VAL, loss 0.3768187541103743, acc 0.8506259135155558,f1 0.6695554626839407, recall 0.6004418494555783,precision 0.7566492667163808,specificity 0.9349285476902626,[tp,tn,fp,fn]: [15220, 70330, 4895, 10128]

TRAIN, epoch 13, loss 0.4217146691916336, acc 0.8177751392992034,recall 0.7112470862470862,precision 0.7576146607790303,specificity 0.8758813500549038,[tp,tn,fp,fn]: [53702, 121243, 17181, 21802]
VAL, loss 0.3804048710761478, acc 0.8511230648384756,f1 0.6738263805685656, recall 0.6101467571406028,precision 0.7523471323636718,specificity 0.9323230309072782,[tp,tn,fp,fn]: [15466, 70134, 5091, 9882]

TRAIN, epoch 14, loss 0.4212420350335253, acc 0.8184342395572342,recall 0.7124125874125874,precision 0.7584816266674187,specificity 0.8762642316361324,[tp,tn,fp,fn]: [53790, 121296, 17128, 21714]
VAL, loss 0.3841498587973728, acc 0.8522963419605659,f1 0.6828362192283878, recall 0.630858450370838,precision 0.7441481688305644,specificity 0.9269125955466933,[tp,tn,fp,fn]: [15991, 69727, 5498, 9357]

TRAIN, epoch 15, loss 0.41964315061263224, acc 0.8190325717063685,recall 0.7149687433778343,precision 0.7584438574800495,specificity 0.8757946598855689,[tp,tn,fp,fn]: [53983, 121231, 17193, 21521]
VAL, loss 0.38482840028586035, acc 0.8514810137909777,f1 0.6743126267361489, recall 0.6100284046078586,precision 0.7537411650012186,specificity 0.9328414755732801,[tp,tn,fp,fn]: [15463, 70173, 5052, 9885]

TRAIN, epoch 16, loss 0.41940476610542776, acc 0.8188876631390001,recall 0.7142270608179699,precision 0.7585202897531472,specificity 0.8759752644050165,[tp,tn,fp,fn]: [53927, 121256, 17168, 21577]
VAL, loss 0.3843315608534469, acc 0.8527338351247352,f1 0.6826236955450319, recall 0.6283730471832097,precision 0.7471269759369576,specificity 0.9283349950149551,[tp,tn,fp,fn]: [15928, 69834, 5391, 9420]

TRAIN, epoch 17, loss 0.4187169329526113, acc 0.8191728058038219,recall 0.7144257257893621,precision 0.7590622537431048,specificity 0.8763075767207998,[tp,tn,fp,fn]: [53942, 121302, 17122, 21562]
VAL, loss 0.3846754490865148, acc 0.8534199039503644,f1 0.6879471656576774, recall 0.6410762190310872,precision 0.7422124783045583,specificity 0.9249717514124294,[tp,tn,fp,fn]: [16250, 69581, 5644, 9098]

TRAIN, epoch 18, loss 0.4178712599622807, acc 0.8196309038555027,recall 0.7152866073320618,precision 0.7596348599077304,specificity 0.8765459746864706,[tp,tn,fp,fn]: [54007, 121335, 17089, 21497]
VAL, loss 0.37898805891488263, acc 0.8522267407753572,f1 0.6773058884835852, recall 0.6153148177370996,precision 0.7531871740390187,specificity 0.93205716184779,[tp,tn,fp,fn]: [15597, 70114, 5111, 9751]

TRAIN, epoch 19, loss 0.418079221655635, acc 0.8198786507610037,recall 0.7148363000635728,precision 0.7604508629799225,specificity 0.8771744784141479,[tp,tn,fp,fn]: [53973, 121422, 17002, 21531]
VAL, loss 0.3775238064277514, acc 0.8530619549978623,f1 0.6855878473256457, recall 0.6356320025248541,precision 0.7440657615221207,specificity 0.9263276836158192,[tp,tn,fp,fn]: [16112, 69683, 5542, 9236]

TRAIN, epoch 20, loss 0.4178921499269616, acc 0.8196122059758424,recall 0.715127675354948,precision 0.7596797793910743,specificity 0.8766037681326938,[tp,tn,fp,fn]: [53995, 121343, 17081, 21509]
VAL, loss 0.3832559392039767, acc 0.8539866564584928,f1 0.6950472432769182, recall 0.6602098784913997,precision 0.73376594905073,specificity 0.9192821535393818,[tp,tn,fp,fn]: [16735, 69153, 6072, 8613]

TRAIN, epoch 21, loss 0.41654036264604827, acc 0.8200001869787966,recall 0.7173527230345412,precision 0.759340520685836,specificity 0.8759897127665722,[tp,tn,fp,fn]: [54163, 121258, 17166, 21341]
VAL, loss 0.3837284659256109, acc 0.8535193342149483,f1 0.6870858113848768, recall 0.6380779548682342,precision 0.744248113381189,specificity 0.9261149883682287,[tp,tn,fp,fn]: [16174, 69667, 5558, 9174]

TRAIN, epoch 22, loss 0.4165665278045666, acc 0.8202993530533638,recall 0.7155779826234372,precision 0.7610039860839191,specificity 0.8774201005605964,[tp,tn,fp,fn]: [54029, 121456, 16968, 21475]
VAL, loss 0.3775148328828592, acc 0.853638650532449,f1 0.6900922144090277, recall 0.6465598863815686,precision 0.7399097065462754,specificity 0.9234164174144234,[tp,tn,fp,fn]: [16389, 69464, 5761, 8959]

TRAIN, epoch 23, loss 0.4163664437183771, acc 0.8198973486406641,recall 0.7158561135833863,precision 0.7599297012302285,specificity 0.8766471132173611,[tp,tn,fp,fn]: [54050, 121349, 17075, 21454]
VAL, loss 0.3818796856965148, acc 0.8542849472522447,f1 0.6971293942587885, recall 0.6653779390878964,precision 0.7320630235687313,specificity 0.9179395147889664,[tp,tn,fp,fn]: [16866, 69052, 6173, 8482]

TRAIN, epoch 24, loss 0.4161475464684378, acc 0.819934744399985,recall 0.7159488239033693,precision 0.7599640100659347,specificity 0.876654337398139,[tp,tn,fp,fn]: [54057, 121350, 17074, 21447]
VAL, loss 0.37723062108455147, acc 0.8540761436966183,f1 0.6949363931154902, recall 0.6594603124506865,precision 0.7344463971880492,specificity 0.9196543702226654,[tp,tn,fp,fn]: [16716, 69181, 6044, 8632]

TRAIN, epoch 25, loss 0.415424146380868, acc 0.8204302382109869,recall 0.7156574486119941,precision 0.761260055507812,specificity 0.8775790325377102,[tp,tn,fp,fn]: [54035, 121478, 16946, 21469]
VAL, loss 0.38106147060870377, acc 0.8542451751464111,f1 0.6924190604083174, recall 0.650938930093104,precision 0.7395455156649187,specificity 0.9227517447657029,[tp,tn,fp,fn]: [16500, 69414, 5811, 8848]

TRAIN, epoch 26, loss 0.4154612157590093, acc 0.82014042107625,recall 0.7163991311718585,precision 0.7601855105052351,specificity 0.876726579205918,[tp,tn,fp,fn]: [54091, 121360, 17064, 21413]
VAL, loss 0.37651393402487804, acc 0.8537977389557834,f1 0.695531536008614, recall 0.6625769291462837,precision 0.7319358493855138,specificity 0.9182319707544034,[tp,tn,fp,fn]: [16795, 69074, 6151, 8553]

TRAIN, epoch 27, loss 0.41536595185146, acc 0.8201824913054859,recall 0.7162004662004662,precision 0.7603914730862253,specificity 0.8768999595445877,[tp,tn,fp,fn]: [54076, 121384, 17040, 21428]
VAL, loss 0.3822793250405531, acc 0.8541755739612024,f1 0.6957892553412156, recall 0.6616695597285782,precision 0.7336191059399878,specificity 0.9190428713858425,[tp,tn,fp,fn]: [16772, 69135, 6090, 8576]

TRAIN, epoch 28, loss 0.415054872370681, acc 0.820434912680902,recall 0.716001801229074,precision 0.7610795134587228,specificity 0.8773984280182627,[tp,tn,fp,fn]: [54061, 121453, 16971, 21443]
VAL, loss 0.37737074950139793, acc 0.8541059727759935,f1 0.6931426061860845, recall 0.6537793908789649,precision 0.7375495126618897,specificity 0.9216085078099037,[tp,tn,fp,fn]: [16572, 69328, 5897, 8776]

TRAIN, epoch 29, loss 0.4144889671521404, acc 0.8203601211622602,recall 0.7156309599491417,precision 0.7611139283299526,specificity 0.8774851181875976,[tp,tn,fp,fn]: [54033, 121465, 16959, 21471]
VAL, loss 0.37708398547286265, acc 0.8545036938343293,f1 0.6976465483397731, recall 0.6660091525958656,precision 0.7324395852314634,specificity 0.918019275506813,[tp,tn,fp,fn]: [16882, 69058, 6167, 8466]

TRAIN, epoch 30, loss 0.4139089752559124, acc 0.8208041958041958,recall 0.7169421487603306,precision 0.7614037555383641,specificity 0.8774562214644859,[tp,tn,fp,fn]: [54132, 121461, 16963, 21372]
VAL, loss 0.37656846584977466, acc 0.8544142065962037,f1 0.694066025908901, recall 0.6552390721161433,precision 0.7377842928216063,specificity 0.9215287470920571,[tp,tn,fp,fn]: [16609, 69322, 5903, 8739]

TRAIN, epoch 31, loss 0.4141238636928348, acc 0.8205470999588647,recall 0.7157104259376986,precision 0.7614987881179189,specificity 0.8777307403340461,[tp,tn,fp,fn]: [54039, 121499, 16925, 21465]
VAL, loss 0.3795518962498024, acc 0.8548218706809979,f1 0.6937773956083135, recall 0.6525169638630267,precision 0.7406080687771459,specificity 0.9229910269192423,[tp,tn,fp,fn]: [16540, 69432, 5793, 8808]

TRAIN, epoch 32, loss 0.41426119390553434, acc 0.820977151191055,recall 0.715472027972028,precision 0.7626207013383025,specificity 0.8785254002196151,[tp,tn,fp,fn]: [54021, 121609, 16815, 21483]
VAL, loss 0.3724079499295996, acc 0.854573295019538,f1 0.6955833992423927, recall 0.659223607385198,precision 0.7361882104150146,specificity 0.9203988035892323,[tp,tn,fp,fn]: [16710, 69237, 5988, 8638]

TRAIN, epoch 33, loss 0.4135770375530854, acc 0.8210285703601211,recall 0.7166640178003815,precision 0.7620730934441237,specificity 0.8779546899381611,[tp,tn,fp,fn]: [54111, 121530, 16894, 21393]
VAL, loss 0.37191766888955463, acc 0.8545832380459965,f1 0.6950393060449985, recall 0.6574877702382831,precision 0.7371400769605024,specificity 0.9209970089730808,[tp,tn,fp,fn]: [16666, 69282, 5943, 8682]

TRAIN, epoch 34, loss 0.41352503344559827, acc 0.8210472682397816,recall 0.7166772621318076,precision 0.7621086432967621,specificity 0.8779763624804947,[tp,tn,fp,fn]: [54112, 121533, 16891, 21392]
VAL, loss 0.3798810159254613, acc 0.8547622125222475,f1 0.6953765302079207, recall 0.6577244753037715,precision 0.7376012033800823,specificity 0.9211565304087737,[tp,tn,fp,fn]: [16672, 69294, 5931, 8676]

TRAIN, epoch 35, loss 0.4135938336932932, acc 0.8210706405893572,recall 0.7165713074803984,precision 0.7622214082443436,specificity 0.8780702768306075,[tp,tn,fp,fn]: [54104, 121546, 16878, 21400]
VAL, loss 0.3737025153984463, acc 0.8544142065962037,f1 0.69930586930628, recall 0.6716900741675872,precision 0.7292898141009166,specificity 0.9159853772017281,[tp,tn,fp,fn]: [17026, 68905, 6320, 8322]

TRAIN, epoch 36, loss 0.41341332320205687, acc 0.8211267342283385,recall 0.7157501589319771,precision 0.7628094740705191,specificity 0.878604866208172,[tp,tn,fp,fn]: [54042, 121620, 16804, 21462]
VAL, loss 0.38168954956498097, acc 0.8546428962047468,f1 0.6970594939594256, recall 0.6635237494082373,precision 0.7341656117683006,specificity 0.9190428713858425,[tp,tn,fp,fn]: [16819, 69135, 6090, 8529]

TRAIN, epoch 37, loss 0.413304489400302, acc 0.82098182566097,recall 0.7148495443949989,precision 0.7629804498098698,specificity 0.8788721608969543,[tp,tn,fp,fn]: [53974, 121657, 16767, 21530]
VAL, loss 0.37747587209134364, acc 0.8538573971145337,f1 0.7001998939338311, recall 0.6771342906738205,precision 0.7248923050933356,specificity 0.9134064473246926,[tp,tn,fp,fn]: [17164, 68711, 6514, 8184]

TRAIN, epoch 38, loss 0.41266758018489336, acc 0.8214726450020567,recall 0.7175381436745073,precision 0.7626052194476507,specificity 0.8781641911807201,[tp,tn,fp,fn]: [54177, 121559, 16865, 21327]
VAL, loss 0.3783440793394318, acc 0.8551002754218329,f1 0.6991473812423873, recall 0.6680211456525169,precision 0.7333160105668876,specificity 0.9181389165835826,[tp,tn,fp,fn]: [16933, 69067, 6158, 8415]

TRAIN, epoch 39, loss nan, acc 0.7087898732283759,recall 0.25214558169103624,precision 0.7655006031363089,specificity 0.9578685777032885,[tp,tn,fp,fn]: [19038, 132592, 5832, 56466]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 40, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 41, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 42, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 43, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 44, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 45, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 46, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 47, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

TRAIN, epoch 48, loss nan, acc 0.6470588235294118,recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 138424, 0, 75504]
VAL, loss nan, acc 0.747964165332644,f1 0, recall 0.0,precision 0,specificity 1.0,[tp,tn,fp,fn]: [0, 75225, 0, 25348]

pooling_ratio 0.2, dropout0.4, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.6155685991419935, acc 0.6861140196701694,recall 0.2624894045348591,precision 0.6335389828341271,specificity 0.9171819915621569,[tp,tn,fp,fn]: [19819, 126960, 11464, 55685]
VAL, loss 0.5554409043317492, acc 0.7766398536386505,f1 0.46368715083798884, recall 0.3831071484929777,precision 0.5871931309710968,specificity 0.9092455965437022,[tp,tn,fp,fn]: [9711, 68398, 6827, 15637]

TRAIN, epoch 1, loss 0.5984283547622363, acc 0.7071678321678322,recall 0.3290951472769655,precision 0.6745391861443657,specificity 0.9133892966537595,[tp,tn,fp,fn]: [24848, 126435, 11989, 50656]
VAL, loss 0.5500886612575434, acc 0.778548914718662,f1 0.477109452035498, recall 0.4008600284046079,precision 0.5891800997332715,specificity 0.9058158856763044,[tp,tn,fp,fn]: [10161, 68140, 7085, 15187]

TRAIN, epoch 2, loss 0.5913063922721381, acc 0.7141842115104147,recall 0.35747774952320405,precision 0.681212457725506,specificity 0.9087513725943478,[tp,tn,fp,fn]: [26991, 125793, 12631, 48513]
VAL, loss 0.5653776552587001, acc 0.7816312529207641,f1 0.5154443561909806, recall 0.46082531166166957,precision 0.584751702042451,specificity 0.8897308075772682,[tp,tn,fp,fn]: [11681, 66930, 8295, 13667]

TRAIN, epoch 3, loss 0.586384881856059, acc 0.7198777158670207,recall 0.3787084127993219,precision 0.6871905791876952,specificity 0.9059700629948564,[tp,tn,fp,fn]: [28594, 125408, 13016, 46910]
VAL, loss 0.5491796922847525, acc 0.784156781641196,f1 0.5201591511936339, recall 0.4641786334227552,precision 0.5914940679670219,specificity 0.8919774011299435,[tp,tn,fp,fn]: [11766, 67099, 8126, 13582]

TRAIN, epoch 4, loss 0.5826419690067127, acc 0.7217381548932351,recall 0.3890389913117186,precision 0.6867576919480034,specificity 0.9032104259376986,[tp,tn,fp,fn]: [29374, 125026, 13398, 46130]
VAL, loss 0.5632958552924918, acc 0.7827846439899376,f1 0.5281437643094733, recall 0.482326021776866,precision 0.5835799522673031,specificity 0.8840279162512462,[tp,tn,fp,fn]: [12226, 66501, 8724, 13122]

TRAIN, epoch 5, loss 0.5669433372253693, acc 0.7261695523727609,recall 0.4334869675778767,precision 0.6743448162188891,specificity 0.885814598624516,[tp,tn,fp,fn]: [32730, 122618, 15806, 42774]
VAL, loss 0.5344553260724969, acc 0.7851610273134937,f1 0.5532143669485742, recall 0.527733943506391,precision 0.5812801460044322,specificity 0.8719042871385843,[tp,tn,fp,fn]: [13377, 65589, 9636, 11971]

TRAIN, epoch 6, loss 0.5164906846831007, acc 0.7527065180808497,recall 0.5768436109345201,precision 0.6751825383291736,specificity 0.8486317401606658,[tp,tn,fp,fn]: [43554, 117471, 20953, 31950]
VAL, loss 0.4936928022783803, acc 0.8044107265369433,f1 0.669055670519356, recall 0.7844405870285625,precision 0.583262444633481,specificity 0.8111399135925557,[tp,tn,fp,fn]: [19884, 61018, 14207, 5464]

TRAIN, epoch 7, loss 0.46522647977936293, acc 0.7931126360270745,recall 0.6796593557957195,precision 0.718836235274342,specificity 0.8549962434259955,[tp,tn,fp,fn]: [51317, 118352, 20072, 24187]
VAL, loss 0.4813042049421981, acc 0.8091634931840553,f1 0.6818927653932212, recall 0.8115433170269843,precision 0.5879612427473061,specificity 0.8083615819209039,[tp,tn,fp,fn]: [20571, 60809, 14416, 4777]

pooling_ratio 0.2, dropout0.4, hidden_dim 64, outdim 128
epochs 50, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.6317020950773518, acc 0.672651546314648,recall 0.15184625980080527,precision 0.6568318533371527,specificity 0.9567271571403803,[tp,tn,fp,fn]: [11465, 132434, 5990, 64039]
VAL, loss 0.5320287359830805, acc 0.7738359201773836,f1 0.3820029343041895, recall 0.27733943506391034,precision 0.61354512131262,specificity 0.9411365902293121,[tp,tn,fp,fn]: [7030, 70797, 4428, 18318]

TRAIN, epoch 1, loss 0.5941692003471449, acc 0.7137962305074604,recall 0.35264356855265944,precision 0.6831558691468891,specificity 0.9107885915737155,[tp,tn,fp,fn]: [26626, 126075, 12349, 48878]
VAL, loss 0.531441930172195, acc 0.7801895140842969,f1 0.42898101511042236, recall 0.3275998106359476,precision 0.6212313907383856,specificity 0.9326952475905617,[tp,tn,fp,fn]: [8304, 70162, 5063, 17044]

TRAIN, epoch 2, loss 0.5868683769674291, acc 0.721527803747055,recall 0.3878072684890867,precision 0.6868475991649269,specificity 0.9035571866150378,[tp,tn,fp,fn]: [29281, 125074, 13350, 46223]
VAL, loss 0.5325123426493386, acc 0.7792946417030415,f1 0.39794949686728687, recall 0.28941139340381883,precision 0.6367502820935683,specificity 0.9443668993020937,[tp,tn,fp,fn]: [7336, 71040, 4185, 18012]

TRAIN, epoch 3, loss 0.5818013607205211, acc 0.7250430051232191,recall 0.4089849544394999,precision 0.6850500255119019,specificity 0.8974383054961568,[tp,tn,fp,fn]: [30880, 124227, 14197, 44624]
VAL, loss 0.527722516823079, acc 0.7871794616845476,f1 0.4556182918764942, recall 0.3533612119299353,precision 0.641159627773801,specificity 0.9333599202392822,[tp,tn,fp,fn]: [8957, 70212, 5013, 16391]

TRAIN, epoch 4, loss 0.575633183805415, acc 0.7294603791929996,recall 0.431566539521085,precision 0.6853939674393168,specificity 0.8919479281049529,[tp,tn,fp,fn]: [32585, 123467, 14957, 42919]
VAL, loss 0.5192925785789827, acc 0.7927475565012478,f1 0.4896680050925473, recall 0.3945084424806691,precision 0.6453278265358803,specificity 0.9269391824526421,[tp,tn,fp,fn]: [10000, 69729, 5496, 15348]

TRAIN, epoch 5, loss 0.5643131975362466, acc 0.7346864365580943,recall 0.4646906124178851,precision 0.6822618908723214,specificity 0.8819568860891175,[tp,tn,fp,fn]: [35086, 122084, 16340, 40418]
VAL, loss 0.501515949370889, acc 0.7977886709156533,f1 0.5011895710186162, recall 0.4030692756824996,precision 0.6624521818063931,specificity 0.930794283815221,[tp,tn,fp,fn]: [10217, 70019, 5206, 15131]

TRAIN, epoch 6, loss 0.5437509394776183, acc 0.7437502337234958,recall 0.5162243059970333,precision 0.6805950863468893,specificity 0.8678552852106571,[tp,tn,fp,fn]: [38977, 120132, 18292, 36527]
VAL, loss 0.48003574174161273, acc 0.8022729758483887,f1 0.4836414624013295, recall 0.3674057124822471,precision 0.7074597386812519,specificity 0.9488069125955467,[tp,tn,fp,fn]: [9313, 71374, 3851, 16035]

TRAIN, epoch 7, loss 0.5197713085594104, acc 0.7600454358475749,recall 0.5702214452214452,precision 0.6951256922356588,specificity 0.8635857943709183,[tp,tn,fp,fn]: [43054, 119541, 18883, 32450]
VAL, loss 0.46613968319943994, acc 0.8080598172471737,f1 0.479395900755124, recall 0.35063910367681866,precision 0.7575860893283327,specificity 0.9621934197407777,[tp,tn,fp,fn]: [8888, 72381, 2844, 16460]

TRAIN, epoch 8, loss 0.50163033972289, acc 0.771441793500617,recall 0.5972133926679382,precision 0.7092725127801809,specificity 0.8664754666820782,[tp,tn,fp,fn]: [45092, 119941, 18483, 30412]
VAL, loss 0.455505182098968, acc 0.8109134658407327,f1 0.47479908310088653, recall 0.33911945715638314,precision 0.7914556670656477,specificity 0.9698903290129611,[tp,tn,fp,fn]: [8596, 72960, 2265, 16752]

TRAIN, epoch 9, loss 0.48719078749958783, acc 0.7819359784600426,recall 0.612868192413647,precision 0.7265048513203756,specificity 0.8741547708489857,[tp,tn,fp,fn]: [46274, 121004, 17420, 29230]
VAL, loss 0.44161285408656914, acc 0.8119375975659471,f1 0.47043341919587867, recall 0.3314265425280101,precision 0.8102816358024691,specificity 0.9738517779993353,[tp,tn,fp,fn]: [8401, 73258, 1967, 16947]

TRAIN, epoch 10, loss 0.4766337338072, acc 0.7886391683183127,recall 0.6250397329942784,precision 0.7362632219414023,specificity 0.8778752239496042,[tp,tn,fp,fn]: [47193, 121519, 16905, 28311]
VAL, loss 0.43048976133803335, acc 0.8177144959382737,f1 0.49784984524363857, recall 0.3585292725264321,precision 0.814263954842756,specificity 0.9724426719840479,[tp,tn,fp,fn]: [9088, 73152, 2073, 16260]

TRAIN, epoch 11, loss 0.4675467669560395, acc 0.7942719045660223,recall 0.6356749311294766,precision 0.7441355679933023,specificity 0.8807793446223199,[tp,tn,fp,fn]: [47996, 121921, 16503, 27508]
VAL, loss 0.4259668098828916, acc 0.8187684567428634,f1 0.5020081418540477, recall 0.3624349061069907,precision 0.8164045143517284,specificity 0.9725357261548687,[tp,tn,fp,fn]: [9187, 73159, 2066, 16161]

TRAIN, epoch 12, loss 0.4607735163603977, acc 0.7980255039078569,recall 0.6446545878364061,precision 0.748232183483982,specificity 0.8816823672195573,[tp,tn,fp,fn]: [48674, 122046, 16378, 26830]
VAL, loss 0.4167363036852075, acc 0.8224175474530938,f1 0.5208713381264084, recall 0.38298879596023355,precision 0.8138832997987927,specificity 0.9704885343968096,[tp,tn,fp,fn]: [9708, 73005, 2220, 15640]

TRAIN, epoch 13, loss 0.45544844349348695, acc 0.802302643880184,recall 0.6558460478915025,precision 0.7522597110608109,specificity 0.8821880598740103,[tp,tn,fp,fn]: [49519, 122116, 16308, 25985]
VAL, loss 0.41562848529759505, acc 0.8253905123641534,f1 0.5366613018126171, recall 0.40121508600284045,precision 0.810164900820521,specificity 0.9683217015619807,[tp,tn,fp,fn]: [10170, 72842, 2383, 15178]

TRAIN, epoch 14, loss 0.45060259093521804, acc 0.8042051531356345,recall 0.6624417249417249,precision 0.7530866056371959,specificity 0.8815306594232214,[tp,tn,fp,fn]: [50017, 122025, 16399, 25487]
VAL, loss 0.4079319230825657, acc 0.8272598013383313,f1 0.5450784257246851, recall 0.4106043869338804,precision 0.810528775017522,specificity 0.9676570289132602,[tp,tn,fp,fn]: [10408, 72792, 2433, 14940]

TRAIN, epoch 15, loss 0.44683578852596834, acc 0.805906660184735,recall 0.6661633820724729,precision 0.7550665025370042,specificity 0.8821302664277871,[tp,tn,fp,fn]: [50298, 122108, 16316, 25206]
VAL, loss 0.4024834581975964, acc 0.8297356149264713,f1 0.5580447013885305, recall 0.42650307716585134,precision 0.8069114793252724,specificity 0.9656098371552011,[tp,tn,fp,fn]: [10811, 72638, 2587, 14537]

TRAIN, epoch 16, loss 0.4442359635037396, acc 0.8077904715605251,recall 0.6711829836829837,precision 0.7567232600158282,specificity 0.8823036467664567,[tp,tn,fp,fn]: [50677, 122132, 16292, 24827]
VAL, loss 0.3989994112960144, acc 0.8317540492975252,f1 0.5676248882074868, recall 0.43818052706327915,precision 0.8056139841880032,specificity 0.9643735460285809,[tp,tn,fp,fn]: [11107, 72545, 2680, 14241]

TRAIN, epoch 17, loss 0.4414811095130956, acc 0.8093751168617479,recall 0.6780435473617292,precision 0.756583808707475,specificity 0.8810105184072127,[tp,tn,fp,fn]: [51195, 121953, 16471, 24309]
VAL, loss 0.3979705179157267, acc 0.8318435365356507,f1 0.5678438186742986, recall 0.43833833044027143,precision 0.8059625707239229,specificity 0.964440013293453,[tp,tn,fp,fn]: [11111, 72550, 2675, 14237]

TRAIN, epoch 18, loss 0.4383957583792551, acc 0.8103146853146853,recall 0.680864589955499,precision 0.7572137691299289,specificity 0.8809238282378778,[tp,tn,fp,fn]: [51408, 121941, 16483, 24096]
VAL, loss 0.39376354758004384, acc 0.8339415151183718,f1 0.5780551274601451, recall 0.45131765819788544,precision 0.8037658961568187,specificity 0.9628713858424726,[tp,tn,fp,fn]: [11440, 72432, 2793, 13908]

TRAIN, epoch 19, loss 0.4367819384711695, acc 0.8112402303578774,recall 0.6859901462174189,precision 0.7564958301079352,specificity 0.8795584580708548,[tp,tn,fp,fn]: [51795, 121752, 16672, 23709]
VAL, loss 0.3917007266113662, acc 0.8346076978910841,f1 0.5821442926045017, recall 0.4571169323023513,precision 0.801313969571231,specificity 0.9618079096045198,[tp,tn,fp,fn]: [11587, 72352, 2873, 13761]

TRAIN, epoch 20, loss 0.43539901085827326, acc 0.8118011667476908,recall 0.6865199194744649,precision 0.7575226153418972,specificity 0.8801363925330867,[tp,tn,fp,fn]: [51835, 121832, 16592, 23669]
VAL, loss 0.3892804142167891, acc 0.8373718592465175,f1 0.5963873260290198, recall 0.4767240018936405,precision 0.7962572482867686,specificity 0.958896643403124,[tp,tn,fp,fn]: [12084, 72133, 3092, 13264]

TRAIN, epoch 21, loss 0.4334146720017845, acc 0.8126799670917318,recall 0.6905329518965883,precision 0.7573244244316943,specificity 0.8793056117436283,[tp,tn,fp,fn]: [52138, 121717, 16707, 23366]
VAL, loss 0.3848495724482018, acc 0.8380280989927714,f1 0.5993211334120425, recall 0.4806296354741991,precision 0.795858374706036,specificity 0.9584579594549685,[tp,tn,fp,fn]: [12183, 72100, 3125, 13165]

TRAIN, epoch 22, loss 0.4327434220375902, acc 0.8120489136531918,recall 0.6907978385251112,precision 0.7556940017386264,specificity 0.8781858637230539,[tp,tn,fp,fn]: [52158, 121562, 16862, 23346]
VAL, loss 0.38519514222396445, acc 0.8385153072892327,f1 0.6019070029659044, recall 0.4843774656777655,precision 0.7947439963751699,specificity 0.9578464606181456,[tp,tn,fp,fn]: [12278, 72054, 3171, 13070]

TRAIN, epoch 23, loss 0.43069159777741045, acc 0.8135727908455181,recall 0.6938440347531256,precision 0.7575556005437141,specificity 0.8788793850777322,[tp,tn,fp,fn]: [52388, 121658, 16766, 23116]
VAL, loss 0.38485240315988994, acc 0.83778946635777,f1 0.5985135600728453, recall 0.4797222660564936,precision 0.7954991495486066,specificity 0.9584446660019941,[tp,tn,fp,fn]: [12160, 72099, 3126, 13188]

TRAIN, epoch 24, loss 0.42978001060136695, acc 0.8144095209603232,recall 0.6966783216783217,precision 0.7579211273287898,specificity 0.8786265387505057,[tp,tn,fp,fn]: [52602, 121623, 16801, 22902]
VAL, loss 0.3812053823394499, acc 0.8408618615334136,f1 0.6144023899583204, recall 0.5030377150071011,precision 0.7890958598923201,specificity 0.9546959122632104,[tp,tn,fp,fn]: [12751, 71817, 3408, 12597]

TRAIN, epoch 25, loss 0.42939918042945546, acc 0.8143861486107475,recall 0.6965856113583386,precision 0.7579185520361991,specificity 0.8786409871120615,[tp,tn,fp,fn]: [52595, 121625, 16799, 22909]
VAL, loss 0.3816053463357611, acc 0.8405635707396617,f1 0.6123346952590479, recall 0.4996054915575193,precision 0.7907586637527318,specificity 0.9554536390827517,[tp,tn,fp,fn]: [12664, 71874, 3351, 12684]

TRAIN, epoch 26, loss 0.42807750109491055, acc 0.8143534273213417,recall 0.6976054248781521,precision 0.757271224211056,specificity 0.878034155926718,[tp,tn,fp,fn]: [52672, 121541, 16883, 22832]
VAL, loss 0.37875575888964735, acc 0.8403746532369523,f1 0.612128533462189, recall 0.4997632949345116,precision 0.7896770976187508,specificity 0.9551478896643403,[tp,tn,fp,fn]: [12668, 71851, 3374, 12680]

TRAIN, epoch 27, loss 0.4276195974888671, acc 0.814446916719644,recall 0.6982014197923289,precision 0.7571561938958707,specificity 0.8778535514072704,[tp,tn,fp,fn]: [52717, 121516, 16908, 22787]
VAL, loss 0.3777054459425231, acc 0.8411104371948733,f1 0.6150510695702447, recall 0.5036294776708221,precision 0.7897797574857709,specificity 0.9548288467929544,[tp,tn,fp,fn]: [12766, 71827, 3398, 12582]

TRAIN, epoch 28, loss 0.4268360012460096, acc 0.8151340637971654,recall 0.6997774952320407,precision 0.7578748063572207,specificity 0.8780558284690516,[tp,tn,fp,fn]: [52836, 121544, 16880, 22668]
VAL, loss 0.3786526665956192, acc 0.840314995078202,f1 0.6120398106097207, recall 0.4997632949345116,precision 0.78938185443669,specificity 0.9550681289464938,[tp,tn,fp,fn]: [12668, 71845, 3380, 12680]

TRAIN, epoch 29, loss 0.4263319412650276, acc 0.8153070191840245,recall 0.7016052129688494,precision 0.7572582374383532,specificity 0.8773261862104837,[tp,tn,fp,fn]: [52974, 121443, 16981, 22530]
VAL, loss 0.3758849719238496, acc 0.8419655374702952,f1 0.6194330045014845, recall 0.5102966703487455,precision 0.7879507797270955,specificity 0.9537254901960784,[tp,tn,fp,fn]: [12935, 71744, 3481, 12413]

TRAIN, epoch 30, loss 0.42615670052227705, acc 0.8153210425937699,recall 0.7027707141343505,precision 0.7566449920146019,specificity 0.8767121308443623,[tp,tn,fp,fn]: [53062, 121358, 17066, 22442]
VAL, loss 0.37580940932895973, acc 0.8417766199675857,f1 0.61896894380193, recall 0.5099021619062648,precision 0.7873895826987511,specificity 0.9536058491193088,[tp,tn,fp,fn]: [12925, 71735, 3490, 12423]

TRAIN, epoch 31, loss 0.4249853643619962, acc 0.8156295576081672,recall 0.702545560500106,precision 0.7574827211972354,specificity 0.8773117378489279,[tp,tn,fp,fn]: [53045, 121441, 16983, 22459]
VAL, loss 0.37484024885740036, acc 0.8433774472273871,f1 0.6262870699881375, recall 0.5207116932302351,precision 0.7855612427092012,specificity 0.9521036889332004,[tp,tn,fp,fn]: [13199, 71622, 3603, 12149]

TRAIN, epoch 32, loss 0.4246662002905096, acc 0.8156903257170637,recall 0.703790527654164,precision 0.756933464381864,specificity 0.876726579205918,[tp,tn,fp,fn]: [53139, 121360, 17064, 22365]
VAL, loss 0.3736305368450763, acc 0.8418263350998777,f1 0.6181285707427144, recall 0.5079296196938614,precision 0.7893930104230533,specificity 0.9543369890329013,[tp,tn,fp,fn]: [12875, 71790, 3435, 12473]

TRAIN, epoch 33, loss 0.42407864103396253, acc 0.8163914962043304,recall 0.7044262555626192,precision 0.758200402001454,specificity 0.8774634456452638,[tp,tn,fp,fn]: [53187, 121462, 16962, 22317]
VAL, loss 0.3703971805892292, acc 0.8447197557992702,f1 0.633343507149062, recall 0.5321129872179264,precision 0.782139750652363,specificity 0.9500564971751413,[tp,tn,fp,fn]: [13488, 71468, 3757, 11860]

TRAIN, epoch 34, loss 0.42357972367156405, acc 0.8160689577801877,recall 0.703962703962704,precision 0.7577122654958088,specificity 0.8772178234988153,[tp,tn,fp,fn]: [53152, 121428, 16996, 22352]
VAL, loss 0.37343022021326405, acc 0.8429101249838425,f1 0.6242359376858129, recall 0.517713429067382,precision 0.7859495717793615,specificity 0.9524891990694583,[tp,tn,fp,fn]: [13123, 71651, 3574, 12225]

TRAIN, epoch 35, loss 0.42256304764907215, acc 0.8159754683818855,recall 0.7048103411739776,precision 0.7570274268806191,specificity 0.8766109923134716,[tp,tn,fp,fn]: [53216, 121344, 17080, 22288]
VAL, loss 0.37230585555784534, acc 0.8438646555238484,f1 0.6295326397244438, recall 0.5263531639577087,precision 0.7830271729561594,specificity 0.9508541043536058,[tp,tn,fp,fn]: [13342, 71528, 3697, 12006]

TRAIN, epoch 36, loss 0.422981038408207, acc 0.8169150368348229,recall 0.7054460690824327,precision 0.75884372640367,specificity 0.8777162919724903,[tp,tn,fp,fn]: [53264, 121497, 16927, 22240]
VAL, loss 0.3725259276848415, acc 0.8434072763067623,f1 0.62666824700723, recall 0.5214612592709484,precision 0.7850567203183465,specificity 0.9518909936856098,[tp,tn,fp,fn]: [13218, 71606, 3619, 12130]

TRAIN, epoch 37, loss 0.4219281457099591, acc 0.8165971728805953,recall 0.7065585929222293,precision 0.7574935749073509,specificity 0.8766182164942495,[tp,tn,fp,fn]: [53348, 121345, 17079, 22156]
VAL, loss 0.37042123639317664, acc 0.8444711801378103,f1 0.6326444340065759, recall 0.5313634211772132,precision 0.7816272051996286,specificity 0.9499767364572947,[tp,tn,fp,fn]: [13469, 71462, 3763, 11879]

TRAIN, epoch 38, loss 0.422489132446428, acc 0.8162746344564527,recall 0.7047441195168468,precision 0.7577539802341147,specificity 0.8771094607871467,[tp,tn,fp,fn]: [53211, 121413, 17011, 22293]
VAL, loss 0.3695725166995465, acc 0.8447197557992702,f1 0.6349718346072039, recall 0.5358608174214928,precision 0.779065098938916,specificity 0.9487936191425723,[tp,tn,fp,fn]: [13583, 71373, 3852, 11765]

pooling_ratio 0.2, dropout0.4, hidden_dim 64, outdim 128
epochs 50, lr 1e-05, weight_decay 0.001
