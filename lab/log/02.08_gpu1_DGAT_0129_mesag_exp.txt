pooling_ratio 0.2, dropout0.5, hidden_dim 128, outdim 256
epochs 50, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.5660790811780726, acc 0.723869713174526,recall 0.40419050646323373,precision 0.684198726571608,specificity 0.8982401895625036,[tp,tn,fp,fn]: [30518, 124338, 14086, 44986]
VAL, loss 0.46506635246189687, acc 0.8021735455838048,f1 0.5538413239449254, recall 0.48717847561937827,precision 0.6416398212615608,specificity 0.9083150548354936,[tp,tn,fp,fn]: [12349, 68328, 6897, 12999]

TRAIN, epoch 1, loss 0.5145854994530391, acc 0.7598771549306309,recall 0.5176282051282052,precision 0.7233440062186522,specificity 0.892012945731954,[tp,tn,fp,fn]: [39083, 123476, 14948, 36421]
VAL, loss 0.4087944373130021, acc 0.8258578346076979,f1 0.6057181449797389, recall 0.5307322076692441,precision 0.7053796140939598,specificity 0.9253040877367896,[tp,tn,fp,fn]: [13453, 69606, 5619, 11895]

TRAIN, epoch 2, loss 0.47304143957262385, acc 0.7852314797501964,recall 0.6036236490781945,precision 0.7399542155764454,specificity 0.8842902964803792,[tp,tn,fp,fn]: [45576, 122407, 16017, 29928]
VAL, loss 0.38729161675620316, acc 0.8351446213198374,f1 0.6317192358951578, recall 0.5609910052075114,precision 0.7228548190321269,specificity 0.9275240943835161,[tp,tn,fp,fn]: [14220, 69773, 5452, 11128]

TRAIN, epoch 3, loss 0.4633595866429182, acc 0.7906258180322352,recall 0.6234769018859928,precision 0.7420748143827735,specificity 0.8817979541120037,[tp,tn,fp,fn]: [47075, 122062, 16362, 28429]
VAL, loss 0.382660704542624, acc 0.8377496942519363,f1 0.6416304300083454, recall 0.5762979327757614,precision 0.7236698702070742,specificity 0.9258491193087405,[tp,tn,fp,fn]: [14608, 69647, 5578, 10740]

TRAIN, epoch 4, loss 0.45850078067311995, acc 0.7941550428181444,recall 0.6306420851875397,precision 0.7467536540994919,specificity 0.8833439287984742,[tp,tn,fp,fn]: [47616, 122276, 16148, 27888]
VAL, loss 0.3799368670284342, acc 0.839280920326529,f1 0.6486545233230447, recall 0.5886460470254063,precision 0.7222867654177558,specificity 0.9237354602858092,[tp,tn,fp,fn]: [14921, 69488, 5737, 10427]

TRAIN, epoch 5, loss 0.4555699769005601, acc 0.795936015855802,recall 0.6359133290951473,precision 0.7481263341591486,specificity 0.8832211177252499,[tp,tn,fp,fn]: [48014, 122259, 16165, 27490]
VAL, loss 0.37599503199562184, acc 0.8409414057450807,f1 0.6519137454577105, recall 0.5909736468360423,precision 0.7268669028094522,specificity 0.9251711532070456,[tp,tn,fp,fn]: [14980, 69596, 5629, 10368]

TRAIN, epoch 6, loss 0.45359481167055044, acc 0.796941026887551,recall 0.6389595253231617,precision 0.7488513597417111,specificity 0.8831127550135814,[tp,tn,fp,fn]: [48244, 122244, 16180, 27260]
VAL, loss 0.37464126775103135, acc 0.8414882722002923,f1 0.6534799808720602, recall 0.5930250907369418,precision 0.7276599864459289,specificity 0.9252110335659688,[tp,tn,fp,fn]: [15032, 69599, 5626, 10316]

TRAIN, epoch 7, loss 0.451455936670027, acc 0.7983760891514903,recall 0.6415421699512609,precision 0.7509107538716728,specificity 0.8839218632607062,[tp,tn,fp,fn]: [48439, 122356, 16068, 27065]
VAL, loss 0.3744650889146677, acc 0.8414683861473755,f1 0.6582793947447383, recall 0.6058466151175635,precision 0.7206475832942281,specificity 0.9208640744433366,[tp,tn,fp,fn]: [15357, 69272, 5953, 9991]

TRAIN, epoch 8, loss 0.4487978885575991, acc 0.7993390299540032,recall 0.6463631065903793,precision 0.7504805548293838,specificity 0.8827804426977981,[tp,tn,fp,fn]: [48803, 122198, 16226, 26701]
VAL, loss 0.37305434311809005, acc 0.8424229166873813,f1 0.6613096255770218, recall 0.6103834622060912,precision 0.7215071814959896,specificity 0.9206114988368229,[tp,tn,fp,fn]: [15472, 69253, 5972, 9876]

TRAIN, epoch 9, loss 0.44760494353812136, acc 0.8006525560001496,recall 0.6491311718584446,precision 0.7521099960101894,specificity 0.8833005837138068,[tp,tn,fp,fn]: [49012, 122270, 16154, 26492]
VAL, loss 0.3730140070431314, acc 0.8426018911636324,f1 0.6623725632384934, recall 0.6125927094839829,precision 0.7209583062494196,specificity 0.9201063476237953,[tp,tn,fp,fn]: [15528, 69215, 6010, 9820]

TRAIN, epoch 10, loss 0.4466968962819533, acc 0.8012415392094536,recall 0.6507337359610087,precision 0.75262706412181,specificity 0.8833367046176963,[tp,tn,fp,fn]: [49133, 122275, 16149, 26371]
VAL, loss 0.3701237136804401, acc 0.8431587006453024,f1 0.6653939162530229, recall 0.6187470411866814,precision 0.7196476094337891,specificity 0.9187770023263543,[tp,tn,fp,fn]: [15684, 69115, 6110, 9664]

TRAIN, epoch 11, loss 0.44502652218028793, acc 0.8021670842526457,recall 0.6527203856749312,precision 0.7537470940902973,specificity 0.8836834652950355,[tp,tn,fp,fn]: [49283, 122323, 16101, 26221]
VAL, loss 0.37061413367603935, acc 0.8431885297246776,f1 0.6668075127289629, recall 0.6225737730787438,precision 0.717807596088242,specificity 0.9175274177467597,[tp,tn,fp,fn]: [15781, 69021, 6204, 9567]

TRAIN, epoch 12, loss 0.44426527850728026, acc 0.8022044800119666,recall 0.6538064208518753,precision 0.7532041501373207,specificity 0.8831488759174709,[tp,tn,fp,fn]: [49365, 122249, 16175, 26139]
VAL, loss 0.36980944213786243, acc 0.8435862507830133,f1 0.6667090404457721, recall 0.6207195833990847,precision 0.7200585785547572,specificity 0.9186839481555334,[tp,tn,fp,fn]: [15734, 69108, 6117, 9614]

TRAIN, epoch 13, loss 0.443642602439041, acc 0.8032141655136308,recall 0.6562301335028607,precision 0.7542700563251636,specificity 0.8833872738831416,[tp,tn,fp,fn]: [49548, 122282, 16142, 25956]
VAL, loss 0.3687668385549432, acc 0.8437851113121811,f1 0.6686072264759855, recall 0.6252564304876125,precision 0.7184171161778704,specificity 0.9174210701229645,[tp,tn,fp,fn]: [15849, 69013, 6212, 9499]

TRAIN, epoch 14, loss 0.44268861846312024, acc 0.8041023147975019,recall 0.6590644204280568,precision 0.7547931076325689,specificity 0.8832138935444721,[tp,tn,fp,fn]: [49762, 122258, 16166, 25742]
VAL, loss 0.3676477940200363, acc 0.8441430602646833,f1 0.6652000256306201, recall 0.6143285466308979,precision 0.7252573238321457,specificity 0.9215819209039549,[tp,tn,fp,fn]: [15572, 69326, 5899, 9776]

TRAIN, epoch 15, loss 0.4419438491162818, acc 0.8043500617030028,recall 0.6593822843822844,precision 0.7552144168196229,specificity 0.8834233947870311,[tp,tn,fp,fn]: [49786, 122287, 16137, 25718]
VAL, loss 0.36771757050557646, acc 0.8442623765821841,f1 0.6702040300675888, recall 0.6278601862079849,precision 0.7186723865432377,specificity 0.9171817879694251,[tp,tn,fp,fn]: [15915, 68995, 6230, 9433]

TRAIN, epoch 16, loss 0.44103364328640676, acc 0.8045837851987585,recall 0.6615940877304514,precision 0.7544972585980334,specificity 0.8825781656360169,[tp,tn,fp,fn]: [49953, 122170, 16254, 25551]
VAL, loss 0.36836504415734017, acc 0.8444811231642687,f1 0.6717868009652712, recall 0.631489663878807,precision 0.7175774420585467,specificity 0.9162512462612163,[tp,tn,fp,fn]: [16007, 68925, 6300, 9341]

TRAIN, epoch 17, loss 0.44040154128556813, acc 0.80485957892375,recall 0.6616338207247299,precision 0.7551470810532999,specificity 0.8829827197595793,[tp,tn,fp,fn]: [49956, 122226, 16198, 25548]
VAL, loss 0.36694779708405456, acc 0.8443916359261432,f1 0.6699287130383432, recall 0.6265583083477987,precision 0.7197498413849361,specificity 0.9177932868062479,[tp,tn,fp,fn]: [15882, 69041, 6184, 9466]

TRAIN, epoch 18, loss 0.43975015446169785, acc 0.8054532366029692,recall 0.6639118457300276,precision 0.7552696207681066,specificity 0.8826576316245738,[tp,tn,fp,fn]: [50128, 122181, 16243, 25376]
VAL, loss 0.367232654202148, acc 0.844739641852187,f1 0.672620919554689, recall 0.6328309925832413,precision 0.7177502349098394,specificity 0.9161448986374211,[tp,tn,fp,fn]: [16041, 68917, 6308, 9307]

TRAIN, epoch 19, loss 0.4391777648959572, acc 0.8059767772334617,recall 0.6646932612841704,precision 0.756090211971014,specificity 0.8830405132058025,[tp,tn,fp,fn]: [50187, 122234, 16190, 25317]
VAL, loss 0.36624026284414163, acc 0.8446103825082278,f1 0.6718323463945235, recall 0.6310951554363263,precision 0.7181916135404508,specificity 0.9165569956796278,[tp,tn,fp,fn]: [15997, 68948, 6277, 9351]

TRAIN, epoch 20, loss 0.43887417420908165, acc 0.8057477282076213,recall 0.665276011866921,precision 0.7551943951649277,specificity 0.8823686643934577,[tp,tn,fp,fn]: [50231, 122141, 16283, 25273]
VAL, loss 0.3672231742313147, acc 0.844789356984479,f1 0.6753057658707048, recall 0.6404055546788702,precision 0.7142291446673706,specificity 0.9136590229312064,[tp,tn,fp,fn]: [16233, 68730, 6495, 9115]

TRAIN, epoch 21, loss 0.4382669225795959, acc 0.8060001495830372,recall 0.6661368934096207,precision 0.75530860489563,specificity 0.8822891984049008,[tp,tn,fp,fn]: [50296, 122130, 16294, 25208]
VAL, loss 0.36573752058111, acc 0.844789356984479,f1 0.6737312933701196, recall 0.6358292567460944,precision 0.7164384779516358,specificity 0.915201063476238,[tp,tn,fp,fn]: [16117, 68846, 6379, 9231]

TRAIN, epoch 22, loss 0.43830537774399586, acc 0.806406828465652,recall 0.6667991099809282,precision 0.7559118958605469,specificity 0.8825564930936832,[tp,tn,fp,fn]: [50346, 122167, 16257, 25158]
VAL, loss 0.3649853614186329, acc 0.844789356984479,f1 0.6746967865627475, recall 0.6386302666877072,precision 0.7150808375298171,specificity 0.9142572283150548,[tp,tn,fp,fn]: [16188, 68775, 6450, 9160]

TRAIN, epoch 23, loss 0.4379377102406967, acc 0.8066312030215773,recall 0.6666799109980928,precision 0.7565264439334506,specificity 0.8829682713980235,[tp,tn,fp,fn]: [50337, 122224, 16200, 25167]
VAL, loss 0.36455533361872877, acc 0.8453958815984409,f1 0.6752167101827675, recall 0.6376439955815054,precision 0.7174945620810583,specificity 0.9154004652708541,[tp,tn,fp,fn]: [16163, 68861, 6364, 9185]

TRAIN, epoch 24, loss 0.4373261931444854, acc 0.8067901349986911,recall 0.6672096842551388,precision 0.7566045386960636,specificity 0.8829249263133561,[tp,tn,fp,fn]: [50377, 122218, 16206, 25127]
VAL, loss 0.3639508327790835, acc 0.8455847991011504,f1 0.6731489666203646, recall 0.630897901215086,precision 0.7214653072272851,specificity 0.917926221335992,[tp,tn,fp,fn]: [15992, 69051, 6174, 9356]

TRAIN, epoch 25, loss 0.4368728656721723, acc 0.8073837926779103,recall 0.6691698453062089,precision 0.7569061601150527,specificity 0.8827732185170202,[tp,tn,fp,fn]: [50525, 122197, 16227, 24979]
VAL, loss 0.36385432635951936, acc 0.8456345142334424,f1 0.676596187897094, recall 0.6406817105886066,precision 0.7167762722337467,specificity 0.9146959122632103,[tp,tn,fp,fn]: [16240, 68808, 6417, 9108]

TRAIN, epoch 26, loss 0.43633278045420343, acc 0.8072342096406268,recall 0.6695009535918627,precision 0.7563515575904479,specificity 0.8823614402126799,[tp,tn,fp,fn]: [50550, 122140, 16284, 24954]
VAL, loss 0.3638026050192585, acc 0.8454853688365664,f1 0.6766945450006242, recall 0.6415890800063121,precision 0.715864072541597,specificity 0.9141907610501828,[tp,tn,fp,fn]: [16263, 68770, 6455, 9085]

TRAIN, epoch 27, loss 0.4357566009426941, acc 0.807622190643581,recall 0.6711697393515575,precision 0.7563243436861036,specificity 0.8820508004392302,[tp,tn,fp,fn]: [50676, 122097, 16327, 24828]
VAL, loss 0.36363624770257963, acc 0.8455350839688585,f1 0.6787036462534385, recall 0.6473094524222819,precision 0.7132982654436378,specificity 0.9123296776337654,[tp,tn,fp,fn]: [16408, 68630, 6595, 8940]

TRAIN, epoch 28, loss 0.435571880590621, acc 0.8081036610448376,recall 0.6718981775799958,precision 0.7570661095358902,specificity 0.8823975611165694,[tp,tn,fp,fn]: [50731, 122145, 16279, 24773]
VAL, loss 0.36456047320784196, acc 0.8451473059369811,f1 0.6784357449620085, recall 0.6481379201514912,precision 0.7117050771096863,specificity 0.9115320704553007,[tp,tn,fp,fn]: [16429, 68570, 6655, 8919]

TRAIN, epoch 29, loss 0.4351082380565289, acc 0.808421524999065,recall 0.6721365755456664,precision 0.7576965570784436,specificity 0.8827587701554643,[tp,tn,fp,fn]: [50749, 122195, 16229, 24755]
VAL, loss 0.36307712410045323, acc 0.8457240014715679,f1 0.6778774289985051, recall 0.6440744831939403,precision 0.7154250657318142,specificity 0.9136723163841808,[tp,tn,fp,fn]: [16326, 68731, 6494, 9022]

TRAIN, epoch 30, loss 0.4348205369936716, acc 0.8090525784376051,recall 0.6730901674083493,precision 0.7586695926075209,specificity 0.8832138935444721,[tp,tn,fp,fn]: [50821, 122258, 16166, 24683]
VAL, loss 0.3634095391250615, acc 0.8458433177890686,f1 0.6792585543464769, recall 0.6476645100205144,precision 0.7140930839495433,specificity 0.9126221335992024,[tp,tn,fp,fn]: [16417, 68652, 6573, 8931]

TRAIN, epoch 31, loss 0.43542504390739056, acc 0.8084635952283011,recall 0.6722027972027972,precision 0.757759894892429,specificity 0.882787666878576,[tp,tn,fp,fn]: [50754, 122199, 16225, 24750]
VAL, loss 0.36361284412157463, acc 0.8458234317361518,f1 0.6793100595632031, recall 0.6479012150860028,precision 0.7139193183794122,specificity 0.9125157859754071,[tp,tn,fp,fn]: [16423, 68644, 6581, 8925]

TRAIN, epoch 32, loss 0.43430189469990177, acc 0.8084729441681313,recall 0.6724014621741895,precision 0.75766710940648,specificity 0.8826937525284633,[tp,tn,fp,fn]: [50769, 122186, 16238, 24735]
VAL, loss 0.36352905595113705, acc 0.8457836596303183,f1 0.6797307342859502, recall 0.6493214454789332,precision 0.7131282495667244,specificity 0.9119840478564307,[tp,tn,fp,fn]: [16459, 68604, 6621, 8889]

TRAIN, epoch 33, loss 0.43374664084653947, acc 0.8095807935380128,recall 0.674308645899555,precision 0.759238271347192,specificity 0.883365601340808,[tp,tn,fp,fn]: [50913, 122279, 16145, 24591]
VAL, loss 0.3631242045885678, acc 0.845952691080111,f1 0.6787350959046138, recall 0.645652516963863,precision 0.7153910040652184,specificity 0.9134463276836158,[tp,tn,fp,fn]: [16366, 68714, 6511, 8982]

TRAIN, epoch 34, loss 0.43399511310719974, acc 0.8089357166897274,recall 0.6743483788938335,precision 0.7576560221421982,specificity 0.8823469918511241,[tp,tn,fp,fn]: [50916, 122138, 16286, 24588]
VAL, loss 0.36305709426799176, acc 0.8460421783182365,f1 0.6796060254924682, recall 0.6478617642417548,precision 0.714621409921671,specificity 0.9128215353938185,[tp,tn,fp,fn]: [16422, 68667, 6558, 8926]

TRAIN, epoch 35, loss 0.4336535460790866, acc 0.8093844658015781,recall 0.6752092604365332,precision 0.7582396335296567,specificity 0.882570941455239,[tp,tn,fp,fn]: [50981, 122169, 16255, 24523]
VAL, loss 0.3630529326750924, acc 0.8460620643711533,f1 0.6801504007933229, recall 0.6494003471674293,precision 0.7139573213046495,specificity 0.9123296776337654,[tp,tn,fp,fn]: [16461, 68630, 6595, 8887]

TRAIN, epoch 36, loss 0.433008235328097, acc 0.8093517445121723,recall 0.6750370841279932,precision 0.7582605590847553,specificity 0.8826142865399064,[tp,tn,fp,fn]: [50968, 122175, 16249, 24536]
VAL, loss 0.3638252220672582, acc 0.8458134887096934,f1 0.6802614486896638, recall 0.6507811267161118,precision 0.7125394151440543,specificity 0.9115320704553007,[tp,tn,fp,fn]: [16496, 68570, 6655, 8852]

TRAIN, epoch 37, loss 0.4330141450881708, acc 0.8099033319621555,recall 0.6759641873278237,precision 0.7590535254837223,specificity 0.8829610472172456,[tp,tn,fp,fn]: [51038, 122223, 16201, 24466]
VAL, loss 0.3636700057253579, acc 0.8459825201594862,f1 0.6826469985658676, recall 0.6572510651727947,precision 0.7100843917824567,specificity 0.9095779328680624,[tp,tn,fp,fn]: [16660, 68423, 6802, 8688]

TRAIN, epoch 38, loss 0.43306084801213585, acc 0.809674282936315,recall 0.6762952956134775,precision 0.7583088300810835,specificity 0.882426457839681,[tp,tn,fp,fn]: [51063, 122149, 16275, 24441]
VAL, loss 0.36203358375172323, acc 0.8464498424030307,f1 0.681120816039976, recall 0.6506627741833675,precision 0.7145704258914258,specificity 0.9124227318045862,[tp,tn,fp,fn]: [16493, 68637, 6588, 8855]

TRAIN, epoch 39, loss 0.43227198998264105, acc 0.8101604278074866,recall 0.6764807162534435,precision 0.7593737920371086,specificity 0.883076634109692,[tp,tn,fp,fn]: [51077, 122239, 16185, 24427]
VAL, loss 0.362985320920582, acc 0.8464597854294891,f1 0.6836563281025935, recall 0.6582767871232444,precision 0.7110713372538993,specificity 0.9098703888334995,[tp,tn,fp,fn]: [16686, 68445, 6780, 8662]

TRAIN, epoch 40, loss 0.4321452703384476, acc 0.8101136831083355,recall 0.6764409832591651,precision 0.7592840365117592,specificity 0.8830260648442466,[tp,tn,fp,fn]: [51074, 122232, 16192, 24430]
VAL, loss 0.36313141054397857, acc 0.8462808109532379,f1 0.6830408397572577, recall 0.6571721634842985,precision 0.711029537305788,specificity 0.9100033233632436,[tp,tn,fp,fn]: [16658, 68455, 6770, 8690]

TRAIN, epoch 41, loss 0.4319452022372515, acc 0.8102071725066378,recall 0.6768118245390973,precision 0.7592939288579834,specificity 0.8829682713980235,[tp,tn,fp,fn]: [51102, 122224, 16200, 24402]
VAL, loss 0.3622553705978814, acc 0.8466188738528233,f1 0.6832443531827516, recall 0.6563436957550891,precision 0.7124443302500857,specificity 0.9107344632768362,[tp,tn,fp,fn]: [16637, 68510, 6715, 8711]

TRAIN, epoch 42, loss 0.4315411869997504, acc 0.8103240342545155,recall 0.6772091544818818,precision 0.7593447881551004,specificity 0.882932150494134,[tp,tn,fp,fn]: [51132, 122219, 16205, 24372]
VAL, loss 0.3624426819312684, acc 0.8468077913555327,f1 0.6821660649819495, recall 0.6522802587975383,precision 0.714921952695983,specificity 0.9123562645397142,[tp,tn,fp,fn]: [16534, 68632, 6593, 8814]

TRAIN, epoch 43, loss 0.4312927432330124, acc 0.8107447365468756,recall 0.6783084339902522,precision 0.7597199353240472,specificity 0.8829827197595793,[tp,tn,fp,fn]: [51215, 122226, 16198, 24289]
VAL, loss 0.3622293688053365, acc 0.8469370506994919,f1 0.6847042438145174, recall 0.6594208616064384,precision 0.7120037485091157,specificity 0.9101229644400133,[tp,tn,fp,fn]: [16715, 68464, 6761, 8633]

TRAIN, epoch 44, loss 0.4312829616150839, acc 0.8109784600426312,recall 0.6795798898071626,precision 0.7595440751979868,specificity 0.8826504074437959,[tp,tn,fp,fn]: [51311, 122180, 16244, 24193]
VAL, loss 0.36138192753893517, acc 0.8471856263609517,f1 0.6827143417494168, recall 0.6523197096417863,precision 0.7160798579533152,specificity 0.9128481222997674,[tp,tn,fp,fn]: [16535, 68669, 6556, 8813]

TRAIN, epoch 45, loss 0.4309832552247796, acc 0.8112916495269437,recall 0.6804540156812884,precision 0.7597900029577048,specificity 0.8826576316245738,[tp,tn,fp,fn]: [51377, 122181, 16243, 24127]
VAL, loss 0.36126868890019154, acc 0.8476827776838715,f1 0.6841508422506752, recall 0.654528956919678,precision 0.7165810046214314,specificity 0.9127683615819209,[tp,tn,fp,fn]: [16591, 68663, 6562, 8757]

TRAIN, epoch 46, loss 0.4304781779215012, acc 0.8111934856587263,recall 0.679447446492901,precision 0.7601386892678806,specificity 0.8830549615673583,[tp,tn,fp,fn]: [51301, 122236, 16188, 24203]
VAL, loss 0.3621118133072106, acc 0.8476330625515794,f1 0.685390490268539, recall 0.6585134921887328,precision 0.7145547945205479,specificity 0.9113592555666334,[tp,tn,fp,fn]: [16692, 68557, 6668, 8656]

TRAIN, epoch 47, loss 0.4304487317369218, acc 0.8112495792977077,recall 0.6798580207671117,precision 0.7600349427738048,specificity 0.8829177021325781,[tp,tn,fp,fn]: [51332, 122217, 16207, 24172]
VAL, loss 0.36057532702978157, acc 0.8478716951865809,f1 0.6849388410691488, recall 0.6561069906896008,precision 0.7164211251830792,specificity 0.9124891990694582,[tp,tn,fp,fn]: [16631, 68642, 6583, 8717]

TRAIN, epoch 48, loss 0.4301621636549156, acc 0.8115206985527841,recall 0.6804010383555839,precision 0.7603718011337567,specificity 0.8830405132058025,[tp,tn,fp,fn]: [51373, 122234, 16190, 24131]
VAL, loss 0.36065234262201207, acc 0.8478319230807473,f1 0.6852841984042115, recall 0.6573299668612909,precision 0.7157216494845361,specificity 0.9120239282153539,[tp,tn,fp,fn]: [16662, 68607, 6618, 8686]

TRAIN, epoch 49, loss 0.42981629631250146, acc 0.8114272091544819,recall 0.6804672600127145,precision 0.7601082952376725,specificity 0.882859908686355,[tp,tn,fp,fn]: [51378, 122209, 16215, 24126]
VAL, loss 0.3606771162956562, acc 0.8481998150597079,f1 0.6847159407719473, recall 0.6540160959444532,precision 0.7184398699891658,specificity 0.9136324360252576,[tp,tn,fp,fn]: [16578, 68728, 6497, 8770]



 * BEST_ACC: 0.8481998150597079
 * TIME: Time 2823.816 (2823.816)

