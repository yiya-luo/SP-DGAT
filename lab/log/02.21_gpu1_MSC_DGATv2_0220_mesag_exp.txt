pooling_ratio 0.2, dropout0.2, hidden_dim 64, outdim 128
epochs 100, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.5407314340636117, acc 0.7444981489099136,recall 0.4387449671540581,precision 0.7295249840340021,specificity 0.9112726116858348,[tp,tn,fp,fn]: [33127, 126142, 12282, 42377]
VAL, loss 0.42124406180994856, acc 0.8256589740785301,f1 0.5519497112485307, recall 0.4260691178791226,precision 0.7834034527781808,specificity 0.9603057494184114,[tp,tn,fp,fn]: [10800, 72239, 2986, 14548]

TRAIN, epoch 1, loss 0.48686516868484603, acc 0.7789536666542014,recall 0.5915580631489722,precision 0.730847269038191,specificity 0.8811694503843264,[tp,tn,fp,fn]: [44665, 121975, 16449, 30839]
VAL, loss 0.404064944533504, acc 0.8305012279637676,f1 0.5725319090248, recall 0.45037083793593186,precision 0.7856307205285252,specificity 0.9585908939847125,[tp,tn,fp,fn]: [11416, 72110, 3115, 13932]

TRAIN, epoch 2, loss 0.4738674502375238, acc 0.7862364907819454,recall 0.6187751642297097,precision 0.7338296736091477,specificity 0.8775790325377102,[tp,tn,fp,fn]: [46720, 121478, 16946, 28784]
VAL, loss 0.39201719267925816, acc 0.8369940242410985,f1 0.6052872345548226, recall 0.49589711219820104,precision 0.7765970591869517,specificity 0.951930874044533,[tp,tn,fp,fn]: [12570, 71609, 3616, 12778]

TRAIN, epoch 3, loss 0.4651235642523127, acc 0.7912148012415392,recall 0.6334763721127358,precision 0.7378781567701825,specificity 0.8772539444027048,[tp,tn,fp,fn]: [47830, 121433, 16991, 27674]
VAL, loss 0.3781404854565515, acc 0.8391715470354867,f1 0.6121382154761048, recall 0.503550575982326,precision 0.7804341180067258,specificity 0.9522632103688933,[tp,tn,fp,fn]: [12764, 71634, 3591, 12584]

TRAIN, epoch 4, loss 0.45893475942143436, acc 0.7943139747952582,recall 0.6398998728544183,precision 0.7418468247144085,specificity 0.8785398485811708,[tp,tn,fp,fn]: [48315, 121611, 16813, 27189]
VAL, loss 0.3737864642076701, acc 0.8405933998190369,f1 0.6193732193732193, recall 0.5145968123717848,precision 0.7777247793942285,specificity 0.9504420073113992,[tp,tn,fp,fn]: [13044, 71497, 3728, 12304]

TRAIN, epoch 5, loss 0.45517644294514303, acc 0.7971373546239856,recall 0.6490914388641661,precision 0.7435520087389246,specificity 0.8778896723111599,[tp,tn,fp,fn]: [49009, 121521, 16903, 26495]
VAL, loss 0.3711932912298449, acc 0.842591948137174,f1 0.6308843759472126, recall 0.5337304718320972,precision 0.7712787184311043,specificity 0.9466666666666667,[tp,tn,fp,fn]: [13529, 71213, 4012, 11819]

TRAIN, epoch 6, loss 0.45077504817159436, acc 0.7989323510713885,recall 0.6550381436745073,precision 0.7445578538524071,specificity 0.8774201005605964,[tp,tn,fp,fn]: [49458, 121456, 16968, 26046]
VAL, loss 0.36965476042232825, acc 0.8423632585286309,f1 0.6275606089081, recall 0.5269449266214297,precision 0.7756678281068525,specificity 0.9486473911598537,[tp,tn,fp,fn]: [13357, 71362, 3863, 11991]

TRAIN, epoch 7, loss 0.4489836615398245, acc 0.8003861112149883,recall 0.6585346471710108,precision 0.7460948636766052,specificity 0.8777596370571578,[tp,tn,fp,fn]: [49722, 121503, 16921, 25782]
VAL, loss 0.36368531897241363, acc 0.844789356984479,f1 0.6366725630760636, recall 0.5395691967808111,precision 0.7763964577656676,specificity 0.9476370887337986,[tp,tn,fp,fn]: [13677, 71286, 3939, 11671]

TRAIN, epoch 8, loss 0.4452581931886184, acc 0.8020969672039191,recall 0.6620841279932189,precision 0.7482076841333274,specificity 0.8784676067733919,[tp,tn,fp,fn]: [49990, 121601, 16823, 25514]
VAL, loss 0.36541608273640747, acc 0.8447098127728118,f1 0.637431516389637, recall 0.5416206406817106,precision 0.7744246389891697,specificity 0.946839481555334,[tp,tn,fp,fn]: [13729, 71226, 3999, 11619]

TRAIN, epoch 9, loss 0.44361548108413695, acc 0.8030271867170263,recall 0.6668123543123543,precision 0.7477869534220533,specificity 0.8773261862104837,[tp,tn,fp,fn]: [50347, 121443, 16981, 25157]
VAL, loss 0.3598197013284257, acc 0.8466089308263649,f1 0.646583125243408, recall 0.5567303140287202,precision 0.7710211440747419,specificity 0.9442871385842473,[tp,tn,fp,fn]: [14112, 71034, 4191, 11236]

TRAIN, epoch 10, loss 0.44070680253298233, acc 0.8048315321042594,recall 0.6693817546090274,precision 0.7506460715877024,specificity 0.8787132289198405,[tp,tn,fp,fn]: [50541, 121635, 16789, 24963]
VAL, loss 0.3607409737137308, acc 0.8463504121384468,f1 0.6420845396641575, recall 0.5468281521224554,precision 0.7775284680540753,specificity 0.9472781655034895,[tp,tn,fp,fn]: [13861, 71259, 3966, 11487]

TRAIN, epoch 11, loss 0.4391189721580094, acc 0.8053270259152612,recall 0.6745073108709473,precision 0.7489632048001412,specificity 0.8766832341212506,[tp,tn,fp,fn]: [50928, 121354, 17070, 24576]
VAL, loss 0.35756602877534654, acc 0.8477822079484554,f1 0.6500080016460529, recall 0.5608332018305192,precision 0.7729027347360409,specificity 0.944473246925889,[tp,tn,fp,fn]: [14216, 71048, 4177, 11132]

TRAIN, epoch 12, loss 0.4378168343503564, acc 0.8070612542537676,recall 0.675010595465141,precision 0.7527879119093689,specificity 0.8790888863202913,[tp,tn,fp,fn]: [50966, 121687, 16737, 24538]
VAL, loss 0.3556883650642165, acc 0.8489654280970041,f1 0.6556336431648152, recall 0.5704592078270475,precision 0.7707067476814838,specificity 0.9428115653040877,[tp,tn,fp,fn]: [14460, 70923, 4302, 10888]

TRAIN, epoch 13, loss 0.4363945449175606, acc 0.8072061628211361,recall 0.6758449883449883,precision 0.7526623204224313,specificity 0.8788577125353985,[tp,tn,fp,fn]: [51029, 121655, 16769, 24475]
VAL, loss 0.36058280051765607, acc 0.845853260815527,f1 0.637771910558658, recall 0.5384251222976172,precision 0.7820755257578362,specificity 0.9494449983383184,[tp,tn,fp,fn]: [13648, 71422, 3803, 11700]

TRAIN, epoch 14, loss 0.43533563040157053, acc 0.8074071650274859,recall 0.6766661368934096,precision 0.7526775585969151,specificity 0.8787204531006184,[tp,tn,fp,fn]: [51091, 121636, 16788, 24413]
VAL, loss 0.35435732854189533, acc 0.8489057699382538,f1 0.6564322857788831, recall 0.5727079059491873,precision 0.7688274547187798,specificity 0.9419740777667,[tp,tn,fp,fn]: [14517, 70860, 4365, 10831]

TRAIN, epoch 15, loss 0.4337905510484911, acc 0.8089450656295576,recall 0.6780700360245815,precision 0.7555414539122222,specificity 0.88033144541409,[tp,tn,fp,fn]: [51197, 121859, 16565, 24307]
VAL, loss 0.357858297692503, acc 0.8468773925407416,f1 0.6426748340990301, recall 0.5463547419914786,precision 0.7802253521126761,specificity 0.9481422399468262,[tp,tn,fp,fn]: [13849, 71324, 3901, 11499]

TRAIN, epoch 16, loss 0.4321213931526208, acc 0.8095387233087767,recall 0.6826393303666031,precision 0.7543651664837175,specificity 0.8787565740045079,[tp,tn,fp,fn]: [51542, 121641, 16783, 23962]
VAL, loss 0.3519687565306391, acc 0.8504469390393048,f1 0.6623566121175387, recall 0.5820183051917311,precision 0.7684254388249387,specificity 0.9408973080757727,[tp,tn,fp,fn]: [14753, 70779, 4446, 10595]

TRAIN, epoch 17, loss 0.4307693409507827, acc 0.8105250364608654,recall 0.6837518542063996,precision 0.7560704138718842,specificity 0.8796740449633011,[tp,tn,fp,fn]: [51626, 121768, 16656, 23878]
VAL, loss 0.3549256132277387, acc 0.8490748013880465,f1 0.6530276361807666, recall 0.5635158592393877,precision 0.7763465405728572,specificity 0.9452974410103024,[tp,tn,fp,fn]: [14284, 71110, 4115, 11064]

TRAIN, epoch 18, loss 0.4308957570862794, acc 0.8104081747129875,recall 0.6830101716465353,precision 0.7562137986655914,specificity 0.879897994567416,[tp,tn,fp,fn]: [51570, 121799, 16625, 23934]
VAL, loss 0.3516658321055583, acc 0.8515605580026449,f1 0.6666517807301552, recall 0.5889222029351429,precision 0.768019756135206,specificity 0.9400598205383849,[tp,tn,fp,fn]: [14928, 70716, 4509, 10420]

TRAIN, epoch 19, loss 0.42949644897866857, acc 0.8111280430799147,recall 0.6848246450519178,precision 0.756890873161092,specificity 0.8800208056406403,[tp,tn,fp,fn]: [51707, 121816, 16608, 23797]
VAL, loss 0.3527276008662926, acc 0.8504469390393048,f1 0.6592201554251534, recall 0.5739308821208774,precision 0.7742828250572144,specificity 0.9436224659355268,[tp,tn,fp,fn]: [14548, 70984, 4241, 10800]

TRAIN, epoch 20, loss 0.4279704140986471, acc 0.8120442391832766,recall 0.6887184784912057,precision 0.7568515580654082,specificity 0.8793128359244061,[tp,tn,fp,fn]: [52001, 121718, 16706, 23503]
VAL, loss 0.3526455757850815, acc 0.8509142612828493,f1 0.6601695299397126, recall 0.5745620956288464,precision 0.7757537019281986,specificity 0.9440345629777335,[tp,tn,fp,fn]: [14564, 71015, 4210, 10784]

TRAIN, epoch 21, loss 0.427074238749896, acc 0.8124976627650424,recall 0.6889701207883026,precision 0.7577788136580819,specificity 0.8798763220250824,[tp,tn,fp,fn]: [52020, 121796, 16628, 23484]
VAL, loss 0.3497947127704629, acc 0.8517097033995208,f1 0.6690484644061779, recall 0.5947214770396086,precision 0.764607425441266,specificity 0.9383050847457627,[tp,tn,fp,fn]: [15075, 70584, 4641, 10273]

TRAIN, epoch 22, loss 0.4266486346614659, acc 0.8130118544557047,recall 0.6900296673023946,precision 0.758391801799179,specificity 0.8800930474484193,[tp,tn,fp,fn]: [52100, 121826, 16598, 23404]
VAL, loss 0.34954031095981114, acc 0.851689817346604,f1 0.6658602150537635, recall 0.5863184472147704,precision 0.7703711382956666,specificity 0.9411100033233633,[tp,tn,fp,fn]: [14862, 70795, 4430, 10486]

TRAIN, epoch 23, loss 0.42607083953664876, acc 0.8128809692980816,recall 0.688559546514092,precision 0.7589191872007474,specificity 0.8806926544529851,[tp,tn,fp,fn]: [51989, 121909, 16515, 23515]
VAL, loss 0.35202512480490045, acc 0.850427052986388,f1 0.6577791933025456, recall 0.5703408552943033,precision 0.77688215379655,specificity 0.9448055832502492,[tp,tn,fp,fn]: [14457, 71073, 4152, 10891]

pooling_ratio 0.2, dropout0.2, hidden_dim 64, outdim 128
epochs 100, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.5349638791941727, acc 0.7611486107475413,recall 0.5065691883873702,precision 0.7342817101499357,specificity 0.900010113853089,[tp,tn,fp,fn]: [38248, 124583, 13841, 37256]
VAL, loss 0.40833265540499025, acc 0.8339514581448301,f1 0.593832084833155, recall 0.4816159065804008,precision 0.7742262810755961,specificity 0.9526753074111001,[tp,tn,fp,fn]: [12208, 71665, 3560, 13140]

TRAIN, epoch 1, loss 0.477839080561456, acc 0.7885316555102652,recall 0.6424825174825175,precision 0.7266871395401093,specificity 0.8681948217072184,[tp,tn,fp,fn]: [48510, 120179, 18245, 26994]
VAL, loss 0.3838549901984217, acc 0.8409414057450807,f1 0.6249150038687894, recall 0.5257219504497396,precision 0.770244494537888,specificity 0.9471585244267199,[tp,tn,fp,fn]: [13326, 71250, 3975, 12022]

TRAIN, epoch 2, loss 0.46702459426897325, acc 0.79292565723047,recall 0.6531044712862895,precision 0.7314258591791631,specificity 0.8691917586545685,[tp,tn,fp,fn]: [49312, 120317, 18107, 26192]
VAL, loss 0.37870356398399263, acc 0.8416771897030018,f1 0.6232580149059506, recall 0.5196070695912892,precision 0.7785659395873973,specificity 0.9502027251578598,[tp,tn,fp,fn]: [13171, 71479, 3746, 12177]

TRAIN, epoch 3, loss 0.4594189162645026, acc 0.7965904416439176,recall 0.6607994278448824,precision 0.7359175184742688,specificity 0.8706582673524822,[tp,tn,fp,fn]: [49893, 120520, 17904, 25611]
VAL, loss 0.3688962529467342, acc 0.8448887872490629,f1 0.6406523541877822, recall 0.5486034401136184,precision 0.7698184233835252,specificity 0.9447258225324028,[tp,tn,fp,fn]: [13906, 71067, 4158, 11442]

TRAIN, epoch 4, loss 0.4558189053804898, acc 0.7990445383493512,recall 0.6628655435473617,precision 0.7405450994318182,specificity 0.8733239900595272,[tp,tn,fp,fn]: [50049, 120889, 17535, 25455]
VAL, loss 0.3690035330359283, acc 0.8439441997355155,f1 0.632323658256612, recall 0.532428593971911,precision 0.7783609204683084,specificity 0.948913260219342,[tp,tn,fp,fn]: [13496, 71382, 3843, 11852]

TRAIN, epoch 5, loss 0.45130347885376165, acc 0.8007039751692158,recall 0.6655276541640178,precision 0.7430024692818382,specificity 0.8744365138993239,[tp,tn,fp,fn]: [50250, 121043, 17381, 25254]
VAL, loss 0.3633359467204325, acc 0.8469569367524087,f1 0.6493530162201567, recall 0.5622534322234496,precision 0.7683847315074401,specificity 0.9428913260219342,[tp,tn,fp,fn]: [14252, 70929, 4296, 11096]

TRAIN, epoch 6, loss 0.44847550529365715, acc 0.8026625780636476,recall 0.6705207671116762,precision 0.7448871494570815,specificity 0.8747399294919956,[tp,tn,fp,fn]: [50627, 121085, 17339, 24877]
VAL, loss 0.3645747226226215, acc 0.8462907539796963,f1 0.6459798016809032, recall 0.5564147072747356,precision 0.7699110213439598,specificity 0.9439680957128614,[tp,tn,fp,fn]: [14104, 71010, 4215, 11244]

TRAIN, epoch 7, loss 0.4463973811532158, acc 0.803312329381848,recall 0.6719246662428481,precision 0.7456458795690707,specificity 0.8749783274576663,[tp,tn,fp,fn]: [50733, 121118, 17306, 24771]
VAL, loss 0.36050389196142196, acc 0.8481600429538743,f1 0.6541658174241909, recall 0.5697885434748303,precision 0.7678770801212186,specificity 0.9419607843137255,[tp,tn,fp,fn]: [14443, 70859, 4366, 10905]

TRAIN, epoch 8, loss 0.4442855333039053, acc 0.8044482255712202,recall 0.6743616232252596,precision 0.7469778768851594,specificity 0.8754045541235624,[tp,tn,fp,fn]: [50917, 121177, 17247, 24587]
VAL, loss 0.36549706893607914, acc 0.844739641852187,f1 0.6347966414856048, recall 0.535387407290516,precision 0.7795393187431788,specificity 0.948979727484214,[tp,tn,fp,fn]: [13571, 71387, 3838, 11777]

TRAIN, epoch 9, loss 0.4427794835128904, acc 0.8050325343106092,recall 0.6738318499682137,precision 0.7486425638988213,specificity 0.8765965439519159,[tp,tn,fp,fn]: [50877, 121342, 17082, 24627]
VAL, loss 0.3580639399613666, acc 0.8483191313772086,f1 0.6525769204491106, recall 0.5652122455420546,precision 0.7718872905554658,specificity 0.9437155201063476,[tp,tn,fp,fn]: [14327, 70991, 4234, 11021]

TRAIN, epoch 10, loss 0.4405807718895951, acc 0.8058739388953293,recall 0.674666242848061,precision 0.7501656726308814,specificity 0.8774417731029301,[tp,tn,fp,fn]: [50940, 121459, 16965, 24564]
VAL, loss 0.3564283408318444, acc 0.8482594732184582,f1 0.6517105233128694, recall 0.5632791541738993,precision 0.7730792138177487,specificity 0.9442871385842473,[tp,tn,fp,fn]: [14278, 71034, 4191, 11070]

TRAIN, epoch 11, loss 0.4390201286795983, acc 0.8072716053999477,recall 0.6792355371900827,precision 0.7509224551950334,specificity 0.8771094607871467,[tp,tn,fp,fn]: [51285, 121413, 17011, 24219]
VAL, loss 0.35712757739560186, acc 0.8476628916309547,f1 0.6479145122371597, recall 0.5561385513649992,precision 0.7759674134419552,specificity 0.9458956463941509,[tp,tn,fp,fn]: [14097, 71155, 4070, 11251]

TRAIN, epoch 12, loss 0.43871400855892034, acc 0.8075614225346845,recall 0.6780700360245815,precision 0.7522554291927473,specificity 0.8781930879038317,[tp,tn,fp,fn]: [51197, 121563, 16861, 24307]
VAL, loss 0.35653888766719016, acc 0.8491742316526304,f1 0.6553674883562423, recall 0.5689995265898691,precision 0.772646917019339,specificity 0.9435825855766036,[tp,tn,fp,fn]: [14423, 70981, 4244, 10925]

TRAIN, epoch 13, loss 0.4362679375929383, acc 0.8082859653715269,recall 0.6801229073956346,precision 0.7528183777285855,specificity 0.8781930879038317,[tp,tn,fp,fn]: [51352, 121563, 16861, 24152]
VAL, loss 0.35624336530422, acc 0.8483887325624173,f1 0.6489224534905138, recall 0.5559412971437588,precision 0.7792523777925238,specificity 0.9469325357261549,[tp,tn,fp,fn]: [14092, 71233, 3992, 11256]

TRAIN, epoch 14, loss 0.43541333041780084, acc 0.8092769529935305,recall 0.6810764992583175,precision 0.7546261647956564,specificity 0.8792044732127376,[tp,tn,fp,fn]: [51424, 121703, 16721, 24080]
VAL, loss 0.35362198221007496, acc 0.8497608702136756,f1 0.6571830474634723, recall 0.571366577244753,precision 0.773334045279795,specificity 0.9435692921236292,[tp,tn,fp,fn]: [14483, 70980, 4245, 10865]

TRAIN, epoch 15, loss 0.4342684685617773, acc 0.8099454021913916,recall 0.6825731087094723,precision 0.7553643665357331,specificity 0.8794211986360747,[tp,tn,fp,fn]: [51537, 121733, 16691, 23967]
VAL, loss 0.3531211974398771, acc 0.8499895598222187,f1 0.6578368448506566, recall 0.5721555941297144,precision 0.7736996532408642,specificity 0.9436091724825524,[tp,tn,fp,fn]: [14503, 70983, 4242, 10845]

TRAIN, epoch 16, loss 0.433499370249933, acc 0.8096976552858905,recall 0.6819108921381649,precision 0.7551517284874085,specificity 0.879399526093741,[tp,tn,fp,fn]: [51487, 121730, 16694, 24017]
VAL, loss 0.35116313973614754, acc 0.8503872808805544,f1 0.6611722848972055, recall 0.5791778444058703,precision 0.7702114264729027,specificity 0.9417746759720838,[tp,tn,fp,fn]: [14681, 70845, 4380, 10667]

TRAIN, epoch 17, loss 0.43177472193878336, acc 0.8106979918477245,recall 0.683685632549269,precision 0.7565179160255001,specificity 0.8799774605559729,[tp,tn,fp,fn]: [51621, 121810, 16614, 23883]
VAL, loss 0.3521423347888611, acc 0.8510832927326419,f1 0.6633095789402694, recall 0.5820183051917311,precision 0.7709955578782336,specificity 0.9417480890661349,[tp,tn,fp,fn]: [14753, 70843, 4382, 10595]

TRAIN, epoch 18, loss 0.43142259940975897, acc 0.8105717811600165,recall 0.6824671540580631,precision 0.7569111901054673,specificity 0.8804470323065364,[tp,tn,fp,fn]: [51529, 121875, 16549, 23975]
VAL, loss 0.3521922511502428, acc 0.8502580215365954,f1 0.6589210490555781, recall 0.5738914312766293,precision 0.7735297245559928,specificity 0.9433831837819874,[tp,tn,fp,fn]: [14547, 70966, 4259, 10801]

TRAIN, epoch 19, loss 0.43060612173222385, acc 0.8118338880370966,recall 0.6856060606060606,precision 0.7581207346006268,specificity 0.8806854302722071,[tp,tn,fp,fn]: [51766, 121908, 16516, 23738]
VAL, loss 0.35320485369993093, acc 0.8500094458751355,f1 0.6577269530097791, recall 0.5718005365314818,precision 0.7740453938584779,specificity 0.9437554004652708,[tp,tn,fp,fn]: [14494, 70994, 4231, 10854]

TRAIN, epoch 20, loss 0.42951758085582487, acc 0.8122639392692869,recall 0.68519548633185,precision 0.7593794034758102,specificity 0.8815740045078888,[tp,tn,fp,fn]: [51735, 122031, 16393, 23769]
VAL, loss 0.35261295153456845, acc 0.8503574518011793,f1 0.6602402022756005, recall 0.5768896954394824,precision 0.7717437196537893,specificity 0.9425058158856763,[tp,tn,fp,fn]: [14623, 70900, 4325, 10725]

TRAIN, epoch 21, loss 0.42821225270627256, acc 0.8126799670917318,recall 0.6880165289256198,precision 0.7587526473380559,specificity 0.8806782060914292,[tp,tn,fp,fn]: [51948, 121907, 16517, 23556]
VAL, loss 0.35048374050280057, acc 0.8512722102353515,f1 0.6629562866155927, recall 0.5803613697333123,precision 0.7729613282891972,specificity 0.9425589896975739,[tp,tn,fp,fn]: [14711, 70904, 4321, 10637]

TRAIN, epoch 22, loss 0.42842035695616787, acc 0.8123387307879286,recall 0.686082856537402,precision 0.759048149342086,specificity 0.8812055712882159,[tp,tn,fp,fn]: [51802, 121980, 16444, 23702]
VAL, loss 0.35065061968159705, acc 0.8510236345738916,f1 0.6607801851977632, recall 0.5757061701120404,precision 0.7753573136390203,specificity 0.9437952808241941,[tp,tn,fp,fn]: [14593, 70997, 4228, 10755]

TRAIN, epoch 23, loss 0.4270140283047397, acc 0.8129417374069781,recall 0.6863609874973511,precision 0.7603251221408764,specificity 0.8819857828122291,[tp,tn,fp,fn]: [51823, 122088, 16336, 23681]
VAL, loss 0.35026434973137405, acc 0.8509341473357661,f1 0.6605379947468526, recall 0.5754300142023039,precision 0.7751913265306123,specificity 0.9437686939182452,[tp,tn,fp,fn]: [14586, 70995, 4230, 10762]

TRAIN, epoch 24, loss 0.4264842550937589, acc 0.8133110205302718,recall 0.687592710319983,precision 0.760495707965898,specificity 0.8818846442813385,[tp,tn,fp,fn]: [51916, 122074, 16350, 23588]
VAL, loss 0.34894798448187236, acc 0.8516500452407704,f1 0.6650502873563218, recall 0.584345905002367,precision 0.7716190873098562,specificity 0.9417215021601861,[tp,tn,fp,fn]: [14812, 70841, 4384, 10536]

TRAIN, epoch 25, loss 0.42594503630300246, acc 0.8137130249429715,recall 0.688652256834075,precision 0.7608428446005268,specificity 0.8819279893660059,[tp,tn,fp,fn]: [51996, 122080, 16344, 23508]
VAL, loss 0.350376329224071, acc 0.850983862468058,f1 0.6596416324120546, recall 0.5729446110146758,precision 0.7772544822049773,specificity 0.9446726487205052,[tp,tn,fp,fn]: [14523, 71063, 4162, 10825]

TRAIN, epoch 26, loss 0.4251792848963891, acc 0.8141243782955013,recall 0.6892482517482518,precision 0.761479031927658,specificity 0.8822386291394556,[tp,tn,fp,fn]: [52041, 122123, 16301, 23463]
VAL, loss 0.3485215610443275, acc 0.8524952024897339,f1 0.6697388632872504, recall 0.5934195991794224,precision 0.7685861734198559,specificity 0.9397939514788967,[tp,tn,fp,fn]: [15042, 70696, 4529, 10306]

TRAIN, epoch 27, loss 0.42460046668295365, acc 0.8143020081522755,recall 0.6914600550964187,precision 0.7606282234330837,specificity 0.8813067098191065,[tp,tn,fp,fn]: [52208, 121994, 16430, 23296]
VAL, loss 0.35017518648141943, acc 0.8516997603730624,f1 0.666592153794568, recall 0.5882120877386776,precision 0.7690720585959664,specificity 0.940485211033566,[tp,tn,fp,fn]: [14910, 70748, 4477, 10438]

TRAIN, epoch 28, loss 0.42371775642823656, acc 0.8151293893272503,recall 0.6913805891078618,precision 0.7626407982585575,specificity 0.8826287349014622,[tp,tn,fp,fn]: [52202, 122177, 16247, 23302]
VAL, loss 0.3499488125203711, acc 0.8522366838018156,f1 0.6674721979816964, recall 0.5884093419599179,precision 0.7710799772527529,specificity 0.9411365902293121,[tp,tn,fp,fn]: [14915, 70797, 4428, 10433]

TRAIN, epoch 29, loss 0.4239985963904257, acc 0.8147040125649752,recall 0.690413752913753,precision 0.7621867415270346,specificity 0.88249869964746,[tp,tn,fp,fn]: [52129, 122159, 16265, 23375]
VAL, loss 0.34883069722294596, acc 0.8521770256430652,f1 0.666621818589528, recall 0.5863973489032666,precision 0.7722761988881384,specificity 0.9417347956131605,[tp,tn,fp,fn]: [14864, 70842, 4383, 10484]

TRAIN, epoch 30, loss 0.42350798101821213, acc 0.8148582700721738,recall 0.6901488662852299,precision 0.7627083912706196,specificity 0.8828815812286886,[tp,tn,fp,fn]: [52109, 122212, 16212, 23395]
VAL, loss 0.3494216425466823, acc 0.852017937219731,f1 0.6655280131244804, recall 0.5841486507811268,precision 0.7732518669382213,specificity 0.9422798271851114,[tp,tn,fp,fn]: [14807, 70883, 4342, 10541]

TRAIN, epoch 31, loss 0.4226219780097559, acc 0.8152228787255525,recall 0.6910759694850604,precision 0.7630405217671059,specificity 0.8829393746749119,[tp,tn,fp,fn]: [52179, 122220, 16204, 23325]
VAL, loss 0.34929122898656945, acc 0.8529128096009864,f1 0.6690085695746537, recall 0.5897901215086003,precision 0.77280951150168,specificity 0.9415752741774676,[tp,tn,fp,fn]: [14950, 70830, 4395, 10398]

TRAIN, epoch 32, loss 0.4215679452447901, acc 0.8152649489547885,recall 0.6906918838737021,precision 0.7633643655951754,specificity 0.8832138935444721,[tp,tn,fp,fn]: [52150, 122258, 16166, 23354]
VAL, loss 0.3500881061594193, acc 0.8521471965636901,f1 0.6648787523663571, recall 0.5819394035032349,precision 0.7753889823380993,specificity 0.9431970754403456,[tp,tn,fp,fn]: [14751, 70952, 4273, 10597]

TRAIN, epoch 33, loss 0.4217489335204931, acc 0.8154799745708836,recall 0.6912349014621741,precision 0.7635621488764045,specificity 0.8832500144483616,[tp,tn,fp,fn]: [52191, 122263, 16161, 23313]
VAL, loss 0.34759807621736316, acc 0.8522565698547324,f1 0.665526167698368, recall 0.5832018305191731,precision 0.7749121979346858,specificity 0.9429179129278831,[tp,tn,fp,fn]: [14783, 70931, 4294, 10565]

TRAIN, epoch 34, loss 0.42127087715519895, acc 0.8157931640551962,recall 0.6929434202161475,precision 0.7633164582816626,specificity 0.8828021152401317,[tp,tn,fp,fn]: [52320, 122201, 16223, 23184]
VAL, loss 0.3478235314786642, acc 0.8530022968391119,f1 0.6700736442758313, recall 0.5922755246962285,precision 0.7714006782447848,specificity 0.9408574277168494,[tp,tn,fp,fn]: [15013, 70776, 4449, 10335]

TRAIN, epoch 35, loss 0.4207171194550968, acc 0.816246587636962,recall 0.6929831532104259,precision 0.7643750365219424,specificity 0.8834811882332544,[tp,tn,fp,fn]: [52323, 122295, 16129, 23181]
VAL, loss 0.34757462520842286, acc 0.853409960923906,f1 0.6725160487794043, recall 0.5972068802272369,precision 0.7695592496568553,specificity 0.939740777666999,[tp,tn,fp,fn]: [15138, 70692, 4533, 10210]

TRAIN, epoch 36, loss 0.41991009648604694, acc 0.8163494259750944,recall 0.6933672388217843,precision 0.7643966826305338,specificity 0.8834306189678091,[tp,tn,fp,fn]: [52352, 122288, 16136, 23152]
VAL, loss 0.34835327445568637, acc 0.8528233223628608,f1 0.6663059651021236, recall 0.5830045762979328,precision 0.7773803261441347,specificity 0.9437421070122964,[tp,tn,fp,fn]: [14778, 70993, 4232, 10570]

TRAIN, epoch 37, loss 0.41962081778803306, acc 0.8161764705882353,recall 0.6932215511760966,precision 0.7640687269170693,specificity 0.8832427902675837,[tp,tn,fp,fn]: [52341, 122262, 16162, 23163]
VAL, loss 0.3489236178918601, acc 0.8524653734103587,f1 0.6639184597961495, recall 0.5781915732996686,precision 0.7794915434528241,specificity 0.9448853439680958,[tp,tn,fp,fn]: [14656, 71079, 4146, 10692]

TRAIN, epoch 38, loss 0.4194109517562577, acc 0.8165924984106803,recall 0.6922679593134139,precision 0.7656217958107514,specificity 0.8844058833728256,[tp,tn,fp,fn]: [52269, 122423, 16001, 23235]
VAL, loss 0.34863799213395597, acc 0.8533602457916141,f1 0.670877036375809, recall 0.5929856398926937,precision 0.7723255574966602,specificity 0.9410967098703888,[tp,tn,fp,fn]: [15031, 70794, 4431, 10317]

TRAIN, epoch 39, loss 0.418812400270679, acc 0.8165177068920384,recall 0.6936188811188811,precision 0.7646517739816031,specificity 0.8835534300410334,[tp,tn,fp,fn]: [52371, 122305, 16119, 23133]
VAL, loss 0.3487259838247272, acc 0.8531216131566126,f1 0.6683132746542123, recall 0.5871074640997317,precision 0.7755889097352512,specificity 0.9427583914921901,[tp,tn,fp,fn]: [14882, 70919, 4306, 10466]

TRAIN, epoch 40, loss 0.4185012631010472, acc 0.8172889944280318,recall 0.6953671328671329,precision 0.765472597646853,specificity 0.8837918280067041,[tp,tn,fp,fn]: [52503, 122338, 16086, 23001]
VAL, loss 0.34677069065665755, acc 0.8541358018553687,f1 0.6727053678996922, recall 0.5947609278838567,precision 0.7741604190202321,specificity 0.9415353938185443,[tp,tn,fp,fn]: [15076, 70827, 4398, 10272]

TRAIN, epoch 41, loss 0.41800649516455257, acc 0.8168215474365207,recall 0.6951022462386098,precision 0.7645122288744192,specificity 0.8832138935444721,[tp,tn,fp,fn]: [52483, 122258, 16166, 23021]
VAL, loss 0.3477083339601364, acc 0.8531812713153629,f1 0.6661541939859824, recall 0.5811898374625217,precision 0.7802139603855524,specificity 0.944832170156198,[tp,tn,fp,fn]: [14732, 71075, 4150, 10616]

TRAIN, epoch 42, loss 0.4175878241243067, acc 0.8174806476945514,recall 0.6948903369357915,precision 0.7662100589987733,specificity 0.8843480899266023,[tp,tn,fp,fn]: [52467, 122415, 16009, 23037]
VAL, loss 0.34962775612686736, acc 0.8520477662991062,f1 0.6614796614796614, recall 0.5735363736783967,precision 0.7812768701633706,specificity 0.9458956463941509,[tp,tn,fp,fn]: [14538, 71155, 4070, 10810]

TRAIN, epoch 43, loss 0.41732882239699903, acc 0.8175273923937025,recall 0.6945592286501377,precision 0.766516604303087,specificity 0.8846009362538289,[tp,tn,fp,fn]: [52442, 122450, 15974, 23062]
VAL, loss 0.34492380261623, acc 0.8542849472522447,f1 0.6727114366750787, recall 0.5941691652201357,precision 0.775181429821401,specificity 0.9419341974077766,[tp,tn,fp,fn]: [15061, 70857, 4368, 10287]

TRAIN, epoch 44, loss 0.41683445184857854, acc 0.8179200478665719,recall 0.6954201101928374,precision 0.7669510093190383,specificity 0.8847381956886089,[tp,tn,fp,fn]: [52507, 122469, 15955, 22997]
VAL, loss 0.34776130715617526, acc 0.8534795621091148,f1 0.6680782052437156, recall 0.5850560201988323,precision 0.7785594288114238,specificity 0.9439282153539382,[tp,tn,fp,fn]: [14830, 71007, 4218, 10518]

TRAIN, epoch 45, loss 0.41686922129342385, acc 0.8178826521072511,recall 0.6949962915872007,precision 0.7671110721281759,specificity 0.8849115760272785,[tp,tn,fp,fn]: [52475, 122493, 15931, 23029]
VAL, loss 0.34702257133460496, acc 0.8533602457916141,f1 0.669208684729948, recall 0.5885276944926622,precision 0.7755250571844459,specificity 0.9425988700564972,[tp,tn,fp,fn]: [14918, 70907, 4318, 10430]

TRAIN, epoch 46, loss 0.41699703773463087, acc 0.8178125350585244,recall 0.6951154905700361,precision 0.766872689548357,specificity 0.8847381956886089,[tp,tn,fp,fn]: [52484, 122469, 15955, 23020]
VAL, loss 0.34487521226213835, acc 0.8549909021307905,f1 0.6749721417428125, recall 0.5974041344484772,precision 0.7756889662944371,specificity 0.9417879694250582,[tp,tn,fp,fn]: [15143, 70846, 4379, 10205]

TRAIN, epoch 47, loss 0.415951162172119, acc 0.8184155416775738,recall 0.697327293918203,precision 0.767015325447235,specificity 0.8844636768190487,[tp,tn,fp,fn]: [52651, 122431, 15993, 22853]
VAL, loss 0.34709264209711366, acc 0.853738080797033,f1 0.6698536672950894, recall 0.5887249487139025,precision 0.7769158683881716,specificity 0.9430375540046527,[tp,tn,fp,fn]: [14923, 70940, 4285, 10425]

TRAIN, epoch 48, loss 0.416083064936231, acc 0.8189811525373023,recall 0.6969829413011231,precision 0.768573556688233,specificity 0.8855256313934,[tp,tn,fp,fn]: [52625, 122578, 15846, 22879]
VAL, loss 0.347502308154018, acc 0.8535193342149483,f1 0.6680935430090569, recall 0.584937667666088,precision 0.7788107994537241,specificity 0.9440212695247591,[tp,tn,fp,fn]: [14827, 71014, 4211, 10521]

TRAIN, epoch 49, loss 0.41562599950643436, acc 0.8191541079241614,recall 0.6977776011866921,precision 0.768518248388132,specificity 0.8853594752355083,[tp,tn,fp,fn]: [52685, 122555, 15869, 22819]
VAL, loss 0.34609073977127913, acc 0.8541755739612024,f1 0.6739149768765562, recall 0.597877544579454,precision 0.7721112696148359,specificity 0.9405383848454636,[tp,tn,fp,fn]: [15155, 70752, 4473, 10193]

TRAIN, epoch 50, loss 0.41490806874294145, acc 0.8189624546576418,recall 0.6979100445009536,precision 0.7679807622240035,specificity 0.8849910420158354,[tp,tn,fp,fn]: [52695, 122504, 15920, 22809]
VAL, loss 0.3478910320317053, acc 0.8540065425114096,f1 0.6694730207325035, recall 0.5866340539687549,precision 0.7795543905635649,specificity 0.9441010302426055,[tp,tn,fp,fn]: [14870, 71020, 4205, 10478]

TRAIN, epoch 51, loss 0.4144677685376643, acc 0.8190465951161139,recall 0.6979232888323798,precision 0.7681744631845945,specificity 0.8851138530890597,[tp,tn,fp,fn]: [52696, 122521, 15903, 22808]
VAL, loss 0.3469658326029608, acc 0.8543644914639118,f1 0.6745038778639526, recall 0.5987060123086634,precision 0.7722762200396927,specificity 0.9405117979395148,[tp,tn,fp,fn]: [15176, 70750, 4475, 10172]

TRAIN, epoch 52, loss 0.4145214090903282, acc 0.8194345761190681,recall 0.698916613689341,precision 0.7685171700696123,specificity 0.8851716465352829,[tp,tn,fp,fn]: [52771, 122529, 15895, 22733]
VAL, loss 0.3464068135782483, acc 0.8544539787020373,f1 0.6747111111111112, recall 0.5989032665299038,precision 0.7724913494809689,specificity 0.9405649717514124,[tp,tn,fp,fn]: [15181, 70754, 4471, 10167]

TRAIN, epoch 53, loss 0.4150955141613761, acc 0.8191868292135672,recall 0.6978703115066751,precision 0.7685418824112834,specificity 0.8853594752355083,[tp,tn,fp,fn]: [52692, 122555, 15869, 22812]
VAL, loss 0.34697307038666986, acc 0.8538076819822418,f1 0.6718153612642576, recall 0.593695755089159,precision 0.7736081838276873,specificity 0.9414556331006979,[tp,tn,fp,fn]: [15049, 70821, 4404, 10299]

TRAIN, epoch 54, loss 0.41505143856606397, acc 0.8187614524512921,recall 0.6968240093240093,precision 0.7681402750605892,specificity 0.8852727850661735,[tp,tn,fp,fn]: [52613, 122543, 15881, 22891]
VAL, loss 0.34805820244250585, acc 0.8537181947441163,f1 0.6683648167350433, recall 0.5848587659775919,precision 0.7796886504680761,specificity 0.9443137254901961,[tp,tn,fp,fn]: [14825, 71036, 4189, 10523]

TRAIN, epoch 55, loss 0.41386186900703587, acc 0.818929733368236,recall 0.6976981351981352,precision 0.7680274092433299,specificity 0.8850560596428365,[tp,tn,fp,fn]: [52679, 122513, 15911, 22825]
VAL, loss 0.34600100478295803, acc 0.8538772831674505,f1 0.6688598467778278, recall 0.5855294303298091,precision 0.7798444724674233,specificity 0.9443004320372217,[tp,tn,fp,fn]: [14842, 71035, 4190, 10506]

TRAIN, epoch 56, loss 0.41394984967323156, acc 0.8199908380389663,recall 0.6981749311294766,precision 0.7702929787389494,specificity 0.8864358781714153,[tp,tn,fp,fn]: [52715, 122704, 15720, 22789]
VAL, loss 0.3483616593211847, acc 0.8538573971145337,f1 0.669380960950153, recall 0.5869891115669875,precision 0.7786790872932803,specificity 0.9437819873712197,[tp,tn,fp,fn]: [14879, 70996, 4229, 10469]

TRAIN, epoch 57, loss 0.4138154588860682, acc 0.8193784824800867,recall 0.6985855054036872,precision 0.768578422801189,specificity 0.8852655608853955,[tp,tn,fp,fn]: [52746, 122542, 15882, 22758]
VAL, loss 0.3453605337651625, acc 0.855458224374335,f1 0.6759546153674684, recall 0.5981537004891905,precision 0.7770204479065238,specificity 0.9421601861083416,[tp,tn,fp,fn]: [15162, 70874, 4351, 10186]

TRAIN, epoch 58, loss 0.413244911704779, acc 0.819972140159306,recall 0.6989298580207671,precision 0.7697985500269864,specificity 0.8859952031439635,[tp,tn,fp,fn]: [52772, 122643, 15781, 22732]
VAL, loss 0.3463460311257895, acc 0.8547721555487059,f1 0.673448399213021, recall 0.5941691652201357,precision 0.7771413828689371,specificity 0.9425855766035227,[tp,tn,fp,fn]: [15061, 70906, 4319, 10287]

TRAIN, epoch 59, loss 0.41346846231302975, acc 0.8192335739127183,recall 0.6985722610722611,precision 0.7682392181423598,specificity 0.8850488354620586,[tp,tn,fp,fn]: [52745, 122512, 15912, 22759]
VAL, loss 0.3463457711806604, acc 0.8546031240989133,f1 0.6711050133825149, recall 0.5885671453369102,precision 0.7805681996546853,specificity 0.9442472582253241,[tp,tn,fp,fn]: [14919, 71031, 4194, 10429]

TRAIN, epoch 60, loss 0.4126944384232165, acc 0.8205237276092892,recall 0.6993006993006993,precision 0.7709042063920807,specificity 0.8866453794139745,[tp,tn,fp,fn]: [52800, 122733, 15691, 22704]
VAL, loss 0.34803169449982463, acc 0.8540264285643264,f1 0.6708812518214631, recall 0.5903029824838252,precision 0.77693545874656,specificity 0.9428913260219342,[tp,tn,fp,fn]: [14963, 70929, 4296, 10385]

TRAIN, epoch 61, loss 0.41244569682940324, acc 0.8194252271792378,recall 0.6988901250264886,precision 0.7685104275894209,specificity 0.8851716465352829,[tp,tn,fp,fn]: [52769, 122529, 15895, 22735]
VAL, loss 0.3469532106785521, acc 0.8544639217284957,f1 0.670181842763469, recall 0.586673504813003,precision 0.7814092795964479,specificity 0.944699235626454,[tp,tn,fp,fn]: [14871, 71065, 4160, 10477]

TRAIN, epoch 62, loss 0.41287099656881826, acc 0.8197056953741446,recall 0.6996980292434838,precision 0.7687047114629106,specificity 0.885164422354505,[tp,tn,fp,fn]: [52830, 122528, 15896, 22674]
VAL, loss 0.3452192585001423, acc 0.8552096487128752,f1 0.6767160998135155, recall 0.6012703171847877,precision 0.7738119415109667,specificity 0.940777666999003,[tp,tn,fp,fn]: [15241, 70770, 4455, 10107]

TRAIN, epoch 63, loss 0.412161952566759, acc 0.8204021913914962,recall 0.6998304725577453,precision 0.7702960770879193,specificity 0.886168583482633,[tp,tn,fp,fn]: [52840, 122667, 15757, 22664]
VAL, loss 0.34613640227703346, acc 0.8549411869984986,f1 0.6731928048206806, recall 0.5927883856714534,precision 0.7788317006168041,specificity 0.9432768361581921,[tp,tn,fp,fn]: [15026, 70958, 4267, 10322]

TRAIN, epoch 64, loss 0.4121463251755387, acc 0.8206312404173367,recall 0.6992609663064209,precision 0.7711869358184102,specificity 0.8868332081141999,[tp,tn,fp,fn]: [52797, 122759, 15665, 22707]
VAL, loss 0.3462652091609965, acc 0.8549312439720402,f1 0.6729726094947774, recall 0.5922360738519804,precision 0.7791965119900343,specificity 0.9434496510468594,[tp,tn,fp,fn]: [15012, 70971, 4254, 10336]

TRAIN, epoch 65, loss 0.41178097196338753, acc 0.8203881679817508,recall 0.6975259588895952,precision 0.7716403914903592,specificity 0.8874039183956539,[tp,tn,fp,fn]: [52666, 122838, 15586, 22838]
VAL, loss 0.34789037815078594, acc 0.8543843775168286,f1 0.6685226681152532, recall 0.5826100678554521,precision 0.7841554717782616,specificity 0.9459621136590229,[tp,tn,fp,fn]: [14768, 71160, 4065, 10580]

TRAIN, epoch 66, loss 0.41168621878100425, acc 0.820266631763958,recall 0.7003470014833652,precision 0.7696640661387983,specificity 0.8856773391897359,[tp,tn,fp,fn]: [52879, 122599, 15825, 22625]
VAL, loss 0.34918164104608773, acc 0.8534298469768228,f1 0.6662591410265118, recall 0.5804797222660565,precision 0.7817863025344031,specificity 0.9454037886340977,[tp,tn,fp,fn]: [14714, 71118, 4107, 10634]

TRAIN, epoch 67, loss 0.4113445421727129, acc 0.8205050297296287,recall 0.699724517906336,precision 0.7706063390656223,specificity 0.8863853089059701,[tp,tn,fp,fn]: [52832, 122697, 15727, 22672]
VAL, loss 0.3455656901397969, acc 0.855279249898084,f1 0.6755967637684712, recall 0.597916995423702,precision 0.7764742046211384,specificity 0.9420006646726488,[tp,tn,fp,fn]: [15156, 70862, 4363, 10192]

TRAIN, epoch 68, loss 0.41099002569727744, acc 0.821145432107999,recall 0.7009429963975419,precision 0.7714194093811036,specificity 0.8867103970409755,[tp,tn,fp,fn]: [52924, 122742, 15682, 22580]
VAL, loss 0.34632454699174875, acc 0.8547124973899556,f1 0.6713745951781216, recall 0.5888433012466466,precision 0.7808118853316593,specificity 0.9443004320372217,[tp,tn,fp,fn]: [14926, 71035, 4190, 10422]

TRAIN, epoch 69, loss 0.4108110901486129, acc 0.8207621255749598,recall 0.7003999788090697,precision 0.7708217940121855,specificity 0.8864142056290817,[tp,tn,fp,fn]: [52883, 122701, 15723, 22621]
VAL, loss 0.34807113353596936, acc 0.8544539787020373,f1 0.6700031561386898, recall 0.5862395455262742,precision 0.7816938453445555,specificity 0.944832170156198,[tp,tn,fp,fn]: [14860, 71075, 4150, 10488]

TRAIN, epoch 70, loss 0.4104642175537259, acc 0.8201217231965895,recall 0.7000291375291375,precision 0.7695051465342787,specificity 0.8856267699242906,[tp,tn,fp,fn]: [52855, 122592, 15832, 22649]
VAL, loss 0.34637615895342244, acc 0.8545931810724549,f1 0.6705267426666066, recall 0.5870680132554836,precision 0.7816472318520853,specificity 0.9447391159853772,[tp,tn,fp,fn]: [14881, 71068, 4157, 10467]

TRAIN, epoch 71, loss 0.4100688130241883, acc 0.8217718110766239,recall 0.7027972027972028,precision 0.7718175471259018,specificity 0.8866670519563081,[tp,tn,fp,fn]: [53064, 122736, 15688, 22440]
VAL, loss 0.34618015326734003, acc 0.8549610730514154,f1 0.6722685299602328, recall 0.5902240807953291,precision 0.7808047596680758,specificity 0.9441674975074775,[tp,tn,fp,fn]: [14961, 71025, 4200, 10387]

TRAIN, epoch 72, loss 0.4100498395624828, acc 0.8210285703601211,recall 0.698651727060818,precision 0.7725122647726441,specificity 0.8877795757961047,[tp,tn,fp,fn]: [52751, 122890, 15534, 22753]
VAL, loss 0.34569754256223817, acc 0.8551102184482913,f1 0.6747466630953975, recall 0.5962995108095314,precision 0.7769610362907371,specificity 0.9423197075440346,[tp,tn,fp,fn]: [15115, 70886, 4339, 10233]

TRAIN, epoch 73, loss 0.4095436621165205, acc 0.8210519427096967,recall 0.7006516211061665,precision 0.7713685806771456,specificity 0.8867248454025314,[tp,tn,fp,fn]: [52902, 122744, 15680, 22602]
VAL, loss 0.34366626088639773, acc 0.8560945780676722,f1 0.6794533897366614, recall 0.6051364999210983,precision 0.7745796091501288,specificity 0.9406580259222334,[tp,tn,fp,fn]: [15339, 70761, 4464, 10009]

TRAIN, epoch 74, loss 0.4094074515566001, acc 0.821481993941887,recall 0.7008767747404111,precision 0.7722695697857684,specificity 0.8872666589608739,[tp,tn,fp,fn]: [52919, 122819, 15605, 22585]
VAL, loss 0.34680466382377545, acc 0.8550107881837073,f1 0.6754362535612536, recall 0.5985876597759192,precision 0.774923391215526,specificity 0.9414157527417747,[tp,tn,fp,fn]: [15173, 70818, 4407, 10175]

TRAIN, epoch 75, loss 0.40998218090165717, acc 0.8214773194719719,recall 0.7013535706717525,precision 0.771972535242066,specificity 0.8869993642720916,[tp,tn,fp,fn]: [52955, 122782, 15642, 22549]
VAL, loss 0.34546200357130913, acc 0.8551301045012081,f1 0.6740783822476735, recall 0.5944058702856241,precision 0.7784149617689605,specificity 0.9429843801927551,[tp,tn,fp,fn]: [15067, 70936, 4289, 10281]

TRAIN, epoch 76, loss 0.40895284553333966, acc 0.8218559515350959,recall 0.70201578724306,precision 0.7724874664801212,specificity 0.8872233138762065,[tp,tn,fp,fn]: [53005, 122813, 15611, 22499]
VAL, loss 0.3449175533416149, acc 0.8557366291151701,f1 0.6765931836925752, recall 0.5987454631529114,precision 0.7777094542659493,specificity 0.942333000997009,[tp,tn,fp,fn]: [15177, 70887, 4338, 10171]

TRAIN, epoch 77, loss 0.40886371704921426, acc 0.8213417598444337,recall 0.7007840644204281,precision 0.7719871607820251,specificity 0.8871005028029821,[tp,tn,fp,fn]: [52912, 122796, 15628, 22592]
VAL, loss 0.3443128243124652, acc 0.8558957175385044,f1 0.6780835610048643, recall 0.6021776866024933,precision 0.7758857317135159,specificity 0.9413891658358259,[tp,tn,fp,fn]: [15264, 70816, 4409, 10084]

TRAIN, epoch 78, loss 0.4092023885199717, acc 0.8215193897012079,recall 0.7018833439287985,precision 0.7717568590901147,specificity 0.8867754146679766,[tp,tn,fp,fn]: [52995, 122751, 15673, 22509]
VAL, loss 0.3460344140841832, acc 0.8550107881837073,f1 0.6744362580933244, recall 0.5958655515228026,precision 0.7768748071186092,specificity 0.942333000997009,[tp,tn,fp,fn]: [15104, 70887, 4338, 10244]

TRAIN, epoch 79, loss 0.40834778351361317, acc 0.82265528589058,recall 0.7034064420428057,precision 0.7735780351030515,specificity 0.8877001098075479,[tp,tn,fp,fn]: [53110, 122879, 15545, 22394]
VAL, loss 0.34617704029148794, acc 0.8555775406918358,f1 0.6784014170264585, recall 0.604386933880385,precision 0.7730736236564566,specificity 0.9402193419740777,[tp,tn,fp,fn]: [15320, 70728, 4497, 10028]

TRAIN, epoch 80, loss 0.4075074610281381, acc 0.8227955199880334,recall 0.7019230769230769,precision 0.7748132337246532,specificity 0.8887259434780096,[tp,tn,fp,fn]: [52998, 123021, 15403, 22506]
VAL, loss 0.3465401217575594, acc 0.8551499905541249,f1 0.6752853067047075, recall 0.5976013886697176,precision 0.776183644189383,specificity 0.9419341974077766,[tp,tn,fp,fn]: [15148, 70857, 4368, 10200]

TRAIN, epoch 81, loss 0.40813567999288286, acc 0.8227908455181182,recall 0.7023071625344353,precision 0.7745690914402571,specificity 0.8885092180546726,[tp,tn,fp,fn]: [53027, 122991, 15433, 22477]
VAL, loss 0.34391020578806875, acc 0.8562636095174649,f1 0.6803043035959131, recall 0.6067934353795171,precision 0.7740815299446402,specificity 0.940325689597873,[tp,tn,fp,fn]: [15381, 70736, 4489, 9967]

TRAIN, epoch 82, loss 0.4081762318305153, acc 0.8220663026812759,recall 0.7015389913117186,precision 0.7732813617717047,specificity 0.8878084725192164,[tp,tn,fp,fn]: [52969, 122894, 15530, 22535]
VAL, loss 0.34716857845400584, acc 0.8554880534537103,f1 0.6739793629430237, recall 0.5926700331387091,precision 0.781146006655574,specificity 0.9440478564307079,[tp,tn,fp,fn]: [15023, 71016, 4209, 10325]

TRAIN, epoch 83, loss 0.4073335777493539, acc 0.8228562880969298,recall 0.7035521296884933,precision 0.7739749978144943,specificity 0.8879312835924407,[tp,tn,fp,fn]: [53121, 122911, 15513, 22383]
VAL, loss 0.34568453776252844, acc 0.8560448629353803,f1 0.6784381663113006, recall 0.6025327442007259,precision 0.776224842447652,specificity 0.9414689265536723,[tp,tn,fp,fn]: [15273, 70822, 4403, 10075]

TRAIN, epoch 84, loss 0.40716998198239135, acc 0.8228329157473543,recall 0.7032077770714135,precision 0.7741262921544899,specificity 0.8880829913887766,[tp,tn,fp,fn]: [53095, 122932, 15492, 22409]
VAL, loss 0.3437370895682982, acc 0.8568303620255934,f1 0.6831275720164609, recall 0.6123165535742465,precision 0.7724580699746181,specificity 0.939222333000997,[tp,tn,fp,fn]: [15521, 70653, 4572, 9827]

TRAIN, epoch 85, loss 0.40704697116650523, acc 0.823113383942261,recall 0.7033137317228226,precision 0.7747399442685613,specificity 0.8884586487892273,[tp,tn,fp,fn]: [53103, 122984, 15440, 22401]
VAL, loss 0.34495227860633293, acc 0.8557664581945452,f1 0.6764942016057092, recall 0.5983509547104308,precision 0.7781140980915248,specificity 0.9425058158856763,[tp,tn,fp,fn]: [15167, 70900, 4325, 10181]

TRAIN, epoch 86, loss 0.40617887304695904, acc 0.8231694775812423,recall 0.7038435049798686,precision 0.7745551004940898,specificity 0.8882563717274461,[tp,tn,fp,fn]: [53143, 122956, 15468, 22361]
VAL, loss 0.3423951549955517, acc 0.8570789376870532,f1 0.6820333584037517, recall 0.6081742149281995,precision 0.7763118138785376,specificity 0.9409504818876703,[tp,tn,fp,fn]: [15416, 70783, 4442, 9932]

TRAIN, epoch 87, loss 0.4061126978287437, acc 0.8228656370367601,recall 0.702995867768595,precision 0.7743333138822431,specificity 0.8882491475466682,[tp,tn,fp,fn]: [53079, 122955, 15469, 22425]
VAL, loss 0.34605002029285664, acc 0.8558758314855875,f1 0.6785104353804866, recall 0.6034401136184314,precision 0.7749126095546887,specificity 0.9409371884346959,[tp,tn,fp,fn]: [15296, 70782, 4443, 10052]

TRAIN, epoch 88, loss 0.4062733689905314, acc 0.8224496092143151,recall 0.7014992583174401,precision 0.7742322141176127,specificity 0.8884225278853378,[tp,tn,fp,fn]: [52966, 122979, 15445, 22538]
VAL, loss 0.3449599863680478, acc 0.856442583993716,f1 0.6794262622674186, recall 0.6035979169954238,precision 0.7770441848654139,specificity 0.9416417414423397,[tp,tn,fp,fn]: [15300, 70835, 4390, 10048]

TRAIN, epoch 89, loss 0.40596132011568886, acc 0.8233891776672525,recall 0.703168044077135,precision 0.7754958955332886,specificity 0.8889643414436803,[tp,tn,fp,fn]: [53092, 123054, 15370, 22412]
VAL, loss 0.3447492395758711, acc 0.8566016724170503,f1 0.6777062662018414, recall 0.5981931513334385,precision 0.7815979381443299,specificity 0.9436756397474244,[tp,tn,fp,fn]: [15163, 70988, 4237, 10185]

TRAIN, epoch 90, loss 0.4058042774537993, acc 0.8236369245727535,recall 0.7039362152998516,precision 0.7756293323604524,specificity 0.8889282205397908,[tp,tn,fp,fn]: [53150, 123049, 15375, 22354]
VAL, loss 0.34331876268097733, acc 0.8573076272955963,f1 0.6838917156765568, recall 0.6124349061069907,precision 0.7742257244027729,specificity 0.9398205383848455,[tp,tn,fp,fn]: [15524, 70698, 4527, 9824]

TRAIN, epoch 91, loss 0.4054664923427376, acc 0.8233143861486107,recall 0.7044394998940453,precision 0.7745449250036406,specificity 0.8881552331965555,[tp,tn,fp,fn]: [53188, 122942, 15482, 22316]
VAL, loss 0.34566883199752474, acc 0.8560647489882971,f1 0.6780105876595934, recall 0.6012703171847877,precision 0.7772055073941866,specificity 0.9419209039548022,[tp,tn,fp,fn]: [15241, 70856, 4369, 10107]

TRAIN, epoch 92, loss 0.40550682086411594, acc 0.8239173927676602,recall 0.7048765628311083,precision 0.7757371696765636,specificity 0.8888487545512339,[tp,tn,fp,fn]: [53221, 123038, 15386, 22283]
VAL, loss 0.34541736781390747, acc 0.8567905899197598,f1 0.6799546696886875, recall 0.6035979169954238,precision 0.7784278809463241,specificity 0.942107012296444,[tp,tn,fp,fn]: [15300, 70870, 4355, 10048]

TRAIN, epoch 93, loss 0.40502299619752574, acc 0.8242118843723122,recall 0.704850074168256,precision 0.7764662970528159,specificity 0.8893183263017974,[tp,tn,fp,fn]: [53219, 123103, 15321, 22285]
VAL, loss 0.34403621591762795, acc 0.8564823560995496,f1 0.6801258753656592, recall 0.6053732049865868,precision 0.7759405339805825,specificity 0.9410967098703888,[tp,tn,fp,fn]: [15345, 70794, 4431, 10003]

TRAIN, epoch 94, loss 0.4049008815097566, acc 0.8245577951460304,recall 0.7049560288196652,precision 0.777240734791624,specificity 0.8897951222331387,[tp,tn,fp,fn]: [53227, 123169, 15255, 22277]
VAL, loss 0.34175097587873177, acc 0.8577650065126823,f1 0.684904953853609, recall 0.6133422755246962,precision 0.7753727993616278,specificity 0.9401262878032569,[tp,tn,fp,fn]: [15547, 70721, 4504, 9801]

TRAIN, epoch 95, loss 0.4038156245815866, acc 0.8244549568078979,recall 0.7066115702479339,precision 0.7759839427524217,specificity 0.8887331676587875,[tp,tn,fp,fn]: [53352, 123022, 15402, 22152]
VAL, loss 0.3434717797302082, acc 0.8573473994014298,f1 0.687925521501751, recall 0.623836200094682,precision 0.7666909090909091,specificity 0.9360319042871386,[tp,tn,fp,fn]: [15813, 70413, 4812, 9535]

TRAIN, epoch 96, loss 0.403336443877123, acc 0.8237350884409708,recall 0.7044394998940453,precision 0.7755613881598133,specificity 0.8888054094665665,[tp,tn,fp,fn]: [53188, 123032, 15392, 22316]
VAL, loss 0.34504572027305797, acc 0.8565320712318415,f1 0.6810918333517515, recall 0.6078586081742149,precision 0.774388098708348,specificity 0.940325689597873,[tp,tn,fp,fn]: [15408, 70736, 4489, 9940]

TRAIN, epoch 97, loss 0.4029286555225083, acc 0.8253805018510901,recall 0.7070486331849968,precision 0.7779575063390749,specificity 0.889925157487141,[tp,tn,fp,fn]: [53385, 123187, 15237, 22119]
VAL, loss 0.3466976128822167, acc 0.8568601911049686,f1 0.6778120943556689, recall 0.5974041344484772,precision 0.7832316127030102,specificity 0.9442871385842473,[tp,tn,fp,fn]: [15143, 71034, 4191, 10205]

TRAIN, epoch 98, loss 0.40285013232090805, acc 0.8249037059197487,recall 0.7062804619622801,precision 0.7772708722014925,specificity 0.8896072935329133,[tp,tn,fp,fn]: [53327, 123143, 15281, 22177]
VAL, loss 0.3417490923331309, acc 0.8581826136239349,f1 0.6896986837811379, recall 0.6253353321761086,precision 0.768831546781782,specificity 0.9366434031239614,[tp,tn,fp,fn]: [15851, 70459, 4766, 9497]

TRAIN, epoch 99, loss 0.4030452225527113, acc 0.8243941886990015,recall 0.704413011231193,precision 0.7771754219332213,specificity 0.8898384673178061,[tp,tn,fp,fn]: [53186, 123175, 15249, 22318]
VAL, loss 0.34300416515192217, acc 0.8571883109780956,f1 0.6827328753506661, recall 0.609673347009626,precision 0.7756863926115545,specificity 0.9405915586573612,[tp,tn,fp,fn]: [15454, 70756, 4469, 9894]



 * BEST_ACC: 0.8581826136239349
 * TIME: Time 9888.830 (9888.830)

pooling_ratio 0.2, dropout0.2, hidden_dim 64, outdim 128
epochs 100, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.53751341701178, acc 0.7577689689989155,recall 0.49402680652680653,precision 0.7325700145331709,specificity 0.9016283303473386,[tp,tn,fp,fn]: [37301, 124807, 13617, 38203]
VAL, loss 0.424085197474167, acc 0.825987093951657,f1 0.5524384318338746, recall 0.42610856872337066,precision 0.7852417302798982,specificity 0.9607311399135926,[tp,tn,fp,fn]: [10801, 72271, 2954, 14547]

TRAIN, epoch 1, loss 0.47591536946399404, acc 0.7875406678882615,recall 0.6372642509006146,precision 0.7270584324332492,specificity 0.8695096226087962,[tp,tn,fp,fn]: [48116, 120361, 18063, 27388]
VAL, loss 0.39970543803651515, acc 0.8339713441977469,f1 0.5887799832537064, recall 0.47159539214139184,precision 0.7834578581727618,specificity 0.956078431372549,[tp,tn,fp,fn]: [11954, 71921, 3304, 13394]

TRAIN, epoch 2, loss 0.4640698180626273, acc 0.7921309973449011,recall 0.6494755244755245,precision 0.7314628361748781,specificity 0.8699430734554702,[tp,tn,fp,fn]: [49038, 120421, 18003, 26466]
VAL, loss 0.3850754043394523, acc 0.8389826295327771,f1 0.6116733010407174, recall 0.5031560675398453,precision 0.7798703681056622,specificity 0.9521435692921236,[tp,tn,fp,fn]: [12754, 71625, 3600, 12594]

TRAIN, epoch 3, loss 0.45650258261332455, acc 0.7969503758273812,recall 0.6592498410680229,precision 0.7375752007823845,specificity 0.8720597584233948,[tp,tn,fp,fn]: [49776, 120714, 17710, 25728]
VAL, loss 0.3751097023937876, acc 0.8430592703807185,f1 0.6325200223505308, recall 0.5359002682657409,precision 0.7716428084526245,specificity 0.9465603190428714,[tp,tn,fp,fn]: [13584, 71205, 4020, 11764]

TRAIN, epoch 4, loss 0.45231100525122603, acc 0.7997737556561086,recall 0.6638456240728968,precision 0.7417278323665206,specificity 0.873916372883315,[tp,tn,fp,fn]: [50123, 120971, 17453, 25381]
VAL, loss 0.3702109537034311, acc 0.8451671919898979,f1 0.6403695150115474, recall 0.5469465046551997,precision 0.7722816399286988,specificity 0.9456563642406115,[tp,tn,fp,fn]: [13864, 71137, 4088, 11484]

TRAIN, epoch 5, loss 0.4485749164126377, acc 0.8013864477768221,recall 0.6683619410892138,precision 0.7430683374317141,specificity 0.8739452696064266,[tp,tn,fp,fn]: [50464, 120975, 17449, 25040]
VAL, loss 0.3668643937609258, acc 0.8468575064878248,f1 0.647857698111482, recall 0.5589395613066119,precision 0.7704187058183796,specificity 0.9438750415420405,[tp,tn,fp,fn]: [14168, 71003, 4222, 11180]

TRAIN, epoch 6, loss 0.4438953277678315, acc 0.8040555700983508,recall 0.6734742530197075,precision 0.7465425610006753,specificity 0.8752817430503381,[tp,tn,fp,fn]: [50850, 121160, 17264, 24654]
VAL, loss 0.36279155492497234, acc 0.8485875930915853,f1 0.6575822989746357, recall 0.5768502445952344,precision 0.7645889981175487,specificity 0.9401528747092057,[tp,tn,fp,fn]: [14622, 70723, 4502, 10726]

TRAIN, epoch 7, loss 0.4415995428667906, acc 0.8053036535656857,recall 0.6758582326764145,precision 0.748163678214846,specificity 0.8759102467780153,[tp,tn,fp,fn]: [51030, 121247, 17177, 24474]
VAL, loss 0.3587816011020191, acc 0.8500889900868026,f1 0.6627597467958037, recall 0.5844642575351112,precision 0.7652771320832688,specificity 0.9395945496842805,[tp,tn,fp,fn]: [14815, 70681, 4544, 10533]

TRAIN, epoch 8, loss 0.43922873712157506, acc 0.8071220223626641,recall 0.6796063784700148,precision 0.7503655825924193,specificity 0.8766760099404728,[tp,tn,fp,fn]: [51313, 121353, 17071, 24191]
VAL, loss 0.358537807548633, acc 0.8503475087747209,f1 0.6607613766988978, recall 0.5782704749881648,precision 0.770702981229297,specificity 0.9420272515785976,[tp,tn,fp,fn]: [14658, 70864, 4361, 10690]

TRAIN, epoch 9, loss 0.436374791144549, acc 0.8081878015033095,recall 0.6812089425725789,precision 0.7519810520775462,specificity 0.8774489972837081,[tp,tn,fp,fn]: [51434, 121460, 16964, 24070]
VAL, loss 0.3549555295651671, acc 0.8523261710399411,f1 0.6750678218255011, recall 0.6086476250591762,precision 0.7577603143418468,specificity 0.9344366899302093,[tp,tn,fp,fn]: [15428, 70293, 4932, 9920]

TRAIN, epoch 10, loss 0.43451052544931973, acc 0.8098004936240231,recall 0.6835002119093028,precision 0.7544993347855963,specificity 0.8786915563775068,[tp,tn,fp,fn]: [51607, 121632, 16792, 23897]
VAL, loss 0.3541725223785403, acc 0.8521173674843149,f1 0.6719167052698917, recall 0.600836357898059,precision 0.7620715536652489,specificity 0.93678963110668,[tp,tn,fp,fn]: [15230, 70470, 4755, 10118]

TRAIN, epoch 11, loss 0.4323967139611965, acc 0.8106091769193373,recall 0.6869040050858233,precision 0.7544951993017166,specificity 0.8780847251921632,[tp,tn,fp,fn]: [51864, 121548, 16876, 23640]
VAL, loss 0.3509280362119969, acc 0.8541556879082856,f1 0.6824558365084864, recall 0.6218242070380307,precision 0.756188831318365,specificity 0.9324426719840478,[tp,tn,fp,fn]: [15762, 70143, 5082, 9586]

TRAIN, epoch 12, loss 0.4319302820964552, acc 0.8108943195841591,recall 0.6844802924348379,precision 0.7565324316015986,specificity 0.8798474253019708,[tp,tn,fp,fn]: [51681, 121792, 16632, 23823]
VAL, loss 0.3557700204270801, acc 0.8516102731349368,f1 0.6645387520230174, recall 0.583162379674925,precision 0.7723092998955068,specificity 0.9420671319375208,[tp,tn,fp,fn]: [14782, 70867, 4358, 10566]

TRAIN, epoch 13, loss 0.42961054937270055, acc 0.8118946561459931,recall 0.6871159143886416,precision 0.7574054338146197,specificity 0.8799557880136393,[tp,tn,fp,fn]: [51880, 121807, 16617, 23624]
VAL, loss 0.35271792065335494, acc 0.8534000178974476,f1 0.674180146733846, recall 0.6017831781600126,precision 0.766378617363344,specificity 0.938185443668993,[tp,tn,fp,fn]: [15254, 70575, 4650, 10094]

TRAIN, epoch 14, loss 0.4286811385177103, acc 0.8130913204442616,recall 0.6881887052341598,precision 0.7596304255661301,specificity 0.8812200196497717,[tp,tn,fp,fn]: [51961, 121982, 16442, 23543]
VAL, loss 0.35118157239483305, acc 0.8545136368607877,f1 0.6784741144414169, recall 0.6090421335016569,precision 0.7657738095238096,specificity 0.9372283150548355,[tp,tn,fp,fn]: [15438, 70503, 4722, 9910]

TRAIN, epoch 15, loss 0.4275378630198821, acc 0.8134933248569612,recall 0.6894998940453486,precision 0.7598336130774282,specificity 0.8811261052996591,[tp,tn,fp,fn]: [52060, 121969, 16455, 23444]
VAL, loss 0.3504348239758428, acc 0.8544838077814125,f1 0.6808835393907676, recall 0.6159460312450686,precision 0.7611270901379613,specificity 0.9348620804253905,[tp,tn,fp,fn]: [15613, 70325, 4900, 9735]

TRAIN, epoch 16, loss 0.4262265025742422, acc 0.8136055121349239,recall 0.6898310023310024,precision 0.7599101267854277,specificity 0.8811188811188811,[tp,tn,fp,fn]: [52085, 121968, 16456, 23419]
VAL, loss 0.34984027628772035, acc 0.8538872261939089,f1 0.6794494252121371, recall 0.6144074483193941,precision 0.7598926567455477,specificity 0.9345829179129279,[tp,tn,fp,fn]: [15574, 70304, 4921, 9774]

TRAIN, epoch 17, loss 0.42450289648956957, acc 0.8147647806738716,recall 0.6898442466624285,precision 0.7626619811113552,specificity 0.8829032537710224,[tp,tn,fp,fn]: [52086, 122215, 16209, 23418]
VAL, loss 0.3492928883627628, acc 0.8547622125222475,f1 0.6836599891716296, recall 0.6226921256114881,precision 0.7578623901666106,specificity 0.9329611166500499,[tp,tn,fp,fn]: [15784, 70182, 5043, 9564]

TRAIN, epoch 18, loss 0.4240486844552178, acc 0.8154285554018175,recall 0.6913673447764357,precision 0.7633622391530058,specificity 0.8830983066520257,[tp,tn,fp,fn]: [52201, 122242, 16182, 23303]
VAL, loss 0.34990243734839194, acc 0.854672725284122,f1 0.6785714285714285, recall 0.6086476250591762,precision 0.7666467899026038,specificity 0.9375739448321702,[tp,tn,fp,fn]: [15428, 70529, 4696, 9920]

TRAIN, epoch 19, loss 0.42348234765188425, acc 0.81469933809506,recall 0.692095783004874,precision 0.7612055528849655,specificity 0.8815740045078888,[tp,tn,fp,fn]: [52256, 122031, 16393, 23248]
VAL, loss 0.3482312636167072, acc 0.8552394777922504,f1 0.6828450059906328, recall 0.6183130818999527,precision 0.762416695043051,specificity 0.935074775672981,[tp,tn,fp,fn]: [15673, 70341, 4884, 9675]

TRAIN, epoch 20, loss 0.4228899611022869, acc 0.8157417448861299,recall 0.6909302818393728,precision 0.7643663003663004,specificity 0.8838207247298157,[tp,tn,fp,fn]: [52168, 122342, 16082, 23336]
VAL, loss 0.3482912842466888, acc 0.8551002754218329,f1 0.6818886293684924, recall 0.6161827363105571,precision 0.7632800664614182,specificity 0.9356065137919575,[tp,tn,fp,fn]: [15619, 70381, 4844, 9729]

TRAIN, epoch 21, loss 0.4211496757005933, acc 0.8165551026513593,recall 0.6942016317016317,precision 0.7644013416946186,specificity 0.883293359533029,[tp,tn,fp,fn]: [52415, 122269, 16155, 23089]
VAL, loss 0.3498091961360142, acc 0.8549411869984986,f1 0.6753599323527449, recall 0.5986665614644153,precision 0.7745903731305191,specificity 0.9412961116650049,[tp,tn,fp,fn]: [15175, 70809, 4416, 10173]

TRAIN, epoch 22, loss 0.4208688832052421, acc 0.816667289929322,recall 0.6918971180334816,precision 0.7660195313645561,specificity 0.8847237473270532,[tp,tn,fp,fn]: [52241, 122467, 15957, 23263]
VAL, loss 0.34627768750391696, acc 0.8558758314855875,f1 0.6890219047006072, recall 0.6335016569354585,precision 0.7552085782815219,specificity 0.9308075772681954,[tp,tn,fp,fn]: [16058, 70020, 5205, 9290]

TRAIN, epoch 23, loss 0.41977406759201635, acc 0.8169758049437194,recall 0.693168573850392,precision 0.7660119430946666,specificity 0.8845070219037161,[tp,tn,fp,fn]: [52337, 122437, 15987, 23167]
VAL, loss 0.34537128954767254, acc 0.8565420142582999,f1 0.6891856958207668, recall 0.6310557045920783,precision 0.7591116173120729,specificity 0.9325224327018943,[tp,tn,fp,fn]: [15996, 70149, 5076, 9352]

TRAIN, epoch 24, loss 0.41946062396491973, acc 0.8172702965483715,recall 0.6939367450731088,precision 0.7662664346198284,specificity 0.8845431428076056,[tp,tn,fp,fn]: [52395, 122442, 15982, 23109]
VAL, loss 0.3474474632248669, acc 0.8558658884591291,f1 0.6810841730100762, recall 0.6106596181158277,precision 0.7698696906396101,specificity 0.9384911930874045,[tp,tn,fp,fn]: [15479, 70598, 4627, 9869]

TRAIN, epoch 25, loss 0.4185567734833587, acc 0.8182425862907147,recall 0.695645263827082,precision 0.7675917401025911,specificity 0.8851138530890597,[tp,tn,fp,fn]: [52524, 122521, 15903, 22980]
VAL, loss 0.3450794783328028, acc 0.8566215584699671,f1 0.6887008332973533, recall 0.6292804166009153,precision 0.7605130161151903,specificity 0.9332269857095381,[tp,tn,fp,fn]: [15951, 70202, 5023, 9397]

TRAIN, epoch 26, loss 0.4171051739284467, acc 0.8180275606746195,recall 0.6938043017588472,precision 0.7681648214678496,specificity 0.8857857019014044,[tp,tn,fp,fn]: [52385, 122614, 15810, 23119]
VAL, loss 0.34607983735420444, acc 0.8564724130730912,f1 0.6856284164906243, recall 0.6209957393088212,precision 0.7652778453011814,specificity 0.9358192090395481,[tp,tn,fp,fn]: [15741, 70397, 4828, 9607]

TRAIN, epoch 27, loss 0.4168515439123291, acc 0.8185697991847725,recall 0.6950227802500529,precision 0.7687473448280914,specificity 0.885959082240074,[tp,tn,fp,fn]: [52477, 122638, 15786, 23027]
VAL, loss 0.3450153151012608, acc 0.8565619003112167,f1 0.6884098665169122, recall 0.6286886539371943,precision 0.7606682577565632,specificity 0.9333466267863078,[tp,tn,fp,fn]: [15936, 70211, 5014, 9412]

TRAIN, epoch 28, loss 0.4158343718044867, acc 0.8187894992707827,recall 0.6956320194956559,precision 0.7689143292147332,specificity 0.8859663064208518,[tp,tn,fp,fn]: [52523, 122639, 15785, 22981]
VAL, loss 0.343570678407501, acc 0.8576954053274736,f1 0.697918865296129, recall 0.6522408079532902,precision 0.7504766227871085,specificity 0.9269258889996677,[tp,tn,fp,fn]: [16533, 69728, 5497, 8815]

TRAIN, epoch 29, loss 0.41575282873637853, acc 0.819514042107625,recall 0.6959896164441619,precision 0.7704487809169147,specificity 0.886891001560423,[tp,tn,fp,fn]: [52550, 122767, 15657, 22954]
VAL, loss 0.344160533230686, acc 0.8579042088830998,f1 0.6974233024920073, recall 0.649755404765662,precision 0.7526390348672486,specificity 0.9280425390495182,[tp,tn,fp,fn]: [16470, 69812, 5413, 8878]

TRAIN, epoch 30, loss 0.41481765301937895, acc 0.8191213866347556,recall 0.6942943420216148,precision 0.7705151760123465,specificity 0.8872088655146506,[tp,tn,fp,fn]: [52422, 122811, 15613, 23082]
VAL, loss 0.34337719650138193, acc 0.8579141519095582,f1 0.6927146051952521, recall 0.6354347483036137,precision 0.7613442994895065,specificity 0.9328813559322033,[tp,tn,fp,fn]: [16107, 70176, 5049, 9241]

TRAIN, epoch 31, loss 0.414737217095121, acc 0.820434912680902,recall 0.6979895104895105,precision 0.7714749970722568,specificity 0.8872233138762065,[tp,tn,fp,fn]: [52701, 122813, 15611, 22803]
VAL, loss 0.3426360732213672, acc 0.858033468227059,f1 0.6929990539262063, recall 0.6357503550575982,precision 0.7615784499054821,specificity 0.9329345297441011,[tp,tn,fp,fn]: [16115, 70180, 5045, 9233]

TRAIN, epoch 32, loss 0.4127912913001888, acc 0.8205050297296287,recall 0.6971683619410892,precision 0.7721385299165359,specificity 0.8877795757961047,[tp,tn,fp,fn]: [52639, 122890, 15534, 22865]
VAL, loss 0.34280903140345775, acc 0.8576456901951817,f1 0.6893753661235382, recall 0.626755562569039,precision 0.7658969290845105,specificity 0.9354469923562645,[tp,tn,fp,fn]: [15887, 70369, 4856, 9461]

TRAIN, epoch 33, loss 0.4122373240476664, acc 0.8209163830821585,recall 0.6980292434837889,precision 0.7726159935498058,specificity 0.8879457319539964,[tp,tn,fp,fn]: [52704, 122913, 15511, 22800]
VAL, loss 0.34202044736128173, acc 0.8584013602060195,f1 0.6982519334675283, recall 0.6500315606753985,precision 0.754199661280725,specificity 0.9286141575274177,[tp,tn,fp,fn]: [16477, 69855, 5370, 8871]

TRAIN, epoch 34, loss 0.41209435759069124, acc 0.8214165513630755,recall 0.6979100445009536,precision 0.7739021882802174,specificity 0.8887837369242327,[tp,tn,fp,fn]: [52695, 123029, 15395, 22809]
VAL, loss 0.34296513158802944, acc 0.8583615881001859,f1 0.6926180868739616, recall 0.6331465993372258,precision 0.7644201000238152,specificity 0.9342505815885677,[tp,tn,fp,fn]: [16049, 70279, 4946, 9299]

TRAIN, epoch 35, loss 0.411115550278485, acc 0.8216456003889159,recall 0.6994331426149608,precision 0.7735348830396508,specificity 0.8883069409928914,[tp,tn,fp,fn]: [52810, 122963, 15461, 22694]
VAL, loss 0.34207926161171126, acc 0.8586201067881042,f1 0.6941427004237561, recall 0.6365393719425596,precision 0.7632089305141668,specificity 0.933452974410103,[tp,tn,fp,fn]: [16135, 70219, 5006, 9213]

TRAIN, epoch 36, loss 0.4105046938006057, acc 0.8219541154033133,recall 0.698744437380801,precision 0.7747022804364107,specificity 0.8891593943246836,[tp,tn,fp,fn]: [52758, 123081, 15343, 22746]
VAL, loss 0.3423449919463747, acc 0.8584113032324779,f1 0.6935261707988981, recall 0.6356320025248541,precision 0.7630232998673991,specificity 0.9334795613160518,[tp,tn,fp,fn]: [16112, 70221, 5004, 9236]

TRAIN, epoch 37, loss 0.4097663354659231, acc 0.8224542836842302,recall 0.6999761602034329,precision 0.7751686711645643,specificity 0.8892605328555742,[tp,tn,fp,fn]: [52851, 123095, 15329, 22653]
VAL, loss 0.34051071173519937, acc 0.8588786254760223,f1 0.7002724220218359, recall 0.6540949976329493,precision 0.753465121563281,specificity 0.9278830176138252,[tp,tn,fp,fn]: [16580, 69800, 5425, 8768]

TRAIN, epoch 38, loss 0.4094317536447949, acc 0.8227721476384579,recall 0.7005589107861835,precision 0.7755865102639297,specificity 0.8894339131942438,[tp,tn,fp,fn]: [52895, 123119, 15305, 22609]
VAL, loss 0.3429035097645824, acc 0.8584610183647698,f1 0.6945344520503852, recall 0.6384330124664668,precision 0.7614454429962829,specificity 0.9326021934197408,[tp,tn,fp,fn]: [16183, 70155, 5070, 9165]

TRAIN, epoch 39, loss 0.4088145918621184, acc 0.822818892337609,recall 0.6997112735749099,precision 0.7762187417354764,specificity 0.8899685025718084,[tp,tn,fp,fn]: [52831, 123193, 15231, 22673]
VAL, loss 0.3418495134279247, acc 0.8589482266612312,f1 0.7003253200388695, recall 0.6539371942559571,precision 0.7537971805366076,specificity 0.9280292455965437,[tp,tn,fp,fn]: [16576, 69811, 5414, 8772]

TRAIN, epoch 40, loss 0.4080801647714971, acc 0.8239407651172357,recall 0.7027707141343505,precision 0.7770780856423174,specificity 0.8900335201988094,[tp,tn,fp,fn]: [53062, 123202, 15222, 22442]
VAL, loss 0.33951859547958235, acc 0.8593360046931084,f1 0.6998238876275754, recall 0.6505838724948714,precision 0.7571277719112989,specificity 0.9296776337653706,[tp,tn,fp,fn]: [16491, 69935, 5290, 8857]

TRAIN, epoch 41, loss 0.4073757434327281, acc 0.8234546202460641,recall 0.701221127357491,precision 0.7768436188631629,specificity 0.8901274345489222,[tp,tn,fp,fn]: [52945, 123215, 15209, 22559]
VAL, loss 0.3406075059385414, acc 0.8593658337724837,f1 0.6976227125021379, recall 0.6436799747514597,precision 0.7614336382303528,specificity 0.9320438683948156,[tp,tn,fp,fn]: [16316, 70113, 5112, 9032]

TRAIN, epoch 42, loss 0.40660543803934035, acc 0.8241417673235855,recall 0.7023336511972875,precision 0.7778364503116978,specificity 0.8905825579379298,[tp,tn,fp,fn]: [53029, 123278, 15146, 22475]
VAL, loss 0.3410610001717093, acc 0.8592962325872749,f1 0.6961935636230918, recall 0.6396559886381569,precision 0.7636945975224907,specificity 0.9333067464273845,[tp,tn,fp,fn]: [16214, 70208, 5017, 9134]

TRAIN, epoch 43, loss 0.4061381095750567, acc 0.8245531206761153,recall 0.7026647594829413,precision 0.7786371574915244,specificity 0.8910376813269375,[tp,tn,fp,fn]: [53054, 123341, 15083, 22450]
VAL, loss 0.3386666414315983, acc 0.8598430990424866,f1 0.7000595795386841, recall 0.6489663878807006,precision 0.7598854397634885,specificity 0.9309006314390162,[tp,tn,fp,fn]: [16450, 70027, 5198, 8898]

TRAIN, epoch 44, loss 0.40540633820670735, acc 0.8250392655472869,recall 0.7040289256198347,precision 0.7789826931813186,specificity 0.8910449055077154,[tp,tn,fp,fn]: [53157, 123342, 15082, 22347]
VAL, loss 0.339700811887558, acc 0.8598430990424866,f1 0.6984683836741679, recall 0.6440744831939403,precision 0.7628971962616823,specificity 0.9325490196078431,[tp,tn,fp,fn]: [16326, 70151, 5074, 9022]

TRAIN, epoch 45, loss 0.4049539492874396, acc 0.8253244082121087,recall 0.7049295401568129,precision 0.7791228737886817,specificity 0.8909943362422701,[tp,tn,fp,fn]: [53225, 123335, 15089, 22279]
VAL, loss 0.3398895182989539, acc 0.8603899654976982,f1 0.7050148112355301, recall 0.6619457156383146,precision 0.7540784683834434,specificity 0.9272582253240279,[tp,tn,fp,fn]: [16779, 69753, 5472, 8569]

TRAIN, epoch 46, loss 0.4037279282126732, acc 0.8260022063497999,recall 0.7054195804195804,precision 0.780475653180546,specificity 0.8917745477662833,[tp,tn,fp,fn]: [53262, 123443, 14981, 22242]
VAL, loss 0.3398420927909816, acc 0.8604297376035318,f1 0.7008120723831447, recall 0.6485718794382199,precision 0.7622050164588067,specificity 0.9318178796942506,[tp,tn,fp,fn]: [16440, 70096, 5129, 8908]

TRAIN, epoch 47, loss 0.4033709921432876, acc 0.8264275831120751,recall 0.7059228650137741,precision 0.7812041976900979,specificity 0.892157429347512,[tp,tn,fp,fn]: [53300, 123496, 14928, 22204]
VAL, loss 0.34118247241252647, acc 0.8598629850954034,f1 0.6996931731015086, recall 0.6477434117090106,precision 0.7607023721275018,specificity 0.9313393153871719,[tp,tn,fp,fn]: [16419, 70060, 5165, 8929]

TRAIN, epoch 48, loss 0.40305140992207017, acc 0.8263481171235182,recall 0.7051546937910574,precision 0.7814880594166947,specificity 0.8924536207594059,[tp,tn,fp,fn]: [53242, 123537, 14887, 22262]
VAL, loss 0.3395666713832813, acc 0.8603203643124895,f1 0.7010045973097224, recall 0.6496765030771658,precision 0.7611388426696247,specificity 0.9312994350282486,[tp,tn,fp,fn]: [16468, 70057, 5168, 8880]

TRAIN, epoch 49, loss 0.40221657734066846, acc 0.8270820089001907,recall 0.7075651621106167,precision 0.7817841254975415,specificity 0.8922730162399584,[tp,tn,fp,fn]: [53424, 123512, 14912, 22080]
VAL, loss 0.33824543057071305, acc 0.8609070028735346,f1 0.7089687311461086, recall 0.672202935142812,precision 0.749988995994542,specificity 0.9244931871053507,[tp,tn,fp,fn]: [17039, 69545, 5680, 8309]

TRAIN, epoch 50, loss 0.4014177911814129, acc 0.8270118918514641,recall 0.7075784064420428,precision 0.7816043187570406,specificity 0.892157429347512,[tp,tn,fp,fn]: [53425, 123496, 14928, 22079]
VAL, loss 0.34031499822543565, acc 0.8599127002276953,f1 0.6988693440485605, recall 0.6449818526116459,precision 0.7625822099911377,specificity 0.9323363243602526,[tp,tn,fp,fn]: [16349, 70135, 5090, 8999]

TRAIN, epoch 51, loss 0.4006192633520446, acc 0.8274840133128903,recall 0.7093134138588684,precision 0.7816796567124967,specificity 0.891940703924175,[tp,tn,fp,fn]: [53556, 123466, 14958, 21948]
VAL, loss 0.3380721764181179, acc 0.860588826026866,f1 0.7060895084372707, recall 0.6644311188259429,precision 0.7533211074831149,specificity 0.9266866068461282,[tp,tn,fp,fn]: [16842, 69710, 5515, 8506]

TRAIN, epoch 52, loss 0.4003568253281416, acc 0.8274232452039939,recall 0.7093796355159991,precision 0.7814902899163956,specificity 0.8918106686701728,[tp,tn,fp,fn]: [53561, 123448, 14976, 21943]
VAL, loss 0.3394154707134151, acc 0.8609964901116602,f1 0.7080200501253133, recall 0.6686918100047341,precision 0.7522634475412746,specificity 0.9257959454968429,[tp,tn,fp,fn]: [16950, 69643, 5582, 8398]

TRAIN, epoch 53, loss 0.4000313732095879, acc 0.8279234134849108,recall 0.7086379529561347,precision 0.7831757369946427,specificity 0.8929882101369705,[tp,tn,fp,fn]: [53505, 123611, 14813, 21999]
VAL, loss 0.33801468408309676, acc 0.8612848378789536,f1 0.7039324292778169, recall 0.6542922518541897,precision 0.7617232351995591,specificity 0.9310335659687604,[tp,tn,fp,fn]: [16585, 70037, 5188, 8763]

TRAIN, epoch 54, loss 0.39900435061672496, acc 0.8280776709921095,recall 0.7092074592074592,precision 0.7831975545187287,specificity 0.8929159683291915,[tp,tn,fp,fn]: [53548, 123601, 14823, 21956]
VAL, loss 0.3377489133591865, acc 0.8613544390641623,f1 0.703621833021595, recall 0.6529903739940035,precision 0.7627649769585253,specificity 0.9315653040877367,[tp,tn,fp,fn]: [16552, 70077, 5148, 8796]

TRAIN, epoch 55, loss 0.39822901042182385, acc 0.8289985415653864,recall 0.7109821996185632,precision 0.7843429473130534,specificity 0.8933710917181992,[tp,tn,fp,fn]: [53682, 123664, 14760, 21822]
VAL, loss 0.34092022909733755, acc 0.8601314468097799,f1 0.6954469678927884, recall 0.6336200094682026,precision 0.7706444028597477,specificity 0.9364572947823198,[tp,tn,fp,fn]: [16061, 70445, 4780, 9287]

TRAIN, epoch 56, loss 0.39777933596129245, acc 0.829101379903519,recall 0.7117768595041323,precision 0.7840968777356289,specificity 0.893096572848639,[tp,tn,fp,fn]: [53742, 123626, 14798, 21762]
VAL, loss 0.33839208460172204, acc 0.8611655215614529,f1 0.7057509535751163, recall 0.6606043869338803,precision 0.7575209228681293,specificity 0.9287470920571619,[tp,tn,fp,fn]: [16745, 69865, 5360, 8603]

TRAIN, epoch 57, loss 0.39674110304225574, acc 0.8293023821098687,recall 0.7119490358126722,precision 0.7844811231265415,specificity 0.8933132982719759,[tp,tn,fp,fn]: [53755, 123656, 14768, 21749]
VAL, loss 0.3373431631565902, acc 0.8617322740695813,f1 0.7049187285150448, recall 0.6552785229603914,precision 0.7626962990173569,specificity 0.9312994350282486,[tp,tn,fp,fn]: [16610, 70057, 5168, 8738]

TRAIN, epoch 58, loss 0.3959256970301994, acc 0.8296295950039265,recall 0.7128364060182242,precision 0.7847259684779915,specificity 0.8933349708143097,[tp,tn,fp,fn]: [53822, 123659, 14765, 21682]
VAL, loss 0.338634150150943, acc 0.8613544390641623,f1 0.7048763968845242, recall 0.6569354584188102,precision 0.760365296803653,specificity 0.9302359587902957,[tp,tn,fp,fn]: [16652, 69977, 5248, 8696]

TRAIN, epoch 59, loss 0.3952964092998541, acc 0.8297932014509555,recall 0.7120947234583598,precision 0.785593220338983,specificity 0.8939923712650986,[tp,tn,fp,fn]: [53766, 123750, 14674, 21738]
VAL, loss 0.33660151099265984, acc 0.8619311345987491,f1 0.7135253342135666, recall 0.682223449581821,precision 0.7478377443348901,specificity 0.9224858757062147,[tp,tn,fp,fn]: [17293, 69394, 5831, 8055]

TRAIN, epoch 60, loss 0.3936608384853481, acc 0.83103193597846,recall 0.714770078406442,precision 0.7869464413304365,specificity 0.8944474946541062,[tp,tn,fp,fn]: [53968, 123813, 14611, 21536]
VAL, loss 0.33909359060378774, acc 0.8612649518260368,f1 0.7029570178613246, recall 0.6513334385355847,precision 0.7634682080924855,specificity 0.9320039880358924,[tp,tn,fp,fn]: [16510, 70110, 5115, 8838]

TRAIN, epoch 61, loss 0.3934818023202717, acc 0.8304663251187315,recall 0.7156309599491417,precision 0.7850210663954671,specificity 0.8931037970294169,[tp,tn,fp,fn]: [54033, 123627, 14797, 21471]
VAL, loss 0.33659067591724595, acc 0.8621995963131258,f1 0.7026539938638461, recall 0.6460075745620957,precision 0.7701895489393725,specificity 0.9350481887670322,[tp,tn,fp,fn]: [16375, 70339, 4886, 8973]

TRAIN, epoch 62, loss 0.39233680309895724, acc 0.8311067274971018,recall 0.7154455393091756,precision 0.786703560766038,specificity 0.8941946483268798,[tp,tn,fp,fn]: [54019, 123778, 14646, 21485]
VAL, loss 0.3376097729087514, acc 0.8616527298579142,f1 0.71078777800873, recall 0.6745305349534481,precision 0.7511642210702048,specificity 0.9247058823529412,[tp,tn,fp,fn]: [17098, 69561, 5664, 8250]

TRAIN, epoch 63, loss 0.39164675170760704, acc 0.8321444598182566,recall 0.7174719220173765,precision 0.7879678249865453,specificity 0.8946931168005549,[tp,tn,fp,fn]: [54172, 123847, 14577, 21332]
VAL, loss 0.3399796209384944, acc 0.8616030147256222,f1 0.7006087199673056, recall 0.6424964494240176,precision 0.7702785791987892,specificity 0.9354336989032901,[tp,tn,fp,fn]: [16286, 70368, 4857, 9062]

TRAIN, epoch 64, loss 0.39073977593971543, acc 0.8323968811936726,recall 0.7161474888747617,precision 0.7894298853930943,specificity 0.8958056406403514,[tp,tn,fp,fn]: [54072, 124001, 14423, 21432]
VAL, loss 0.33641346023950536, acc 0.8623089696041681,f1 0.7050730502193636, recall 0.6530298248382516,precision 0.7661297787651579,specificity 0.9328281821203057,[tp,tn,fp,fn]: [16553, 70172, 5053, 8795]

TRAIN, epoch 65, loss 0.38952624908043165, acc 0.8321304364085113,recall 0.7168361941089214,precision 0.7883360522022839,specificity 0.8950182049355603,[tp,tn,fp,fn]: [54124, 123892, 14532, 21380]
VAL, loss 0.3383159389054654, acc 0.8616328438049974,f1 0.7028146756075684, recall 0.649163642101941,precision 0.7661327870378992,specificity 0.9332269857095381,[tp,tn,fp,fn]: [16455, 70202, 5023, 8893]

TRAIN, epoch 66, loss 0.38860779444115096, acc 0.8328222579559478,recall 0.7185049798686163,precision 0.7889761489237929,specificity 0.8951771369126741,[tp,tn,fp,fn]: [54250, 123914, 14510, 21254]
VAL, loss 0.3400302566850543, acc 0.8612351227466616,f1 0.7033415525890656, recall 0.6526747672400189,precision 0.7625368731563422,specificity 0.9315121302758391,[tp,tn,fp,fn]: [16544, 70073, 5152, 8804]

TRAIN, epoch 67, loss 0.38806762409693446, acc 0.8337665008788003,recall 0.720518118245391,precision 0.790014812233162,specificity 0.8955383459515691,[tp,tn,fp,fn]: [54402, 123964, 14460, 21102]
VAL, loss 0.33917186454517206, acc 0.8610064331381185,f1 0.6991110441464518, recall 0.6406817105886066,precision 0.7692672066695088,specificity 0.9352475905616484,[tp,tn,fp,fn]: [16240, 70354, 4871, 9108]

TRAIN, epoch 68, loss 0.38649032618990475, acc 0.8350426311656258,recall 0.7220544606908244,precision 0.7921709943185946,specificity 0.8966725423336993,[tp,tn,fp,fn]: [54518, 124121, 14303, 20986]
VAL, loss 0.33967247792271704, acc 0.8615234705139551,f1 0.7038257873806435, recall 0.6528325706170112,precision 0.7634602076124567,specificity 0.9318444666001994,[tp,tn,fp,fn]: [16548, 70098, 5127, 8800]

TRAIN, epoch 69, loss 0.3862059311731953, acc 0.8337010582999888,recall 0.7196042593769867,precision 0.7904361488550729,specificity 0.8959356758943536,[tp,tn,fp,fn]: [54333, 124019, 14405, 21171]
VAL, loss 0.33634142331720407, acc 0.8629254372445885,f1 0.7073781626761758, recall 0.6573694177055389,precision 0.7656221282852417,specificity 0.932190096377534,[tp,tn,fp,fn]: [16663, 70124, 5101, 8685]

TRAIN, epoch 70, loss 0.38504955267269597, acc 0.8344162521970009,recall 0.7224517906336089,precision 0.7903789031369992,specificity 0.8954877766861238,[tp,tn,fp,fn]: [54548, 123957, 14467, 20956]
VAL, loss 0.3391972058044802, acc 0.8619311345987491,f1 0.7011964193492856, recall 0.6427726053337541,precision 0.771302783563719,specificity 0.9357793286806247,[tp,tn,fp,fn]: [16293, 70394, 4831, 9055]

TRAIN, epoch 71, loss 0.38447817044796456, acc 0.8354867058075615,recall 0.7235908031362577,precision 0.792279358450071,specificity 0.8965208345373634,[tp,tn,fp,fn]: [54634, 124100, 14324, 20870]
VAL, loss 0.33845488023568376, acc 0.8622791405247929,f1 0.705942296669002, recall 0.6559097364683604,precision 0.7642381061824868,specificity 0.9318178796942506,[tp,tn,fp,fn]: [16626, 70096, 5129, 8722]

TRAIN, epoch 72, loss 0.383423944878991, acc 0.835636288844845,recall 0.7240013774104683,precision 0.7923841827564214,specificity 0.8965280587181413,[tp,tn,fp,fn]: [54665, 124101, 14323, 20839]
VAL, loss 0.3404809605723341, acc 0.8613345530112456,f1 0.6970500065169222, recall 0.6329493451159854,precision 0.7755970221405781,specificity 0.9382917912927883,[tp,tn,fp,fn]: [16044, 70583, 4642, 9304]

TRAIN, epoch 73, loss 0.38177622099481934, acc 0.8366132530571033,recall 0.7254847425301971,precision 0.7938350506499717,specificity 0.8972288042535976,[tp,tn,fp,fn]: [54777, 124198, 14226, 20727]
VAL, loss 0.33710872689903854, acc 0.8627564057947958,f1 0.7054354553020764, recall 0.6520435537320499,precision 0.7683510761935753,specificity 0.9337587238285144,[tp,tn,fp,fn]: [16528, 70242, 4983, 8820]

TRAIN, epoch 74, loss 0.3808454941066744, acc 0.8366973935155754,recall 0.7258555838101293,precision 0.7938036818701931,specificity 0.8971565624458187,[tp,tn,fp,fn]: [54805, 124188, 14236, 20699]
VAL, loss 0.34020856352581846, acc 0.8620106788104163,f1 0.6986450099887085, recall 0.6346457314186523,precision 0.7769996136012365,specificity 0.9386241276171485,[tp,tn,fp,fn]: [16087, 70608, 4617, 9261]

TRAIN, epoch 75, loss 0.38038696015604656, acc 0.8379408025129951,recall 0.7286104047467684,precision 0.7950889566562125,specificity 0.8975755649309368,[tp,tn,fp,fn]: [55013, 124246, 14178, 20491]
VAL, loss 0.3408136358991805, acc 0.8620106788104163,f1 0.7045725476839237, recall 0.6528720214612592,precision 0.76516552616978,specificity 0.9324825523429711,[tp,tn,fp,fn]: [16549, 70146, 5079, 8799]

TRAIN, epoch 76, loss 0.37814152568967674, acc 0.8382680154070529,recall 0.7300275482093664,precision 0.7949808898824547,specificity 0.8973082702421545,[tp,tn,fp,fn]: [55120, 124209, 14215, 20384]
VAL, loss 0.33933199509799317, acc 0.8622194823660426,f1 0.706002164088855, recall 0.6563831465993373,precision 0.7637365159513426,specificity 0.9315785975407112,[tp,tn,fp,fn]: [16638, 70078, 5147, 8710]

TRAIN, epoch 77, loss 0.3774366351078195, acc 0.8379641748625706,recall 0.7292593769866497,precision 0.7947289417470123,specificity 0.8972577009767092,[tp,tn,fp,fn]: [55062, 124202, 14222, 20442]
VAL, loss 0.34089271360747797, acc 0.8620504509162499,f1 0.7048964138341771, recall 0.6537004891904686,precision 0.7647927628542417,specificity 0.9322565636424062,[tp,tn,fp,fn]: [16570, 70129, 5096, 8778]

TRAIN, epoch 78, loss 0.3762905631455526, acc 0.839193560450245,recall 0.7310208730663276,precision 0.7966140834499978,specificity 0.8981968444778362,[tp,tn,fp,fn]: [55195, 124332, 14092, 20309]
VAL, loss 0.34171884661515217, acc 0.8628260069800046,f1 0.7000999956523629, recall 0.6352769449266215,precision 0.779655272586424,specificity 0.9395014955134596,[tp,tn,fp,fn]: [16103, 70674, 4551, 9245]

TRAIN, epoch 79, loss 0.37458362755678803, acc 0.8395908903930295,recall 0.7325042381860564,precision 0.7966323855616052,specificity 0.8980017915968329,[tp,tn,fp,fn]: [55307, 124305, 14119, 20197]
VAL, loss 0.3397721081671204, acc 0.8616527298579142,f1 0.7061705452548888, recall 0.6596181158276787,precision 0.7597927837862402,specificity 0.9297308075772682,[tp,tn,fp,fn]: [16720, 69939, 5286, 8628]

TRAIN, epoch 80, loss 0.37415974874988794, acc 0.8404696907370705,recall 0.7333916083916084,precision 0.7982183013319495,specificity 0.8988759174709587,[tp,tn,fp,fn]: [55374, 124426, 13998, 20130]
VAL, loss 0.34068676606479237, acc 0.8623785707893769,f1 0.7047631236535056, recall 0.6517279469780654,precision 0.7671945386151489,specificity 0.9333599202392822,[tp,tn,fp,fn]: [16520, 70212, 5013, 8828]

TRAIN, epoch 81, loss 0.3725858439655945, acc 0.841039976066714,recall 0.735219326128417,precision 0.7984351177976584,specificity 0.8987603305785123,[tp,tn,fp,fn]: [55512, 124410, 14014, 19992]
VAL, loss 0.33930609496005787, acc 0.8632635001441739,f1 0.7065050367082125, recall 0.6529903739940035,precision 0.7695741119583411,specificity 0.9341176470588235,[tp,tn,fp,fn]: [16552, 70269, 4956, 8796]

TRAIN, epoch 82, loss 0.37165829570393016, acc 0.8411381399349314,recall 0.734954439499894,precision 0.7988483408910962,specificity 0.8990565219904063,[tp,tn,fp,fn]: [55492, 124451, 13973, 20012]
VAL, loss 0.34399348241976874, acc 0.862557545265628,f1 0.6956962025316455, recall 0.6233627899637052,precision 0.7870199731035513,specificity 0.9431571950814224,[tp,tn,fp,fn]: [15801, 70949, 4276, 9547]

TRAIN, epoch 83, loss 0.36964842169693435, acc 0.8428069256946262,recall 0.7376165501165501,precision 0.8012228456337218,specificity 0.9001834941917587,[tp,tn,fp,fn]: [55693, 124607, 13817, 19811]
VAL, loss 0.3427781639086628, acc 0.8625277161862528,f1 0.7075966500296084, recall 0.6599731734259113,precision 0.762627644055434,specificity 0.9307809903622466,[tp,tn,fp,fn]: [16729, 70018, 5207, 8619]

TRAIN, epoch 84, loss 0.3688901598833069, acc 0.842297408473879,recall 0.737510595465141,precision 0.8000373547117222,specificity 0.8994538519331908,[tp,tn,fp,fn]: [55685, 124506, 13918, 19819]
VAL, loss 0.34395398345442896, acc 0.861066091296869,f1 0.7016037755995472, recall 0.6480590184629951,precision 0.7647935192513617,specificity 0.9328414755732801,[tp,tn,fp,fn]: [16427, 70173, 5052, 8921]

TRAIN, epoch 85, loss 0.3674702005137868, acc 0.8428209491043716,recall 0.7392588472133926,precision 0.8001863665687048,specificity 0.8993093683176328,[tp,tn,fp,fn]: [55817, 124486, 13938, 19687]
VAL, loss 0.34158018753839303, acc 0.8621399381543754,f1 0.7048681325698717, recall 0.6531876282152438,precision 0.765429245064953,specificity 0.9325490196078431,[tp,tn,fp,fn]: [16557, 70151, 5074, 8791]

TRAIN, epoch 86, loss 0.3648621641866494, acc 0.844134475150518,recall 0.7407554566645476,precision 0.802439024390244,specificity 0.90052303068832,[tp,tn,fp,fn]: [55930, 124654, 13770, 19574]
VAL, loss 0.3418863959670542, acc 0.8615334135404135,f1 0.6994172242607383, recall 0.6391825785071801,precision 0.7721856829663521,specificity 0.9364572947823198,[tp,tn,fp,fn]: [16202, 70445, 4780, 9146]

TRAIN, epoch 87, loss 0.36429492731773927, acc 0.8452002542911634,recall 0.7439870735325281,precision 0.8029445397369925,specificity 0.9004074437958736,[tp,tn,fp,fn]: [56174, 124638, 13786, 19330]
VAL, loss 0.3422534447278355, acc 0.8614041541964543,f1 0.7011940234517353, recall 0.6452185576771343,precision 0.7678043284352847,specificity 0.9342505815885677,[tp,tn,fp,fn]: [16355, 70279, 4946, 8993]

TRAIN, epoch 88, loss 0.3638552554409513, acc 0.8447468307093976,recall 0.7429672600127145,precision 0.8024977468778164,specificity 0.9002629601803156,[tp,tn,fp,fn]: [56097, 124618, 13806, 19407]
VAL, loss 0.3441759270128041, acc 0.862835950006463,f1 0.7005318571583632, recall 0.6365393719425596,precision 0.7788289810300719,specificity 0.939089398471253,[tp,tn,fp,fn]: [16135, 70643, 4582, 9213]

TRAIN, epoch 89, loss 0.36239246018630733, acc 0.8454480011966643,recall 0.7443976478067387,precision 0.803284311623719,specificity 0.9005663757729874,[tp,tn,fp,fn]: [56205, 124660, 13764, 19299]
VAL, loss 0.33710130961088314, acc 0.8643870621339723,f1 0.7075999571229499, recall 0.6510572826258482,precision 0.7748978729398507,specificity 0.936271186440678,[tp,tn,fp,fn]: [16503, 70431, 4794, 8845]

TRAIN, epoch 90, loss 0.36058319204742784, acc 0.8460790546352044,recall 0.7459472345835982,precision 0.8038191471142319,specificity 0.9006964110269895,[tp,tn,fp,fn]: [56322, 124678, 13746, 19182]
VAL, loss 0.34388666521073813, acc 0.8629154942181301,f1 0.7010040988050574, recall 0.6376045447372574,precision 0.7784038915378317,specificity 0.9388368228647391,[tp,tn,fp,fn]: [16162, 70624, 4601, 9186]

TRAIN, epoch 91, loss 0.35906673523104854, acc 0.8470700422572081,recall 0.747258423394787,precision 0.8053929825563138,specificity 0.9015127434548922,[tp,tn,fp,fn]: [56421, 124791, 13633, 19083]
VAL, loss 0.3447829193493291, acc 0.8630944686943812,f1 0.7022081882475075, recall 0.6404450055231182,precision 0.7771554406625497,specificity 0.938118976404121,[tp,tn,fp,fn]: [16234, 70570, 4655, 9114]

TRAIN, epoch 92, loss 0.357346409775682, acc 0.8478974234321828,recall 0.7464770078406442,precision 0.807953095657908,specificity 0.9032176501184765,[tp,tn,fp,fn]: [56362, 125027, 13397, 19142]
VAL, loss 0.34912975802708696, acc 0.8620305648633331,f1 0.7004447130952896, recall 0.6400110462363895,precision 0.7734814532278058,specificity 0.9368428049185776,[tp,tn,fp,fn]: [16223, 70474, 4751, 9125]

TRAIN, epoch 93, loss 0.3558492381278233, acc 0.8479768894207397,recall 0.7498278236914601,precision 0.8059304179478419,specificity 0.9015127434548922,[tp,tn,fp,fn]: [56615, 124791, 13633, 18889]
VAL, loss 0.34350114748560917, acc 0.8625277161862528,f1 0.7034574468085106, recall 0.6469543948240493,precision 0.7707745816882873,specificity 0.935167829843802,[tp,tn,fp,fn]: [16399, 70348, 4877, 8949]

TRAIN, epoch 94, loss 0.3545640608150428, acc 0.849080064320706,recall 0.7509535918626827,precision 0.8078994614003591,specificity 0.9026035947523551,[tp,tn,fp,fn]: [56700, 124942, 13482, 18804]
VAL, loss 0.34607470110541794, acc 0.8624382289481273,f1 0.7035759432648426, recall 0.6477434117090106,precision 0.7699413833528722,specificity 0.934782319707544,[tp,tn,fp,fn]: [16419, 70319, 4906, 8929]

TRAIN, epoch 95, loss 0.3521928960978951, acc 0.8495194644927265,recall 0.7526091332909515,precision 0.8078847848957889,specificity 0.9023796451482402,[tp,tn,fp,fn]: [56825, 124911, 13513, 18679]
VAL, loss 0.3501017838472779, acc 0.8622294253925009,f1 0.7005661926783939, recall 0.6394587344169165,precision 0.7745866386313677,specificity 0.9372947823197075,[tp,tn,fp,fn]: [16209, 70508, 4717, 9139]

TRAIN, epoch 96, loss 0.3524763396837374, acc 0.8498279795071239,recall 0.7522912693367239,precision 0.8088545226703121,specificity 0.9030298214182512,[tp,tn,fp,fn]: [56801, 125001, 13423, 18703]
VAL, loss 0.3468557714082639, acc 0.8604297376035318,f1 0.7019175638657069, recall 0.6520041028878018,precision 0.7601067010072207,specificity 0.930661349285477,[tp,tn,fp,fn]: [16527, 70009, 5216, 8821]

TRAIN, epoch 97, loss 0.3498100412785305, acc 0.8505011031749,recall 0.7559467048103412,precision 0.8080898176463925,specificity 0.9020762295555684,[tp,tn,fp,fn]: [57077, 124869, 13555, 18427]
VAL, loss 0.34716242120683644, acc 0.8626768615831286,f1 0.7045838591687879, recall 0.649755404765662,precision 0.7695182918282484,specificity 0.9344233964772349,[tp,tn,fp,fn]: [16470, 70292, 4933, 8878]

TRAIN, epoch 98, loss 0.3489959309001782, acc 0.8511882502524214,recall 0.7548076923076923,precision 0.8105329028771351,specificity 0.903759463676819,[tp,tn,fp,fn]: [56991, 125102, 13322, 18513]
VAL, loss 0.3495678024316919, acc 0.8620902230220835,f1 0.6992367074334288, recall 0.6360659618115828,precision 0.7763385978428351,specificity 0.9382519109338651,[tp,tn,fp,fn]: [16123, 70580, 4645, 9225]

TRAIN, epoch 99, loss 0.34744793403280605, acc 0.8518333271007068,recall 0.7576287349014622,precision 0.8102434809705245,specificity 0.9032176501184765,[tp,tn,fp,fn]: [57204, 125027, 13397, 18300]
VAL, loss 0.35124658962949806, acc 0.8608374016883259,f1 0.6962805433791937, recall 0.6329098942717374,precision 0.7737532555223304,specificity 0.9376404120970422,[tp,tn,fp,fn]: [16043, 70534, 4691, 9305]



 * BEST_ACC: 0.8643870621339723
 * TIME: Time 9888.068 (9888.068)

