pooling_ratio 0.2, dropout0.2, hidden_dim 64, outdim 128
epochs 50, lr 0.0001, weight_decay 0.001
pooling_ratio 0.2, dropout0.2, hidden_dim 64, outdim 128
epochs 50, lr 0.0001, weight_decay 0.001
TRAIN, epoch 0, loss 0.5504865424290926, acc 0.7482190269623424,recall 0.49491417673235855,precision 0.7037950842828892,specificity 0.8863853089059701,[tp,tn,fp,fn]: [37368, 122697, 15727, 38136]
VAL, loss 0.4009032950338497, acc 0.8243365515595636,f1 0.5642189388520263, recall 0.4511993056651412,precision 0.7527808859343118,specificity 0.9500697906281157,[tp,tn,fp,fn]: [11437, 71469, 3756, 13911]

TRAIN, epoch 1, loss 0.4863442937857746, acc 0.7784581728431996,recall 0.6041666666666666,precision 0.7226569925860211,specificity 0.8735262671213084,[tp,tn,fp,fn]: [45617, 120917, 17507, 29887]
VAL, loss 0.3801135873916908, acc 0.8384655921569407,f1 0.6156794095382285, recall 0.5133738362000947,precision 0.7689080595603877,specificity 0.9480093054170821,[tp,tn,fp,fn]: [13013, 71314, 3911, 12335]

TRAIN, epoch 2, loss 0.4655935284094252, acc 0.7910932650237463,recall 0.6321916719643992,precision 0.7382952067189458,specificity 0.8777668612379356,[tp,tn,fp,fn]: [47733, 121504, 16920, 27771]
VAL, loss 0.36635266762558444, acc 0.8425322899784237,f1 0.6369908542874826, recall 0.5481694808268897,precision 0.7601619344603097,specificity 0.9417215021601861,[tp,tn,fp,fn]: [13895, 70841, 4384, 11453]

TRAIN, epoch 3, loss 0.4536614601194651, acc 0.797445869638383,recall 0.6513429752066116,precision 0.7430423352370592,specificity 0.8771383575102584,[tp,tn,fp,fn]: [49179, 121417, 17007, 26325]
VAL, loss 0.3630066872485075, acc 0.844361806846768,f1 0.6362558966374643, recall 0.540082057756036,precision 0.7741023466214306,specificity 0.9468926553672317,[tp,tn,fp,fn]: [13690, 71230, 3995, 11658]

TRAIN, epoch 4, loss 0.44818953662048633, acc 0.801297632848435,recall 0.6631304301758847,precision 0.7457180304429418,specificity 0.876661561578917,[tp,tn,fp,fn]: [50069, 121351, 17073, 25435]
VAL, loss 0.3563326707424525, acc 0.8485975361180436,f1 0.656717090876299, recall 0.5746015464730945,precision 0.7662160029459729,specificity 0.9409238949817215,[tp,tn,fp,fn]: [14565, 70781, 4444, 10783]

TRAIN, epoch 5, loss 0.44145551786288634, acc 0.8042145020754646,recall 0.6702691248145793,precision 0.748683354044618,specificity 0.8772756169450384,[tp,tn,fp,fn]: [50608, 121436, 16988, 24896]
VAL, loss 0.35764807065946047, acc 0.8484682767740845,f1 0.6547662196447988, recall 0.5701436010730629,precision 0.7688869972334539,specificity 0.9422532402791625,[tp,tn,fp,fn]: [14452, 70881, 4344, 10896]

TRAIN, epoch 6, loss 0.4389168592682194, acc 0.8058505665457537,recall 0.6768912905276542,precision 0.7488790551827214,specificity 0.8761919898283534,[tp,tn,fp,fn]: [51108, 121286, 17138, 24396]
VAL, loss 0.3596799551687088, acc 0.8474043729430364,f1 0.6462439204296614, recall 0.553021934669402,precision 0.7772664263931245,specificity 0.9466001994017946,[tp,tn,fp,fn]: [14018, 71208, 4017, 11330]

TRAIN, epoch 7, loss 0.4359220008072458, acc 0.8069023222766538,recall 0.6793944691671965,precision 0.7499671047822336,specificity 0.8764520603363578,[tp,tn,fp,fn]: [51297, 121322, 17102, 24207]
VAL, loss 0.3542023178484429, acc 0.8495719527109662,f1 0.6625627300100368, recall 0.5859633896165378,precision 0.7622004413198543,specificity 0.9383981389165836,[tp,tn,fp,fn]: [14853, 70591, 4634, 10495]

TRAIN, epoch 8, loss 0.4340876612687877, acc 0.8088188549418496,recall 0.684135939817758,precision 0.7518375664071029,specificity 0.8768277177368087,[tp,tn,fp,fn]: [51655, 121374, 17050, 23849]
VAL, loss 0.35983652308921515, acc 0.847722549789705,f1 0.6476475324974117, recall 0.5552706327915418,precision 0.7768946293536457,specificity 0.9462678630774344,[tp,tn,fp,fn]: [14075, 71183, 4042, 11273]

TRAIN, epoch 9, loss 0.43321758513140174, acc 0.8094171870909839,recall 0.6881622165713075,precision 0.7510153935101539,specificity 0.8755562619198983,[tp,tn,fp,fn]: [51959, 121198, 17226, 23545]
VAL, loss 0.35397887356539226, acc 0.850606027462639,f1 0.6661185306993177, recall 0.5912892535900268,precision 0.7626316592886582,specificity 0.9379860418743768,[tp,tn,fp,fn]: [14988, 70560, 4665, 10360]

TRAIN, epoch 10, loss 0.43180283154364607, acc 0.8088609251710857,recall 0.6891422970968426,precision 0.7491936877267753,specificity 0.8741619950297637,[tp,tn,fp,fn]: [52033, 121005, 17419, 23471]
VAL, loss 0.3527391213672668, acc 0.8506756286478478,f1 0.6679784223558543, recall 0.5959839040555468,precision 0.7597565882116274,specificity 0.936497175141243,[tp,tn,fp,fn]: [15107, 70448, 4777, 10241]

TRAIN, epoch 11, loss 0.43087286223140553, acc 0.8112075090684716,recall 0.6916587200678109,precision 0.7532525602192414,specificity 0.8764159394324683,[tp,tn,fp,fn]: [52223, 121317, 17107, 23281]
VAL, loss 0.3547392249937516, acc 0.8507750589124318,f1 0.6644757433489827, recall 0.5862789963705223,precision 0.7667423382519863,specificity 0.9399002991026919,[tp,tn,fp,fn]: [14861, 70704, 4521, 10487]

TRAIN, epoch 12, loss 0.4300500556532926, acc 0.8106512471485734,recall 0.693168573850392,precision 0.7511373911046687,specificity 0.8747327053112177,[tp,tn,fp,fn]: [52337, 121084, 17340, 23167]
VAL, loss 0.3534202544264965, acc 0.8512224951030595,f1 0.6667409073698747, recall 0.5905002367050655,precision 0.7655874379827119,specificity 0.9390761050182785,[tp,tn,fp,fn]: [14968, 70642, 4583, 10380]

TRAIN, epoch 13, loss 0.42889064836709817, acc 0.8114225346845668,recall 0.6916984530620894,precision 0.7537306970702843,specificity 0.876726579205918,[tp,tn,fp,fn]: [52226, 121360, 17064, 23278]
VAL, loss 0.35070190094055415, acc 0.8513318683941018,f1 0.6683524088368379, recall 0.594366419441376,precision 0.7633765707336846,specificity 0.9379195746095048,[tp,tn,fp,fn]: [15066, 70555, 4670, 10282]

TRAIN, epoch 14, loss 0.42847782845410826, acc 0.8117590965184548,recall 0.6942678533587624,precision 0.7530959974714824,specificity 0.8758452291510143,[tp,tn,fp,fn]: [52420, 121238, 17186, 23084]
VAL, loss 0.35228531405977326, acc 0.8513219253676434,f1 0.6706024892609318, recall 0.6004813002998264,precision 0.7592657255449693,specificity 0.9358457959454969,[tp,tn,fp,fn]: [15221, 70399, 4826, 10127]

TRAIN, epoch 15, loss 0.4277028868186002, acc 0.8119040050858233,recall 0.6943473193473193,precision 0.7533878454308994,specificity 0.8760258336704617,[tp,tn,fp,fn]: [52426, 121263, 17161, 23078]
VAL, loss 0.3483887461652664, acc 0.8535591063207819,f1 0.6871309002846582, recall 0.6380385040239861,precision 0.7444076222038111,specificity 0.9261814556331007,[tp,tn,fp,fn]: [16173, 69672, 5553, 9175]

TRAIN, epoch 16, loss 0.42626855637937944, acc 0.8128903182379118,recall 0.6966121000211909,precision 0.754424969161479,specificity 0.8763148009015778,[tp,tn,fp,fn]: [52597, 121303, 17121, 22907]
VAL, loss 0.35034931556270293, acc 0.851640102214312,f1 0.6705671958139227, recall 0.5991005207511441,precision 0.7613938330408624,specificity 0.9367364572947823,[tp,tn,fp,fn]: [15186, 70466, 4759, 10162]

TRAIN, epoch 17, loss 0.4253364836256665, acc 0.8137176994128866,recall 0.6972743165924984,precision 0.7559770824657889,specificity 0.877232271860371,[tp,tn,fp,fn]: [52647, 121430, 16994, 22857]
VAL, loss 0.3511128064578389, acc 0.8523062849870243,f1 0.6793731652564324, recall 0.6208379359318289,precision 0.750095328884652,specificity 0.9303024260551678,[tp,tn,fp,fn]: [15737, 69982, 5243, 9611]

TRAIN, epoch 18, loss 0.4251384327731374, acc 0.8135213716764519,recall 0.6978703115066751,precision 0.7551918363837015,specificity 0.8766037681326938,[tp,tn,fp,fn]: [52692, 121343, 17081, 22812]
VAL, loss 0.352602779630279, acc 0.8522863989341075,f1 0.6776041666666667, recall 0.6159065804008206,precision 0.7530387806289793,specificity 0.9319375207710203,[tp,tn,fp,fn]: [15612, 70105, 5120, 9736]

TRAIN, epoch 19, loss 0.42389530480757226, acc 0.8138766313900003,recall 0.6989563466836194,precision 0.7554143227265571,specificity 0.8765604230480264,[tp,tn,fp,fn]: [52774, 121337, 17087, 22730]
VAL, loss 0.35047215362674156, acc 0.8523659431457747,f1 0.6783640932328221, recall 0.6177213192362316,precision 0.7522098385857033,specificity 0.9314323695579927,[tp,tn,fp,fn]: [15658, 70067, 5158, 9690]

TRAIN, epoch 20, loss 0.424279196719252, acc 0.8142739613327848,recall 0.6999496715405806,precision 0.7557846866687641,specificity 0.8766326648558054,[tp,tn,fp,fn]: [52849, 121347, 17077, 22655]
VAL, loss 0.35116676932301116, acc 0.8518886778757718,f1 0.6818453652285349, recall 0.629714375887644,precision 0.743386736214605,specificity 0.9267530741110004,[tp,tn,fp,fn]: [15962, 69715, 5510, 9386]

TRAIN, epoch 21, loss 0.4231065938672106, acc 0.8146899891552298,recall 0.7015522356431447,precision 0.7558612423122476,specificity 0.8764014910709126,[tp,tn,fp,fn]: [52970, 121315, 17109, 22534]
VAL, loss 0.3510844651227955, acc 0.852853151442236,f1 0.6907791637936438, recall 0.652122455420546,precision 0.7343076718048954,specificity 0.9204918577600532,[tp,tn,fp,fn]: [16530, 69244, 5981, 8818]

TRAIN, epoch 22, loss 0.4229454513481652, acc 0.8147507572641263,recall 0.6994861199406653,precision 0.757146543567394,specificity 0.8776223776223776,[tp,tn,fp,fn]: [52814, 121484, 16940, 22690]
VAL, loss 0.35240349030657786, acc 0.8525150885426506,f1 0.6765379331399786, recall 0.6119614959760139,precision 0.7563508703496026,specificity 0.9335726154868728,[tp,tn,fp,fn]: [15512, 70228, 4997, 9836]

TRAIN, epoch 23, loss 0.42282428976298403, acc 0.8151106914475899,recall 0.7017111676202585,precision 0.7567451758959051,specificity 0.8769649771715887,[tp,tn,fp,fn]: [52982, 121393, 17031, 22522]
VAL, loss 0.3503671581498955, acc 0.8536983086911994,f1 0.6832429174201327, recall 0.6260454473725737,precision 0.751942759666414,specificity 0.9304087736789631,[tp,tn,fp,fn]: [15869, 69990, 5235, 9479]

TRAIN, epoch 24, loss 0.42226633094403004, acc 0.8155874873789313,recall 0.7016846789574063,precision 0.7578640193399803,specificity 0.8777162919724903,[tp,tn,fp,fn]: [52980, 121497, 16927, 22524]
VAL, loss 0.3521415447247327, acc 0.8529923538126535,f1 0.6792076200394889, recall 0.6174846141707433,precision 0.7546405669929126,specificity 0.932349617813227,[tp,tn,fp,fn]: [15652, 70136, 5089, 9696]

TRAIN, epoch 25, loss 0.42237103587870223, acc 0.8155173703302045,recall 0.7014330366603094,precision 0.7578415660236965,specificity 0.8777451886956019,[tp,tn,fp,fn]: [52961, 121501, 16923, 22543]
VAL, loss 0.353402528962834, acc 0.8523162280134827,f1 0.6802023899235655, recall 0.6231655357424649,precision 0.7487320472105039,specificity 0.929531405782652,[tp,tn,fp,fn]: [15796, 69924, 5301, 9552]

TRAIN, epoch 26, loss 0.4219143352161362, acc 0.8151293893272503,recall 0.7014330366603094,precision 0.756942558634785,specificity 0.8771455816910363,[tp,tn,fp,fn]: [52961, 121418, 17006, 22543]
VAL, loss 0.35194632508983065, acc 0.8525548606484842,f1 0.6750662839362798, recall 0.6077008047972227,precision 0.7592291389422839,specificity 0.9350614822200066,[tp,tn,fp,fn]: [15404, 70340, 4885, 9944]

TRAIN, epoch 27, loss 0.4216699712269594, acc 0.8162045174077259,recall 0.7038435049798686,precision 0.7580918959786593,specificity 0.8774923423683755,[tp,tn,fp,fn]: [53143, 121466, 16958, 22361]
VAL, loss 0.3513363434822569, acc 0.8529128096009864,f1 0.6766910720139876, recall 0.6107385198043238,precision 0.7586122408977312,specificity 0.9345164506480559,[tp,tn,fp,fn]: [15481, 70299, 4926, 9867]

TRAIN, epoch 28, loss 0.4210657740529975, acc 0.8159333981526495,recall 0.7011151727060818,precision 0.7589860495791934,specificity 0.8785615211235046,[tp,tn,fp,fn]: [52937, 121614, 16810, 22567]
VAL, loss 0.35267577775692943, acc 0.8520875384049397,f1 0.6707101115636621, recall 0.5976802903582137,precision 0.7640710106919508,specificity 0.9378132269857096,[tp,tn,fp,fn]: [15150, 70547, 4678, 10198]

TRAIN, epoch 29, loss 0.42173869311999, acc 0.8153163681238548,recall 0.7006781097690189,precision 0.7577958259922937,specificity 0.8778463272264925,[tp,tn,fp,fn]: [52904, 121515, 16909, 22600]
VAL, loss 0.35395371438204126, acc 0.8520875384049397,f1 0.6749125874125874, recall 0.6091999368786492,precision 0.7565157750342936,specificity 0.9339315387171818,[tp,tn,fp,fn]: [15442, 70255, 4970, 9906]

TRAIN, epoch 30, loss 0.4214379458338984, acc 0.8156529299577427,recall 0.7012873490146218,precision 0.7582375094869188,specificity 0.878034155926718,[tp,tn,fp,fn]: [52950, 121541, 16883, 22554]
VAL, loss 0.35202852075668983, acc 0.8521273105107733,f1 0.6745448179271709, recall 0.6080164115512072,precision 0.7574208767446432,specificity 0.9343835161183117,[tp,tn,fp,fn]: [15412, 70289, 4936, 9936]

TRAIN, epoch 31, loss 0.4210140079929675, acc 0.8163634493848397,recall 0.7034064420428057,precision 0.7587034470936129,specificity 0.8779763624804947,[tp,tn,fp,fn]: [53110, 121533, 16891, 22394]
VAL, loss 0.35271487674736973, acc 0.8530520119714039,f1 0.6757782506636247, recall 0.6076219031087265,precision 0.7611564121571535,specificity 0.9357527417746759,[tp,tn,fp,fn]: [15402, 70392, 4833, 9946]

TRAIN, epoch 32, loss 0.4205887674737015, acc 0.8164522643132269,recall 0.7023336511972875,precision 0.7595101690060154,specificity 0.8786987805582847,[tp,tn,fp,fn]: [53029, 121633, 16791, 22475]
VAL, loss 0.3532709757581408, acc 0.8521173674843149,f1 0.6740164383561644, recall 0.6065961811582767,precision 0.758297578537259,specificity 0.9348487869724161,[tp,tn,fp,fn]: [15376, 70324, 4901, 9972]

TRAIN, epoch 33, loss 0.4202991992581787, acc 0.8165223813619535,recall 0.7034991523627887,precision 0.759020305511496,specificity 0.878171415361498,[tp,tn,fp,fn]: [53117, 121560, 16864, 22387]
VAL, loss 0.3523550091377953, acc 0.8526045757807762,f1 0.6771495774893284, recall 0.6133028246804482,precision 0.7558343057176196,specificity 0.9332402791625125,[tp,tn,fp,fn]: [15546, 70203, 5022, 9802]

TRAIN, epoch 34, loss 0.4202501623847446, acc 0.8167187090983883,recall 0.7025588048315321,precision 0.7600040116337379,specificity 0.8789877477894007,[tp,tn,fp,fn]: [53046, 121673, 16751, 22458]
VAL, loss 0.35324249343145514, acc 0.8520577093255645,f1 0.6706655747139156, recall 0.5976802903582137,precision 0.7639554233271141,specificity 0.9377733466267864,[tp,tn,fp,fn]: [15150, 70544, 4681, 10198]

TRAIN, epoch 35, loss 0.4201995124301024, acc 0.8168308963763509,recall 0.7029561347743166,precision 0.7600418140420718,specificity 0.8789444027047333,[tp,tn,fp,fn]: [53076, 121667, 16757, 22428]
VAL, loss 0.3515600162113557, acc 0.8529625247332783,f1 0.6823064363667611, recall 0.6264794066593025,precision 0.7490566037735849,specificity 0.9292788301761382,[tp,tn,fp,fn]: [15880, 69905, 5320, 9468]

TRAIN, epoch 36, loss 0.42010999238997926, acc 0.816835570846266,recall 0.7038037719855902,precision 0.759576901086335,specificity 0.8784892793157256,[tp,tn,fp,fn]: [53140, 121604, 16820, 22364]
VAL, loss 0.3532563154576909, acc 0.8530619549978623,f1 0.6820567986230637, recall 0.6253353321761086,precision 0.7500946431951543,specificity 0.9297972748421403,[tp,tn,fp,fn]: [15851, 69944, 5281, 9497]

TRAIN, epoch 37, loss 0.4201105841501351, acc 0.816667289929322,recall 0.7028501801229073,precision 0.7597205520242799,specificity 0.87874934982373,[tp,tn,fp,fn]: [53068, 121640, 16784, 22436]
VAL, loss 0.35450910544053016, acc 0.8516202161613952,f1 0.6762976941931845, recall 0.614999210983115,precision 0.7511685057582036,specificity 0.9313526088401463,[tp,tn,fp,fn]: [15589, 70061, 5164, 9759]

TRAIN, epoch 38, loss 0.420014058644001, acc 0.8165130324221234,recall 0.7019230769230769,precision 0.7598824288479461,specificity 0.8790166445125123,[tp,tn,fp,fn]: [52998, 121677, 16747, 22506]
VAL, loss 0.3528664837524242, acc 0.8521869686695236,f1 0.6734039281163495, recall 0.6046236389458735,precision 0.7598413485374318,specificity 0.9356065137919575,[tp,tn,fp,fn]: [15326, 70381, 4844, 10022]

TRAIN, epoch 39, loss 0.41988723838673914, acc 0.8164055196140758,recall 0.701048951048951,precision 0.7601240737549544,specificity 0.879327284285962,[tp,tn,fp,fn]: [52932, 121720, 16704, 22572]
VAL, loss 0.35303256456020565, acc 0.8518290197170215,f1 0.6723106693640601, recall 0.6030850560201988,precision 0.7594892686804452,specificity 0.9356463941508807,[tp,tn,fp,fn]: [15287, 70384, 4841, 10061]

TRAIN, epoch 40, loss 0.41953176373671514, acc 0.8166345686399162,recall 0.704850074168256,precision 0.7585268168925756,specificity 0.8776079292608219,[tp,tn,fp,fn]: [53219, 121482, 16942, 22285]
VAL, loss 0.35029971471292237, acc 0.8533005876328636,f1 0.6819710294878427, recall 0.6240729051601704,precision 0.7517107013875689,specificity 0.9305417082087072,[tp,tn,fp,fn]: [15819, 70000, 5225, 9529]

TRAIN, epoch 41, loss 0.41981136156026305, acc 0.8165177068920384,recall 0.7020687645687645,precision 0.7598113694349683,specificity 0.8789444027047333,[tp,tn,fp,fn]: [53009, 121667, 16757, 22495]
VAL, loss 0.3513982662681412, acc 0.8521869686695236,f1 0.6754857018118314, recall 0.6103834622060912,precision 0.7561333203010459,specificity 0.9336656696576936,[tp,tn,fp,fn]: [15472, 70235, 4990, 9876]

TRAIN, epoch 42, loss 0.4195160554865928, acc 0.8171113645712577,recall 0.7021747192201737,precision 0.7611370325174073,specificity 0.8798040802173034,[tp,tn,fp,fn]: [53017, 121786, 16638, 22487]
VAL, loss 0.3507369064086419, acc 0.8531216131566126,f1 0.677692441961948, recall 0.612671611172479,precision 0.7581527045498926,specificity 0.9341442339647723,[tp,tn,fp,fn]: [15530, 70271, 4954, 9818]

TRAIN, epoch 43, loss 0.41942114305498, acc 0.8171440858606634,recall 0.703697817334181,precision 0.7603537594092561,specificity 0.8790238686932902,[tp,tn,fp,fn]: [53132, 121678, 16746, 22372]
VAL, loss 0.352913848971018, acc 0.8529227526274448,f1 0.6765078948519441, recall 0.6101862079848509,precision 0.7590048091078614,specificity 0.934715852442672,[tp,tn,fp,fn]: [15467, 70314, 4911, 9881]

TRAIN, epoch 44, loss 0.41930185044909785, acc 0.8168589431958416,recall 0.7030091121000211,precision 0.7600773251235055,specificity 0.8789588510662891,[tp,tn,fp,fn]: [53080, 121669, 16755, 22424]
VAL, loss 0.34952859443021883, acc 0.8530718980243206,f1 0.6779838305476258, recall 0.6136973331229288,precision 0.7573146390146536,specificity 0.9337321369225656,[tp,tn,fp,fn]: [15556, 70240, 4985, 9792]

TRAIN, epoch 45, loss 0.4189185778341575, acc 0.8165738005310198,recall 0.7042408349226531,precision 0.7587254929939214,specificity 0.8778463272264925,[tp,tn,fp,fn]: [53173, 121515, 16909, 22331]
VAL, loss 0.3498600204295345, acc 0.8529724677597367,f1 0.6747608050148466, recall 0.6051364999210983,precision 0.7624894367947507,specificity 0.9364838816882686,[tp,tn,fp,fn]: [15339, 70447, 4778, 10009]

TRAIN, epoch 46, loss 0.4191171308604439, acc 0.8170225496428705,recall 0.7022276965458784,precision 0.7608995149392956,specificity 0.8796379240594117,[tp,tn,fp,fn]: [53021, 121763, 16661, 22483]
VAL, loss 0.3501725653583053, acc 0.8530321259184871,f1 0.6852360569858813, recall 0.6347246331071484,precision 0.7444819767710888,specificity 0.9265935526753074,[tp,tn,fp,fn]: [16089, 69703, 5522, 9259]

TRAIN, epoch 47, loss 0.41929542150160776, acc 0.8173544370068434,recall 0.703790527654164,precision 0.7607914441565136,specificity 0.8792983875628504,[tp,tn,fp,fn]: [53139, 121716, 16708, 22365]
VAL, loss 0.35313043858879556, acc 0.8512423811559763,f1 0.6682925747732966, recall 0.5945636736626164,precision 0.7628954695013921,specificity 0.937733466267863,[tp,tn,fp,fn]: [15071, 70541, 4684, 10277]

TRAIN, epoch 48, loss 0.41906808208212937, acc 0.817130062450918,recall 0.7038170163170163,precision 0.7602540808881386,specificity 0.8789371785239554,[tp,tn,fp,fn]: [53141, 121666, 16758, 22363]
VAL, loss 0.3525485631677096, acc 0.8536784226382826,f1 0.6816785637032231, recall 0.6216269528167903,precision 0.7545733167321138,specificity 0.9318710535061482,[tp,tn,fp,fn]: [15757, 70100, 5125, 9591]

TRAIN, epoch 49, loss 0.4192217854718647, acc 0.8171721326801541,recall 0.7028634244543336,precision 0.7608895133771112,specificity 0.8795223371669653,[tp,tn,fp,fn]: [53069, 121747, 16677, 22435]
VAL, loss 0.35222729908789197, acc 0.8527636642041104,f1 0.6779469334493258, recall 0.6148808584503709,precision 0.7554284606436603,specificity 0.9329212362911267,[tp,tn,fp,fn]: [15586, 70179, 5046, 9762]



 * BEST_ACC: 0.8536983086911994
 * TIME: Time 4497.268 (4497.268)

