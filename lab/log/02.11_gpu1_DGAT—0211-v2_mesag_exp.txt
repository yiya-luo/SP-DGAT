pooling_ratio 0.2, dropout0.5, hidden_dim 128, outdim 256
epochs 50, lr 0.0001, weight_decay 0.001
TRAIN, epoch 0, loss 0.590270135095172, acc 0.6985668075240268,recall 0.2636416613689341,precision 0.6913485916715868,specificity 0.9357987054268047,[tp,tn,fp,fn]: [19906, 129537, 8887, 55598]
VAL, loss 0.45891947620169704, acc 0.8008113509590049,f1 0.4989119287626004, recall 0.39344326968597126,precision 0.6816348848335726,specificity 0.9380790960451978,[tp,tn,fp,fn]: [9973, 70567, 4658, 15375]

TRAIN, epoch 1, loss 0.5526742609128257, acc 0.7326717400246812,recall 0.4130244755244755,precision 0.7078651685393258,specificity 0.9070247933884298,[tp,tn,fp,fn]: [31185, 125554, 12870, 44319]
VAL, loss 0.44233254552876944, acc 0.813856601672417,f1 0.509728951158832, recall 0.38393561622218714,precision 0.7581210563215705,specificity 0.9587238285144566,[tp,tn,fp,fn]: [9732, 72120, 3105, 15616]

TRAIN, epoch 2, loss 0.5477639874734919, acc 0.7391879510863468,recall 0.4228120364484001,precision 0.7232606085321371,specificity 0.9117566317979541,[tp,tn,fp,fn]: [31924, 126209, 12215, 43580]
VAL, loss 0.44545987434142587, acc 0.8082288486969664,f1 0.4699480583724957, recall 0.3373047183209721,precision 0.774526678141136,specificity 0.9669125955466933,[tp,tn,fp,fn]: [8550, 72736, 2489, 16798]

TRAIN, epoch 3, loss 0.5439227150464699, acc 0.7425816162447179,recall 0.4327717736808646,precision 0.7274751207783244,specificity 0.9115688030977287,[tp,tn,fp,fn]: [32676, 126183, 12241, 42828]
VAL, loss 0.4488475388888379, acc 0.8056138327384089,f1 0.44472847080209044, recall 0.3088606596181158,precision 0.7940162271805273,specificity 0.9730009970089731,[tp,tn,fp,fn]: [7829, 73194, 2031, 17519]

TRAIN, epoch 4, loss 0.5410077373535951, acc 0.7447458958154145,recall 0.44258582326764145,precision 0.7274686520376176,specificity 0.9095604808414726,[tp,tn,fp,fn]: [33417, 125905, 12519, 42087]
VAL, loss 0.4370505101313899, acc 0.8145227844451294,f1 0.5078619670747151, recall 0.379714375887644,precision 0.766565785281937,specificity 0.961036889332004,[tp,tn,fp,fn]: [9625, 72294, 2931, 15723]

TRAIN, epoch 5, loss 0.5384676377568488, acc 0.7466811263602707,recall 0.4463604577240941,precision 0.7311897943243947,specificity 0.9104924001618216,[tp,tn,fp,fn]: [33702, 126034, 12390, 41802]
VAL, loss 0.44002809573432766, acc 0.8081393614588408,f1 0.456205613797768, recall 0.3193151333438536,precision 0.7985398579321231,specificity 0.9728547690262546,[tp,tn,fp,fn]: [8094, 73183, 2042, 17254]

TRAIN, epoch 6, loss 0.5387665833381408, acc 0.746774615758573,recall 0.44879741470650564,precision 0.7296726959517658,specificity 0.9093076345142461,[tp,tn,fp,fn]: [33886, 125870, 12554, 41618]
VAL, loss 0.4334802093366782, acc 0.8117884521690713,f1 0.477892704454558, recall 0.3417626637210036,precision 0.7942605666086,specificity 0.9701694915254238,[tp,tn,fp,fn]: [8663, 72981, 2244, 16685]

TRAIN, epoch 7, loss 0.5383606865031928, acc 0.7468494072772147,recall 0.4469167196439924,precision 0.7313394018205461,specificity 0.9104490550771542,[tp,tn,fp,fn]: [33744, 126028, 12396, 41760]
VAL, loss 0.43638062724780485, acc 0.8086563988346773,f1 0.45806814981695293, recall 0.3208537162695282,precision 0.8003345798071246,specificity 0.973027583914922,[tp,tn,fp,fn]: [8133, 73196, 2029, 17215]

TRAIN, epoch 8, loss 0.5379057746832071, acc 0.7460547473916458,recall 0.44842657342657344,precision 0.727534487945335,specificity 0.9083973877362307,[tp,tn,fp,fn]: [33858, 125744, 12680, 41646]
VAL, loss 0.43510371505422657, acc 0.8086663418611357,f1 0.45541248054337063, recall 0.31742149281994636,precision 0.8056473415440072,specificity 0.97419740777667,[tp,tn,fp,fn]: [8046, 73284, 1941, 17302]

TRAIN, epoch 9, loss 0.5362083888781427, acc 0.7482751206013238,recall 0.451221127357491,precision 0.7329030870173174,specificity 0.9103045714615963,[tp,tn,fp,fn]: [34069, 126008, 12416, 41435]
VAL, loss 0.4329162166855298, acc 0.8104461435971881,f1 0.46712880143112695, recall 0.32965125453684707,precision 0.8013041810510165,specificity 0.9724559654370223,[tp,tn,fp,fn]: [8356, 73153, 2072, 16992]

TRAIN, epoch 10, loss 0.5351892371130598, acc 0.7482564227216634,recall 0.45243960584869675,precision 0.7319220962869325,specificity 0.9096110501069179,[tp,tn,fp,fn]: [34161, 125912, 12512, 41343]
VAL, loss 0.4322804759378489, acc 0.8118679963807384,f1 0.47635125785293225, recall 0.3395139655988638,precision 0.7979601298099211,specificity 0.9710335659687603,[tp,tn,fp,fn]: [8606, 73046, 2179, 16742]

TRAIN, epoch 11, loss 0.5352795953584062, acc 0.7488874761602035,recall 0.45360510701419793,precision 0.7331635055871901,specificity 0.9099505866034792,[tp,tn,fp,fn]: [34249, 125959, 12465, 41255]
VAL, loss 0.43044993705850404, acc 0.8147216449742973,f1 0.4907351735446844, recall 0.3541896796591447,precision 0.7986123465575521,specificity 0.9699036224659355,[tp,tn,fp,fn]: [8978, 72961, 2264, 16370]

TRAIN, epoch 12, loss 0.5351481018036627, acc 0.7489435697991847,recall 0.4530885780885781,precision 0.73374227865477,specificity 0.9103190198231521,[tp,tn,fp,fn]: [34210, 126010, 12414, 41294]
VAL, loss 0.43106087273798865, acc 0.8149901066886739,f1 0.4936457397882821, recall 0.3578191573299669,precision 0.7956838319150803,specificity 0.9690395480225988,[tp,tn,fp,fn]: [9070, 72896, 2329, 16278]

TRAIN, epoch 13, loss 0.5343114825194831, acc 0.7497008339254329,recall 0.45772409408773046,precision 0.7327933505788559,specificity 0.9089608738369069,[tp,tn,fp,fn]: [34560, 125822, 12602, 40944]
VAL, loss 0.43096083090855025, acc 0.8116293637457369,f1 0.4733842946490618, recall 0.3359239387722897,precision 0.8012609391173426,specificity 0.9719242273180458,[tp,tn,fp,fn]: [8515, 73113, 2112, 16833]

TRAIN, epoch 14, loss 0.5324587339167507, acc 0.7502197000860102,recall 0.45843928798474254,precision 0.7339850293687313,specificity 0.9093726521412472,[tp,tn,fp,fn]: [34614, 125879, 12545, 40890]
VAL, loss 0.4289078410173071, acc 0.8125640082328259,f1 0.47409680569117035, recall 0.3352138235758245,precision 0.8094693722015814,specificity 0.9734130940511798,[tp,tn,fp,fn]: [8497, 73225, 2000, 16851]

TRAIN, epoch 15, loss 0.533270038285139, acc 0.7493595976216297,recall 0.4572208094935368,precision 0.7320341822345682,specificity 0.9087080275096804,[tp,tn,fp,fn]: [34522, 125787, 12637, 40982]
VAL, loss 0.43029402462559274, acc 0.8166505921072256,f1 0.5024284943335132, recall 0.3672873599495029,precision 0.7949112021857924,specificity 0.9680691259554669,[tp,tn,fp,fn]: [9310, 72823, 2402, 16038]

TRAIN, epoch 16, loss 0.5334471302836056, acc 0.7499906510601698,recall 0.45620099597372327,precision 0.7349050565393642,specificity 0.9102395538345952,[tp,tn,fp,fn]: [34445, 125999, 12425, 41059]
VAL, loss 0.4240543373416477, acc 0.813349507323039,f1 0.4801152099257782, recall 0.34195991794224395,precision 0.8055762081784387,specificity 0.9721900963775341,[tp,tn,fp,fn]: [8668, 73133, 2092, 16680]

TRAIN, epoch 17, loss 0.5322669597981974, acc 0.7508928237537863,recall 0.4600948294130112,precision 0.7349836030889665,specificity 0.9095099115760272,[tp,tn,fp,fn]: [34739, 125898, 12526, 40765]
VAL, loss 0.426578494434809, acc 0.8148509043182564,f1 0.49138237141842617, recall 0.35486034401136185,precision 0.7986326911124922,specificity 0.9698504486540379,[tp,tn,fp,fn]: [8995, 72957, 2268, 16353]

TRAIN, epoch 18, loss 0.5326442639444614, acc 0.7509021726936166,recall 0.46116762025852936,precision 0.7342119135477069,specificity 0.9089392012945732,[tp,tn,fp,fn]: [34820, 125819, 12605, 40684]
VAL, loss 0.4419010442577443, acc 0.8089646326548875,f1 0.45635381002235365, recall 0.31813160801641155,precision 0.8069648754127889,specificity 0.9743569292123629,[tp,tn,fp,fn]: [8064, 73296, 1929, 17284]

TRAIN, epoch 19, loss 0.5326042572783575, acc 0.7501355596275382,recall 0.4592074592074592,precision 0.7331317531135686,specificity 0.9088236144021268,[tp,tn,fp,fn]: [34672, 125803, 12621, 40832]
VAL, loss 0.4328200727826829, acc 0.8111620415021924,f1 0.4692600044712722, recall 0.3312292883067698,precision 0.8045228056726715,specificity 0.9728813559322034,[tp,tn,fp,fn]: [8396, 73185, 2040, 16952]

TRAIN, epoch 20, loss 0.5313863874591773, acc 0.7507759620059086,recall 0.46181659249841067,precision 0.7333123028391167,specificity 0.9083901635554528,[tp,tn,fp,fn]: [34869, 125743, 12681, 40635]
VAL, loss 0.4355839820398288, acc 0.8107742634703151,f1 0.4658864471948584, recall 0.32744200725895534,precision 0.8071574443255859,specificity 0.9736390827517447,[tp,tn,fp,fn]: [8300, 73242, 1983, 17048]

TRAIN, epoch 21, loss 0.5317927600023148, acc 0.7510844770203059,recall 0.46332644628099173,precision 0.7332117706237424,specificity 0.9080434028781136,[tp,tn,fp,fn]: [34983, 125695, 12729, 40521]
VAL, loss 0.42393516969891115, acc 0.8152386823501337,f1 0.4937888198757764, recall 0.3575430014202304,precision 0.7977992957746479,specificity 0.96946493851778,[tp,tn,fp,fn]: [9063, 72928, 2297, 16285]

TRAIN, epoch 22, loss 0.5309702333839262, acc 0.7514677835533451,recall 0.46495549904640815,precision 0.7332692789706743,specificity 0.9077472114662197,[tp,tn,fp,fn]: [35106, 125654, 12770, 40398]
VAL, loss 0.4249500272923515, acc 0.8139262028576258,f1 0.4850586098728743, recall 0.34771974120246174,precision 0.8017100236492632,specificity 0.9710202725157859,[tp,tn,fp,fn]: [8814, 73045, 2180, 16534]

TRAIN, epoch 23, loss 0.5323454897825258, acc 0.7506544257881156,recall 0.4606775799957618,precision 0.7337566450088601,specificity 0.9088236144021268,[tp,tn,fp,fn]: [34783, 125803, 12621, 40721]
VAL, loss 0.43204751385711687, acc 0.8138665446988754,f1 0.48551640740944313, recall 0.348469307243175,precision 0.8002355499184635,specificity 0.9706879361914257,[tp,tn,fp,fn]: [8833, 73020, 2205, 16515]

TRAIN, epoch 24, loss 0.5322725022411093, acc 0.7514490856736846,recall 0.4640946175037084,precision 0.7338429319371728,specificity 0.9081878864936717,[tp,tn,fp,fn]: [35041, 125715, 12709, 40463]
VAL, loss 0.43307914281267634, acc 0.814413411154087,f1 0.48847597906218304, recall 0.3515859239387723,precision 0.7999281931603985,specificity 0.9703688933200398,[tp,tn,fp,fn]: [8912, 72996, 2229, 16436]

TRAIN, epoch 25, loss 0.530404234389655, acc 0.7524821435249243,recall 0.46516740834922654,precision 0.7364492252206916,specificity 0.9091992718025775,[tp,tn,fp,fn]: [35122, 125855, 12569, 40382]
VAL, loss 0.42931111532917976, acc 0.8116194207192785,f1 0.47269691065961594, recall 0.3350165693545842,precision 0.8024948024948025,specificity 0.9722166832834829,[tp,tn,fp,fn]: [8492, 73135, 2090, 16856]

TRAIN, epoch 26, loss 0.5309989354009158, acc 0.7510003365618338,recall 0.46196228014409835,precision 0.7339449541284404,specificity 0.908657458244235,[tp,tn,fp,fn]: [34880, 125780, 12644, 40624]
VAL, loss 0.4299568300239731, acc 0.8114106171636523,f1 0.4697067128917717, recall 0.331387091683762,precision 0.806219406852865,specificity 0.973160518444666,[tp,tn,fp,fn]: [8400, 73206, 2019, 16948]

TRAIN, epoch 27, loss 0.5315256571008301, acc 0.751551924011817,recall 0.46326022462386096,precision 0.7348010587790429,specificity 0.9088019418597931,[tp,tn,fp,fn]: [34978, 125800, 12624, 40526]
VAL, loss 0.4302774293426219, acc 0.8113310729519851,f1 0.47031236914831254, recall 0.33233391194571565,precision 0.804200477326969,specificity 0.9727351279494849,[tp,tn,fp,fn]: [8424, 73174, 2051, 16924]

TRAIN, epoch 28, loss 0.5311982096888749, acc 0.7510190344414943,recall 0.46290262767535495,precision 0.733309554781587,specificity 0.9081734381321158,[tp,tn,fp,fn]: [34951, 125713, 12711, 40553]
VAL, loss 0.42453124043059587, acc 0.8136875702226244,f1 0.4857284004830388, recall 0.34910052075114406,precision 0.7980699855699855,specificity 0.9702359587902958,[tp,tn,fp,fn]: [8849, 72986, 2239, 16499]

TRAIN, epoch 29, loss 0.5303201734972876, acc 0.7521736285105269,recall 0.46658455181182457,precision 0.7343811886348002,specificity 0.907949488528001,[tp,tn,fp,fn]: [35229, 125682, 12742, 40275]
VAL, loss 0.4260568000973246, acc 0.8122955465184493,f1 0.4744724681253828, recall 0.3362000946820262,precision 0.805939095895593,specificity 0.9727218344965105,[tp,tn,fp,fn]: [8522, 73173, 2052, 16826]

TRAIN, epoch 30, loss 0.5301779005893135, acc 0.752178302980442,recall 0.46552500529773255,precision 0.7351809244927839,specificity 0.9085346471710108,[tp,tn,fp,fn]: [35149, 125763, 12661, 40355]
VAL, loss 0.4262903730648448, acc 0.8125838942857427,f1 0.4772153654139508, recall 0.3393956130661196,precision 0.8034930419351826,specificity 0.9720305749418412,[tp,tn,fp,fn]: [8603, 73121, 2104, 16745]

TRAIN, epoch 31, loss 0.5297538864844837, acc 0.7514724580232601,recall 0.46602828989192624,precision 0.7324978662281159,specificity 0.9071692770039878,[tp,tn,fp,fn]: [35187, 125574, 12850, 40317]
VAL, loss 0.42998830733648874, acc 0.819136348721824,f1 0.5193425642109715, recall 0.38768344642575353,precision 0.7864116517285531,specificity 0.9645197740112994,[tp,tn,fp,fn]: [9827, 72556, 2669, 15521]

TRAIN, epoch 32, loss 0.5309379196533434, acc 0.751173291948693,recall 0.46458465776647595,precision 0.7325773238936575,specificity 0.9074943651389933,[tp,tn,fp,fn]: [35078, 125619, 12805, 40426]
VAL, loss 0.42452585707552865, acc 0.81352848179929,f1 0.48247695788950823, recall 0.34487928041660093,precision 0.8027548209366391,specificity 0.9714456630109671,[tp,tn,fp,fn]: [8742, 73077, 2148, 16606]

TRAIN, epoch 33, loss 0.5302586074025392, acc 0.751799670917318,recall 0.46597531256622166,precision 0.733605788277487,specificity 0.9077038663815523,[tp,tn,fp,fn]: [35183, 125648, 12776, 40321]
VAL, loss 0.4267667535572701, acc 0.813021387449912,f1 0.4775082659553778, recall 0.33900110462363897,precision 0.8073851357699897,specificity 0.9727484214024593,[tp,tn,fp,fn]: [8593, 73175, 2050, 16755]

TRAIN, epoch 34, loss 0.5301127093537111, acc 0.7521128604016305,recall 0.46744543335452426,precision 0.7335494866359064,specificity 0.9073860024273247,[tp,tn,fp,fn]: [35294, 125604, 12820, 40210]
VAL, loss 0.42619656682101587, acc 0.8131307607409544,f1 0.48025442477876107, recall 0.34255168060596497,precision 0.8030891601923789,specificity 0.9716982386174808,[tp,tn,fp,fn]: [8683, 73096, 2129, 16665]

TRAIN, epoch 35, loss 0.5303897440315367, acc 0.7509068471635316,recall 0.46343240093240096,precision 0.7325503496210694,specificity 0.9077110905623302,[tp,tn,fp,fn]: [34991, 125649, 12775, 40513]
VAL, loss 0.4225739139788349, acc 0.8166406490807672,f1 0.5002032685584193, recall 0.3640523907211614,precision 0.7990302190665859,specificity 0.9691458956463942,[tp,tn,fp,fn]: [9228, 72904, 2321, 16120]

TRAIN, epoch 36, loss 0.5298719939395692, acc 0.7526550989117834,recall 0.4661607332061877,precision 0.7362772989707974,specificity 0.9089247529330174,[tp,tn,fp,fn]: [35197, 125817, 12607, 40307]
VAL, loss 0.41849948004971643, acc 0.8171875155359788,f1 0.5043937678581056, recall 0.369102098784914,precision 0.7962553191489362,specificity 0.9681754735792623,[tp,tn,fp,fn]: [9356, 72831, 2394, 15992]

TRAIN, epoch 37, loss 0.5299600772170968, acc 0.7518978347855353,recall 0.4644919474464929,precision 0.7350253594332901,specificity 0.908664682425013,[tp,tn,fp,fn]: [35071, 125781, 12643, 40433]
VAL, loss 0.43366387028679715, acc 0.8091833792369721,f1 0.4563610096031274, recall 0.3177765504181789,precision 0.8093037275193409,specificity 0.9747690262545696,[tp,tn,fp,fn]: [8055, 73327, 1898, 17293]

TRAIN, epoch 38, loss 0.5296905797005128, acc 0.7529776373359262,recall 0.46678321678321677,precision 0.7368751176064731,specificity 0.9090836849101311,[tp,tn,fp,fn]: [35244, 125839, 12585, 40260]
VAL, loss 0.42368514761627246, acc 0.8154872580115936,f1 0.4932135346969987, recall 0.35624112356004417,precision 0.8013133374744875,specificity 0.9702359587902958,[tp,tn,fp,fn]: [9030, 72986, 2239, 16318]

TRAIN, epoch 39, loss 0.5302819937321578, acc 0.7523465838973861,recall 0.46597531256622166,precision 0.7353998578654739,specificity 0.9085490955325666,[tp,tn,fp,fn]: [35183, 125765, 12659, 40321]
VAL, loss 0.4265968463291504, acc 0.814741531027214,f1 0.4890863222551277, recall 0.3518226290042607,precision 0.801978417266187,specificity 0.9707278165503489,[tp,tn,fp,fn]: [8918, 73023, 2202, 16430]

TRAIN, epoch 40, loss 0.5302718636863969, acc 0.7525990052728021,recall 0.4662534435261708,precision 0.7360234162659419,specificity 0.9087874934982373,[tp,tn,fp,fn]: [35204, 125798, 12626, 40300]
VAL, loss 0.42355764665689444, acc 0.8152187962972169,f1 0.49201836868576426, recall 0.3550575982326022,precision 0.8009967960128159,specificity 0.970275839149219,[tp,tn,fp,fn]: [9000, 72989, 2236, 16348]

TRAIN, epoch 41, loss 0.5290449201650571, acc 0.7531038480236342,recall 0.46831955922865015,precision 0.7361452304617563,specificity 0.9084407328208981,[tp,tn,fp,fn]: [35360, 125750, 12674, 40144]
VAL, loss 0.4267526537783858, acc 0.8133992224553309,f1 0.48201816124313435, recall 0.34448477197412025,precision 0.802352292566388,specificity 0.9714057826520439,[tp,tn,fp,fn]: [8732, 73074, 2151, 16616]

TRAIN, epoch 42, loss 0.5293520607987889, acc 0.7525616095134812,recall 0.46847849120576396,precision 0.7342549923195084,specificity 0.9075160376813269,[tp,tn,fp,fn]: [35372, 125622, 12802, 40132]
VAL, loss 0.42206569937869937, acc 0.8150398218209659,f1 0.49071893993319826, recall 0.35355846615117564,precision 0.8017534442655215,specificity 0.9705417082087072,[tp,tn,fp,fn]: [8962, 73009, 2216, 16386]

TRAIN, epoch 43, loss 0.5297482329902793, acc 0.7522250476795931,recall 0.46763085399449034,precision 0.7337794588303753,specificity 0.9074582442351037,[tp,tn,fp,fn]: [35308, 125614, 12810, 40196]
VAL, loss 0.42268014740795096, acc 0.815497201038052,f1 0.4918113600262913, recall 0.3542291305033928,precision 0.8041375604513702,specificity 0.9709272183449651,[tp,tn,fp,fn]: [8979, 73038, 2187, 16369]

TRAIN, epoch 44, loss 0.5293916412017442, acc 0.7530384054448226,recall 0.4683328035600763,precision 0.7359209157127992,specificity 0.9083323701092296,[tp,tn,fp,fn]: [35361, 125735, 12689, 40143]
VAL, loss 0.4232147664655347, acc 0.8150298787945075,f1 0.49245627915859547, recall 0.35604386933880383,precision 0.7983193277310925,specificity 0.9696909272183449,[tp,tn,fp,fn]: [9025, 72945, 2280, 16323]

TRAIN, epoch 45, loss 0.5291135286162346, acc 0.7531085224935492,recall 0.46784276329730873,precision 0.73651508517337,specificity 0.9087080275096804,[tp,tn,fp,fn]: [35324, 125787, 12637, 40180]
VAL, loss 0.42591307402414513, acc 0.8167201932924344,f1 0.5013930590494738, recall 0.3656304244910841,precision 0.7975217279063764,specificity 0.968720505151213,[tp,tn,fp,fn]: [9268, 72872, 2353, 16080]

TRAIN, epoch 46, loss 0.5292191895812349, acc 0.752430724355858,recall 0.46751165501165504,precision 0.7345388713167971,specificity 0.9078411258163325,[tp,tn,fp,fn]: [35299, 125667, 12757, 40205]
VAL, loss 0.429382307617904, acc 0.810595288994064,f1 0.4646299991568534, recall 0.3261006785545211,precision 0.8077787550083064,specificity 0.9738517779993353,[tp,tn,fp,fn]: [8266, 73258, 1967, 17082]

TRAIN, epoch 47, loss 0.5288945118783857, acc 0.7526364010321229,recall 0.46902150879423604,precision 0.7341003316749586,specificity 0.9073354331618795,[tp,tn,fp,fn]: [35413, 125597, 12827, 40091]
VAL, loss 0.424793990930652, acc 0.8132301910055383,f1 0.480272259421172, recall 0.3423938772289727,precision 0.8040578098943858,specificity 0.9718843469591226,[tp,tn,fp,fn]: [8679, 73110, 2115, 16669]

TRAIN, epoch 48, loss 0.528604608081647, acc 0.7531365693130398,recall 0.46960425937698663,precision 0.7353020468260716,specificity 0.9077905565508871,[tp,tn,fp,fn]: [35457, 125660, 12764, 40047]
VAL, loss 0.42226657861131767, acc 0.8154773149851352,f1 0.4934490664919751, recall 0.3565961811582768,precision 0.8007618710134656,specificity 0.9701030242605517,[tp,tn,fp,fn]: [9039, 72976, 2249, 16309]

TRAIN, epoch 49, loss 0.5285622551388054, acc 0.752972962866011,recall 0.4698559016740835,precision 0.7345840062947778,specificity 0.9074004507888805,[tp,tn,fp,fn]: [35476, 125606, 12818, 40028]
VAL, loss 0.4229310939396031, acc 0.8124546349417836,f1 0.4749763402549685, recall 0.33659460312450684,precision 0.8065796937039138,specificity 0.9728015952143569,[tp,tn,fp,fn]: [8532, 73179, 2046, 16816]



 * BEST_ACC: 0.819136348721824
 * TIME: Time 2352.155 (2352.155)

