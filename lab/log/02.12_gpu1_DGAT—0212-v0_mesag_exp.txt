pooling_ratio 0.2, dropout0.5, hidden_dim 128, outdim 256
epochs 50, lr 0.0001, weight_decay 0.001
TRAIN, epoch 0, loss 0.5901538601012037, acc 0.6991324183837553,recall 0.263456240728968,precision 0.6944560815528558,specificity 0.936773969831821,[tp,tn,fp,fn]: [19892, 129672, 8752, 55612]
VAL, loss 0.4467842769995521, acc 0.8056138327384089,f1 0.5050131658902167, recall 0.39344326968597126,precision 0.7049052869663557,specificity 0.9444998338318378,[tp,tn,fp,fn]: [9973, 71050, 4175, 15375]

TRAIN, epoch 1, loss 0.5527214583295484, acc 0.7345789237500467,recall 0.41473299427844884,precision 0.7132217287324906,specificity 0.9090403398254638,[tp,tn,fp,fn]: [31314, 125833, 12591, 44190]
VAL, loss 0.4594931158886491, acc 0.8181221600230678,f1 0.526849456802897, recall 0.4017673978223134,precision 0.7650240384615384,specificity 0.9584180790960452,[tp,tn,fp,fn]: [10184, 72097, 3128, 15164]

TRAIN, epoch 2, loss 0.546963559106081, acc 0.7414316966456004,recall 0.4244278448823903,precision 0.7299273398173246,specificity 0.9143428885164422,[tp,tn,fp,fn]: [32046, 126567, 11857, 43458]
VAL, loss 0.43607756457057195, acc 0.8122856034919909,f1 0.4836300976450317, recall 0.34878491399715955,precision 0.7884598234192455,specificity 0.9684679295446993,[tp,tn,fp,fn]: [8841, 72853, 2372, 16507]

TRAIN, epoch 3, loss 0.5431144934648138, acc 0.744012004038742,recall 0.4323082220809494,precision 0.7328304258997328,specificity 0.9140322487429925,[tp,tn,fp,fn]: [32641, 126524, 11900, 42863]
VAL, loss 0.43762275529868405, acc 0.8112316426874012,f1 0.47236041243989885, recall 0.3352532744200726,precision 0.7992100065832785,specificity 0.9716184778996344,[tp,tn,fp,fn]: [8498, 73090, 2135, 16850]

TRAIN, epoch 4, loss 0.540403254845884, acc 0.7459145132941924,recall 0.4398442466624285,precision 0.733566001060258,specificity 0.9128619314569728,[tp,tn,fp,fn]: [33210, 126362, 12062, 42294]
VAL, loss 0.43530758714994866, acc 0.8145227844451294,f1 0.4952922077922078, recall 0.36109357740255643,precision 0.788236307268343,specificity 0.9673113991359256,[tp,tn,fp,fn]: [9153, 72766, 2459, 16195]

TRAIN, epoch 5, loss 0.5381334738502961, acc 0.7476767884521895,recall 0.44242689129052765,precision 0.7376614773103677,specificity 0.9141767323585506,[tp,tn,fp,fn]: [33405, 126544, 11880, 42099]
VAL, loss 0.43277059777854465, acc 0.8141946645720024,f1 0.49047034764826175, recall 0.3548208931671138,precision 0.7940319590359318,specificity 0.9689863742107012,[tp,tn,fp,fn]: [8994, 72892, 2333, 16354]

TRAIN, epoch 6, loss 0.5376960908478143, acc 0.7477702778504918,recall 0.4458041958041958,precision 0.7353358820316767,specificity 0.9124790498757441,[tp,tn,fp,fn]: [33660, 126309, 12115, 41844]
VAL, loss 0.4228419243972182, acc 0.8180326727849423,f1 0.5096589234520269, recall 0.37521697964336437,precision 0.7942379958246346,specificity 0.9672449318710535,[tp,tn,fp,fn]: [9511, 72761, 2464, 15837]

TRAIN, epoch 7, loss 0.5380624971760313, acc 0.7476253692831233,recall 0.4439897223988133,precision 0.7362514275674251,specificity 0.9132448130382015,[tp,tn,fp,fn]: [33523, 126415, 12009, 41981]
VAL, loss 0.429985247359413, acc 0.8129915583705368,f1 0.48201597356100245, recall 0.3452343380148335,precision 0.7983032293377121,specificity 0.9706081754735792,[tp,tn,fp,fn]: [8751, 73014, 2211, 16597]

TRAIN, epoch 8, loss 0.5369158278968089, acc 0.7471859691111028,recall 0.44703591862682773,precision 0.7323916156750423,specificity 0.9109041784661619,[tp,tn,fp,fn]: [33753, 126091, 12333, 41751]
VAL, loss 0.4304210345212359, acc 0.8133296212701222,f1 0.48266740148801324, recall 0.34551049392457,precision 0.8004021202705173,specificity 0.9709670987038883,[tp,tn,fp,fn]: [8758, 73041, 2184, 16590]

TRAIN, epoch 9, loss 0.5355198416241908, acc 0.7491539209453648,recall 0.45059864378046194,precision 0.7363591108802459,specificity 0.9120022539444027,[tp,tn,fp,fn]: [34022, 126243, 12181, 41482]
VAL, loss 0.42620719002704, acc 0.8161434977578476,f1 0.4997429862294728, recall 0.364367997475146,precision 0.7951786482996126,specificity 0.9683748753738783,[tp,tn,fp,fn]: [9236, 72846, 2379, 16112]

TRAIN, epoch 10, loss 0.5343306746957529, acc 0.7490417336674021,recall 0.45360510701419793,precision 0.7336817977335532,specificity 0.9101889845691499,[tp,tn,fp,fn]: [34249, 125992, 12432, 41255]
VAL, loss 0.42744136203499383, acc 0.8169985980332694,f1 0.5030645030645031, recall 0.3675240650149913,precision 0.7969886217811618,specificity 0.9684546360917248,[tp,tn,fp,fn]: [9316, 72852, 2373, 16032]

TRAIN, epoch 11, loss 0.5343317670025245, acc 0.7495185295987435,recall 0.45417461326552233,precision 0.7348548162434373,specificity 0.910615211235046,[tp,tn,fp,fn]: [34292, 126051, 12373, 41212]
VAL, loss 0.42251099520901436, acc 0.8189076591132809,f1 0.5131385495469005, recall 0.3786492030929462,precision 0.7957880772738579,specificity 0.9672582253240279,[tp,tn,fp,fn]: [9598, 72762, 2463, 15750]

TRAIN, epoch 12, loss 0.5342192655279974, acc 0.7496540892262817,recall 0.45331373172282263,precision 0.7359695523158302,specificity 0.9112942842281685,[tp,tn,fp,fn]: [34227, 126145, 12279, 41277]
VAL, loss 0.42631159491789833, acc 0.8187883427957802,f1 0.5127917234742161, recall 0.37837304718320974,precision 0.7953395803963844,specificity 0.9671917580591559,[tp,tn,fp,fn]: [9591, 72757, 2468, 15757]

TRAIN, epoch 13, loss 0.5336769268583696, acc 0.7504861448711716,recall 0.45691618987073535,precision 0.7360257723160949,specificity 0.910615211235046,[tp,tn,fp,fn]: [34499, 126051, 12373, 41005]
VAL, loss 0.42393714066132165, acc 0.8172968888270211,f1 0.5034991488556838, recall 0.3675635158592394,precision 0.7989880799245348,specificity 0.9688401462279828,[tp,tn,fp,fn]: [9317, 72881, 2344, 16031]

TRAIN, epoch 14, loss 0.5313546067355686, acc 0.7511873153584383,recall 0.45956505615596527,precision 0.7363651797461908,specificity 0.9102540021961509,[tp,tn,fp,fn]: [34699, 126001, 12423, 40805]
VAL, loss 0.422042681149571, acc 0.8186491404253626,f1 0.5095856524427953, recall 0.37383620009468205,precision 0.8001351009034873,specificity 0.9685343968095713,[tp,tn,fp,fn]: [9476, 72858, 2367, 15872]

TRAIN, epoch 15, loss 0.5326036415657873, acc 0.7499065106016978,recall 0.45691618987073535,precision 0.7340837518086646,specificity 0.9097194128185864,[tp,tn,fp,fn]: [34499, 125927, 12497, 41005]
VAL, loss 0.42379807565196914, acc 0.8199317908384954,f1 0.5167831794652863, recall 0.38204197569827997,precision 0.7983511953833471,specificity 0.9674842140245928,[tp,tn,fp,fn]: [9684, 72779, 2446, 15664]

TRAIN, epoch 16, loss 0.5326028260870498, acc 0.7508086832953144,recall 0.45800222504767957,precision 0.7362829220516532,specificity 0.9105212968849332,[tp,tn,fp,fn]: [34581, 126038, 12386, 40923]
VAL, loss 0.4189246692525772, acc 0.8178934704145248,f1 0.5047724630235514, recall 0.36823418021145654,precision 0.8022346368715084,specificity 0.9694117647058823,[tp,tn,fp,fn]: [9334, 72924, 2301, 16014]

TRAIN, epoch 17, loss 0.5315624450213854, acc 0.7513368983957219,recall 0.460161051070142,precision 0.7364137346333192,specificity 0.9101600878460383,[tp,tn,fp,fn]: [34744, 125988, 12436, 40760]
VAL, loss 0.4194411907851439, acc 0.8181718751553598,f1 0.5072881584265122, recall 0.37139024775130186,precision 0.8000339933712926,specificity 0.968720505151213,[tp,tn,fp,fn]: [9414, 72872, 2353, 15934]

TRAIN, epoch 18, loss 0.5320490781497966, acc 0.7509535918626827,recall 0.4597902097902098,precision 0.7354149896199635,specificity 0.9097699820840317,[tp,tn,fp,fn]: [34716, 125934, 12490, 40788]
VAL, loss 0.44538839033439065, acc 0.810973123999483,f1 0.4678814342094214, recall 0.32973015622534324,precision 0.8052798920897967,specificity 0.9731339315387172,[tp,tn,fp,fn]: [8358, 73204, 2021, 16990]

pooling_ratio 0.2, dropout0.5, hidden_dim 128, outdim 256
epochs 50, lr 0.0001, weight_decay 0.001
TRAIN, epoch 0, loss 0.5905461338555945, acc 0.6992726524812086,recall 0.26472769654587835,precision 0.6938832187738666,specificity 0.9362971739004797,[tp,tn,fp,fn]: [19988, 129606, 8818, 55516]
VAL, loss 0.4493458834063905, acc 0.8009604963558808,f1 0.4964785189656907, recall 0.3893403818841723,precision 0.6849666851749028,specificity 0.9396610169491525,[tp,tn,fp,fn]: [9869, 70686, 4539, 15479]

TRAIN, epoch 1, loss 0.553786882826904, acc 0.7332607232339853,recall 0.418467895740623,precision 0.7060400884896427,specificity 0.9049659018667283,[tp,tn,fp,fn]: [31596, 125269, 13155, 43908]
VAL, loss 0.4659731416296281, acc 0.8074234635538365,f1 0.4846743295019157, recall 0.3593182894113934,precision 0.7443609022556391,specificity 0.9584180790960452,[tp,tn,fp,fn]: [9108, 72097, 3128, 16240]

TRAIN, epoch 2, loss 0.5477025378542124, acc 0.7406510601697768,recall 0.4312751642297097,precision 0.7219537069882938,specificity 0.9094015488643588,[tp,tn,fp,fn]: [32563, 125883, 12541, 42941]
VAL, loss 0.44280847810530977, acc 0.8118282242749048,f1 0.48381201756539294, recall 0.3498895376361054,precision 0.7838267786124613,specificity 0.9674842140245928,[tp,tn,fp,fn]: [8869, 72779, 2446, 16479]

TRAIN, epoch 3, loss 0.5431386918205093, acc 0.7440821210874686,recall 0.4385198135198135,precision 0.7282685201478093,specificity 0.910752470669826,[tp,tn,fp,fn]: [33110, 126070, 12354, 42394]
VAL, loss 0.4396758039746399, acc 0.8094717270042655,f1 0.4640899429466384, recall 0.32732365472621117,precision 0.7971752498078402,specificity 0.9719375207710202,[tp,tn,fp,fn]: [8297, 73114, 2111, 17051]

TRAIN, epoch 4, loss 0.5402728477402029, acc 0.7456854642683519,recall 0.44549957618139435,precision 0.7284677855982674,specificity 0.9094232214066925,[tp,tn,fp,fn]: [33637, 125886, 12538, 41867]
VAL, loss 0.43962422042078186, acc 0.8112714147932347,f1 0.4781568746047892, recall 0.3430645415811898,precision 0.7887528344671202,specificity 0.9690395480225988,[tp,tn,fp,fn]: [8696, 72896, 2329, 16652]

TRAIN, epoch 5, loss 0.5381398712022647, acc 0.7467933136382334,recall 0.44706240728968,precision 0.7310391129206913,specificity 0.9102828989192625,[tp,tn,fp,fn]: [33755, 126005, 12419, 41749]
VAL, loss 0.4359493917058449, acc 0.8126634384974099,f1 0.48092128826073777, recall 0.34432696859712797,precision 0.7971504246963192,specificity 0.9704752409438352,[tp,tn,fp,fn]: [8728, 73004, 2221, 16620]

TRAIN, epoch 6, loss 0.5381115065886665, acc 0.7466203582513743,recall 0.45009535918626825,precision 0.7281921618204804,specificity 0.9083612668323412,[tp,tn,fp,fn]: [33984, 125739, 12685, 41520]
VAL, loss 0.430432604246284, acc 0.813299792190747,f1 0.48404913032726066, recall 0.34748303613697334,precision 0.7974649162516976,specificity 0.9702625456962446,[tp,tn,fp,fn]: [8808, 72988, 2237, 16540]

TRAIN, epoch 7, loss 0.5380505582025229, acc 0.746695149770016,recall 0.44858550540368725,precision 0.7295638126009693,specificity 0.9093004103334682,[tp,tn,fp,fn]: [33870, 125869, 12555, 41634]
VAL, loss 0.4397857416265123, acc 0.8084873673848846,f1 0.4539449437246619, recall 0.31584345905002364,precision 0.8066498740554157,specificity 0.974489863742107,[tp,tn,fp,fn]: [8006, 73306, 1919, 17342]

TRAIN, epoch 8, loss 0.5370639705081995, acc 0.7474991585954153,recall 0.45194956558592925,precision 0.7297534270011334,specificity 0.9087080275096804,[tp,tn,fp,fn]: [34124, 125787, 12637, 41380]
VAL, loss 0.43737935814914447, acc 0.8108538076819822,f1 0.4686164418000503, recall 0.3309136815527852,precision 0.8026026217586834,specificity 0.9725756065137919,[tp,tn,fp,fn]: [8388, 73162, 2063, 16960]

TRAIN, epoch 9, loss 0.5356301905242593, acc 0.7486490781945327,recall 0.45295613477431657,precision 0.7328519082006557,specificity 0.9099361382419233,[tp,tn,fp,fn]: [34200, 125957, 12467, 41304]
VAL, loss 0.43306622454350424, acc 0.8102472830680203,f1 0.4655539374929987, recall 0.32791541738993213,precision 0.8023166023166023,specificity 0.9727750083084081,[tp,tn,fp,fn]: [8312, 73177, 2048, 17036]

TRAIN, epoch 10, loss 0.5351307308244561, acc 0.7487986612318163,recall 0.45535335876244964,precision 0.7315573334468157,specificity 0.9088597353060163,[tp,tn,fp,fn]: [34381, 125808, 12616, 41123]
VAL, loss 0.4357990666527714, acc 0.8110029530788582,f1 0.46943560542622675, recall 0.33174214928199464,precision 0.8025386524145829,specificity 0.9724958457959455,[tp,tn,fp,fn]: [8409, 73156, 2069, 16939]

TRAIN, epoch 11, loss 0.534908708363971, acc 0.7492707826932425,recall 0.4556977113795296,precision 0.7328746698474908,specificity 0.9094015488643588,[tp,tn,fp,fn]: [34407, 125883, 12541, 41097]
VAL, loss 0.43240191916553194, acc 0.8138267725930419,f1 0.48588687534321795, recall 0.349061069906896,precision 0.7991329479768786,specificity 0.970435360584912,[tp,tn,fp,fn]: [8848, 73001, 2224, 16500]

TRAIN, epoch 12, loss 0.5351213338638912, acc 0.7490884783665532,recall 0.45473087518542066,precision 0.7329903289852907,specificity 0.9096471710108074,[tp,tn,fp,fn]: [34334, 125917, 12507, 41170]
VAL, loss 0.43039931674900955, acc 0.8160341244668052,f1 0.4973921547321525, recall 0.36117247909105255,precision 0.7985868806699232,specificity 0.9693054170820871,[tp,tn,fp,fn]: [9155, 72916, 2309, 16193]

TRAIN, epoch 13, loss 0.5346150128984767, acc 0.749873789312292,recall 0.4595253231616868,precision 0.7320294533409287,specificity 0.9082456799398948,[tp,tn,fp,fn]: [34696, 125723, 12701, 40808]
VAL, loss 0.428241331429814, acc 0.8141151203603353,f1 0.4866690463768912, recall 0.34961338172636897,precision 0.80046969560112,specificity 0.9706347623795281,[tp,tn,fp,fn]: [8862, 73016, 2209, 16486]

TRAIN, epoch 14, loss 0.5325400980461028, acc 0.7510704536105606,recall 0.46224041110404746,precision 0.7339698429055119,specificity 0.9086141131595677,[tp,tn,fp,fn]: [34901, 125774, 12650, 40603]
VAL, loss 0.4328120668182821, acc 0.8123452616507413,f1 0.47512306365937096, recall 0.3369891115669875,precision 0.805165425582053,specificity 0.9725224327018943,[tp,tn,fp,fn]: [8542, 73158, 2067, 16806]

TRAIN, epoch 15, loss 0.5337609781862656, acc 0.7500701170487267,recall 0.46035971604153425,precision 0.732061245550852,specificity 0.9080939721435589,[tp,tn,fp,fn]: [34759, 125702, 12722, 40745]
VAL, loss 0.4311743593695071, acc 0.8180724448907759,f1 0.5082905592432346, recall 0.37308663405396875,precision 0.7971845233077637,specificity 0.9680159521435693,[tp,tn,fp,fn]: [9457, 72819, 2406, 15891]

TRAIN, epoch 16, loss 0.5335666000506475, acc 0.7505328895703227,recall 0.4608630006357279,precision 0.7332167390113363,specificity 0.9085346471710108,[tp,tn,fp,fn]: [34797, 125763, 12661, 40707]
VAL, loss 0.42522576593945155, acc 0.816382130392849,f1 0.497619630566664, recall 0.3608174214928199,precision 0.8015073175006573,specificity 0.9698903290129611,[tp,tn,fp,fn]: [9146, 72960, 2265, 16202]

TRAIN, epoch 17, loss 0.5324159319541836, acc 0.7508460790546352,recall 0.46282316168679805,precision 0.7327992954054564,specificity 0.907949488528001,[tp,tn,fp,fn]: [34945, 125682, 12742, 40559]
VAL, loss 0.4254616402646613, acc 0.8182613623934853,f1 0.5091045818338078, recall 0.37391510178317816,precision 0.7974087161366313,specificity 0.9679893652376205,[tp,tn,fp,fn]: [9478, 72817, 2408, 15870]

TRAIN, epoch 18, loss 0.5330167046829354, acc 0.750458098051681,recall 0.4633794236066963,precision 0.731119655619175,specificity 0.9070464659307634,[tp,tn,fp,fn]: [34987, 125557, 12867, 40517]
VAL, loss 0.43569691425630475, acc 0.8118182812484463,f1 0.4734587135544179, recall 0.3356872337068013,precision 0.8030388825972065,specificity 0.9722565636424061,[tp,tn,fp,fn]: [8509, 73138, 2087, 16839]

TRAIN, epoch 19, loss 0.5331411541482326, acc 0.7500607681088964,recall 0.46218743377834287,precision 0.7306895035490693,specificity 0.9070825868346529,[tp,tn,fp,fn]: [34897, 125562, 12862, 40607]
VAL, loss 0.4281712287236253, acc 0.8163423582870154,f1 0.49794786768503163, recall 0.3613697333122929,precision 0.8004893821550293,specificity 0.9696510468594217,[tp,tn,fp,fn]: [9160, 72942, 2283, 16188]

TRAIN, epoch 20, loss 0.5313479553221729, acc 0.7514163643842788,recall 0.4658031362576817,precision 0.7324794335103614,specificity 0.9072053979078772,[tp,tn,fp,fn]: [35170, 125579, 12845, 40334]
VAL, loss 0.4305717812694074, acc 0.8138267725930419,f1 0.48135837349731314, recall 0.34278838567145337,precision 0.8079784266319509,specificity 0.9725490196078431,[tp,tn,fp,fn]: [8689, 73160, 2065, 16659]

TRAIN, epoch 21, loss 0.5319565159947919, acc 0.7509395684529374,recall 0.46568393727484636,precision 0.7310131187758582,specificity 0.9065335490955325,[tp,tn,fp,fn]: [35161, 125486, 12938, 40343]
VAL, loss 0.42238900331292506, acc 0.8163523013134738,f1 0.497196058147765, recall 0.360265109673347,precision 0.802037590022835,specificity 0.9700365569956796,[tp,tn,fp,fn]: [9132, 72971, 2254, 16216]

TRAIN, epoch 22, loss 0.5314579198780468, acc 0.751551924011817,recall 0.46634615384615385,precision 0.732524756594824,specificity 0.9071187077385424,[tp,tn,fp,fn]: [35211, 125567, 12857, 40293]
VAL, loss 0.42378690704978467, acc 0.8162727571018067,f1 0.49727935575144194, recall 0.36054126558308347,precision 0.8011044880785414,specificity 0.9698371552010635,[tp,tn,fp,fn]: [9139, 72956, 2269, 16209]

TRAIN, epoch 23, loss 0.5324591090129863, acc 0.7503646086533787,recall 0.4632337359610087,precision 0.7309203377079327,specificity 0.9069814483037624,[tp,tn,fp,fn]: [34976, 125548, 12876, 40528]
VAL, loss 0.4357458928156632, acc 0.8172372306682708,f1 0.504461758283234, recall 0.369102098784914,precision 0.7965942954448701,specificity 0.9682419408441343,[tp,tn,fp,fn]: [9356, 72836, 2389, 15992]

TRAIN, epoch 24, loss 0.5325703743414338, acc 0.7508647769342957,recall 0.46416083916083917,precision 0.7318784588075598,specificity 0.9072487429925447,[tp,tn,fp,fn]: [35046, 125585, 12839, 40458]
VAL, loss 0.43233568480800466, acc 0.8189474312191145,f1 0.5135575561670184, recall 0.3792015149124191,precision 0.7953661563922217,specificity 0.9671252907942838,[tp,tn,fp,fn]: [9612, 72752, 2473, 15736]

TRAIN, epoch 25, loss 0.5311251148909719, acc 0.7515425750719869,recall 0.4648098114007205,precision 0.733621806931728,specificity 0.907942264347223,[tp,tn,fp,fn]: [35095, 125681, 12743, 40409]
VAL, loss 0.4253902996346499, acc 0.8159446372286797,f1 0.49515913491695523, recall 0.3581347640839514,precision 0.8020143122183938,specificity 0.970209371884347,[tp,tn,fp,fn]: [9078, 72984, 2241, 16270]

TRAIN, epoch 26, loss 0.5314364264790271, acc 0.7505749597995587,recall 0.4624920534011443,precision 0.7321522172135444,specificity 0.9077110905623302,[tp,tn,fp,fn]: [34920, 125649, 12775, 40584]
VAL, loss 0.4233472947610094, acc 0.8143338669424199,f1 0.4850390226414053, recall 0.3469307243175004,precision 0.8058279116649867,specificity 0.971831173147225,[tp,tn,fp,fn]: [8794, 73106, 2119, 16554]

TRAIN, epoch 27, loss 0.5319364099913405, acc 0.750836730114805,recall 0.4635913329095147,precision 0.7322037443782031,specificity 0.9075160376813269,[tp,tn,fp,fn]: [35003, 125622, 12802, 40501]
VAL, loss 0.4259272300146016, acc 0.8145824426038798,f1 0.4865638766519824, recall 0.3485876597759192,precision 0.8053226394458622,specificity 0.97160518444666,[tp,tn,fp,fn]: [8836, 73089, 2136, 16512]

TRAIN, epoch 28, loss 0.5317674898262277, acc 0.751257432407165,recall 0.46545878364060184,precision 0.7322124299435382,specificity 0.9071476044616541,[tp,tn,fp,fn]: [35144, 125571, 12853, 40360]
VAL, loss 0.42310666639798994, acc 0.8150000497151323,f1 0.49024657534246574, recall 0.3529667034874546,precision 0.8022776183644189,specificity 0.9706879361914257,[tp,tn,fp,fn]: [8947, 73020, 2205, 16401]

TRAIN, epoch 29, loss 0.5308137266991013, acc 0.7522717923787442,recall 0.46773680864589956,precision 0.7338542099576095,specificity 0.9074726925966595,[tp,tn,fp,fn]: [35316, 125616, 12808, 40188]
VAL, loss 0.4232505337726939, acc 0.816889224742227,f1 0.501488820312923, recall 0.3654331702698438,precision 0.7989477315853027,specificity 0.96901296111665,[tp,tn,fp,fn]: [9263, 72894, 2331, 16085]

TRAIN, epoch 30, loss 0.5305319270566604, acc 0.7520848135821397,recall 0.46647859716041534,precision 0.7341685079418018,specificity 0.907870022539444,[tp,tn,fp,fn]: [35221, 125671, 12753, 40283]
VAL, loss 0.4246417980482926, acc 0.8163224722340986,f1 0.49647013928639566, recall 0.3592788385671453,precision 0.8031572449069583,specificity 0.9703290129611166,[tp,tn,fp,fn]: [9107, 72993, 2232, 16241]

TRAIN, epoch 31, loss 0.5305039101788023, acc 0.7513742941550429,recall 0.46592233524051707,precision 0.7322551101119853,specificity 0.907075362653875,[tp,tn,fp,fn]: [35179, 125561, 12863, 40325]
VAL, loss 0.42285248807571624, acc 0.820249967685164,f1 0.5196364989105596, recall 0.38575035505759825,precision 0.7958652124369201,specificity 0.9666600199401795,[tp,tn,fp,fn]: [9778, 72717, 2508, 15570]

TRAIN, epoch 32, loss 0.5313277113438098, acc 0.7509442429228526,recall 0.4651806526806527,precision 0.7313939444421307,specificity 0.9068152921458706,[tp,tn,fp,fn]: [35123, 125525, 12899, 40381]
VAL, loss 0.4215262221073387, acc 0.8167997375041015,f1 0.49922539613513434, recall 0.36231655357424647,precision 0.8024464831804281,specificity 0.9699435028248587,[tp,tn,fp,fn]: [9184, 72964, 2261, 16164]

TRAIN, epoch 33, loss 0.5308925437368223, acc 0.7514818069630904,recall 0.4661474888747616,precision 0.7324412627723556,specificity 0.9071187077385424,[tp,tn,fp,fn]: [35196, 125567, 12857, 40308]
VAL, loss 0.42585478590754744, acc 0.8161335547313892,f1 0.4944225721784776, recall 0.35671453369102096,precision 0.8053081581759886,specificity 0.9709405117979395,[tp,tn,fp,fn]: [9042, 73039, 2186, 16306]

TRAIN, epoch 34, loss 0.5304182245332726, acc 0.7518978347855353,recall 0.46752489934308117,precision 0.7327908328489579,specificity 0.9070103450268739,[tp,tn,fp,fn]: [35300, 125552, 12872, 40204]
VAL, loss 0.42184956623431047, acc 0.8155866882761775,f1 0.49320982594201707, recall 0.35604386933880383,precision 0.802293537203307,specificity 0.970435360584912,[tp,tn,fp,fn]: [9025, 73001, 2224, 16323]

TRAIN, epoch 35, loss 0.5308670422714876, acc 0.7508040088253992,recall 0.46500847637211273,precision 0.7310623412318328,specificity 0.9066924810726463,[tp,tn,fp,fn]: [35110, 125508, 12916, 40394]
VAL, loss 0.4230460626143031, acc 0.8173466039593131,f1 0.5013030730806819, recall 0.36424964494240175,precision 0.803708217270195,specificity 0.9700232635427052,[tp,tn,fp,fn]: [9233, 72970, 2255, 16115]

TRAIN, epoch 36, loss 0.5303261416371922, acc 0.7524026775363674,recall 0.46635939817758,precision 0.7352990310725025,specificity 0.9084262844593423,[tp,tn,fp,fn]: [35212, 125748, 12676, 40292]
VAL, loss 0.4236910922844642, acc 0.8195340697801596,f1 0.5168246193163668, recall 0.3829493451159855,precision 0.7946136214800262,specificity 0.9666467264872051,[tp,tn,fp,fn]: [9707, 72716, 2509, 15641]

TRAIN, epoch 37, loss 0.5306037898064284, acc 0.7516126921207135,recall 0.46618722186904005,precision 0.7328392080114926,specificity 0.90729931225799,[tp,tn,fp,fn]: [35199, 125592, 12832, 40305]
VAL, loss 0.42479668377366997, acc 0.8140654052280433,f1 0.4824532270563489, recall 0.3438535584661512,precision 0.8082344213649851,specificity 0.9725091392489199,[tp,tn,fp,fn]: [8716, 73157, 2068, 16632]

TRAIN, epoch 38, loss 0.5301311034092768, acc 0.752678471261359,recall 0.46802818393727486,precision 0.7349680747072648,specificity 0.907942264347223,[tp,tn,fp,fn]: [35338, 125681, 12743, 40166]
VAL, loss 0.42263466770355795, acc 0.8169289968480606,f1 0.500027154727638, recall 0.36322392299195205,precision 0.8021432305279665,specificity 0.9698105682951147,[tp,tn,fp,fn]: [9207, 72954, 2271, 16141]

TRAIN, epoch 39, loss 0.5308450795914873, acc 0.7517669496279122,recall 0.46700837041746135,precision 0.7327417813058477,specificity 0.9070898110154308,[tp,tn,fp,fn]: [35261, 125563, 12861, 40243]
VAL, loss 0.4222273963538441, acc 0.8166207630278505,f1 0.5003115771221112, recall 0.36424964494240175,precision 0.7986333362165903,specificity 0.9690528414755732,[tp,tn,fp,fn]: [9233, 72897, 2328, 16115]

TRAIN, epoch 40, loss 0.5307481907769775, acc 0.7524774690550091,recall 0.46866391184573003,precision 0.7338448776441311,specificity 0.9072848638964341,[tp,tn,fp,fn]: [35386, 125590, 12834, 40118]
VAL, loss 0.4200703766351685, acc 0.8173068318534795,f1 0.5039148982126465, recall 0.36815527852296037,precision 0.7982891360136869,specificity 0.968654037886341,[tp,tn,fp,fn]: [9332, 72867, 2358, 16016]

TRAIN, epoch 41, loss 0.5293738375979342, acc 0.752972962866011,recall 0.46947181606272514,precision 0.7348660751306079,specificity 0.9076099520314397,[tp,tn,fp,fn]: [35447, 125635, 12789, 40057]
VAL, loss 0.4278109253072022, acc 0.8154773149851352,f1 0.4918679152291769, recall 0.354347483036137,precision 0.8038303203866117,specificity 0.9708607510800931,[tp,tn,fp,fn]: [8982, 73033, 2192, 16366]

TRAIN, epoch 42, loss 0.5299598009763938, acc 0.7524587711753488,recall 0.46989563466836193,precision 0.732885767403429,specificity 0.9065841183609779,[tp,tn,fp,fn]: [35479, 125493, 12931, 40025]
VAL, loss 0.42190529222571277, acc 0.8169091107951438,f1 0.5014079930683418, recall 0.3652753668928515,precision 0.7992921270718232,specificity 0.9690927218344965,[tp,tn,fp,fn]: [9259, 72900, 2325, 16089]

TRAIN, epoch 43, loss 0.5303540229596757, acc 0.7519773007740922,recall 0.46808116126297944,precision 0.7326437115197247,specificity 0.9068297405074265,[tp,tn,fp,fn]: [35342, 125527, 12897, 40162]
VAL, loss 0.4211770726112195, acc 0.8166307060543088,f1 0.4981768707482993, recall 0.3611330282468045,precision 0.8028416067356604,specificity 0.9701163177135261,[tp,tn,fp,fn]: [9154, 72977, 2248, 16194]

TRAIN, epoch 44, loss 0.5297899580214473, acc 0.7527532627800008,recall 0.4693791057427421,precision 0.7342186496509147,specificity 0.9073209848003236,[tp,tn,fp,fn]: [35440, 125595, 12829, 40064]
VAL, loss 0.42334773026190226, acc 0.8158352639376374,f1 0.49564317612460507, recall 0.3590421335016569,precision 0.8000175808720112,specificity 0.969757394483217,[tp,tn,fp,fn]: [9101, 72950, 2275, 16247]

TRAIN, epoch 45, loss 0.5297139189778802, acc 0.7530524288545679,recall 0.4688493324856961,precision 0.7355844155844156,specificity 0.9080722996012253,[tp,tn,fp,fn]: [35400, 125699, 12725, 40104]
VAL, loss 0.424151862777549, acc 0.820428942161415,f1 0.5239099488585439, recall 0.3920230392930409,precision 0.7895280470363897,specificity 0.9647856430707876,[tp,tn,fp,fn]: [9937, 72576, 2649, 15411]

TRAIN, epoch 46, loss 0.5297344115310829, acc 0.7522343966194234,recall 0.46698188175460903,precision 0.7342871423216294,specificity 0.9078266774547766,[tp,tn,fp,fn]: [35259, 125665, 12759, 40245]
VAL, loss 0.42472817553788167, acc 0.8135881399580405,f1 0.4811822005756032, recall 0.3429856398926937,precision 0.8058954393770856,specificity 0.9721635094715853,[tp,tn,fp,fn]: [8694, 73131, 2094, 16654]

TRAIN, epoch 47, loss 0.5294404153531235, acc 0.7528140308888972,recall 0.4690877304513668,precision 0.7346303824773915,specificity 0.9075738311275502,[tp,tn,fp,fn]: [35418, 125630, 12794, 40086]
VAL, loss 0.4228847314541982, acc 0.8180823879172342,f1 0.5096483704974271, recall 0.37509862711062014,precision 0.7947174857907054,specificity 0.9673512794948488,[tp,tn,fp,fn]: [9508, 72769, 2456, 15840]

TRAIN, epoch 48, loss 0.5293988608062626, acc 0.7522577689689989,recall 0.4694453273998729,precision 0.7325617443422549,specificity 0.9065191007339768,[tp,tn,fp,fn]: [35445, 125484, 12940, 40059]
VAL, loss 0.42074979285506586, acc 0.8171974585624372,f1 0.504113283884019, recall 0.3686681394981853,precision 0.7968789971859811,specificity 0.9683349950149551,[tp,tn,fp,fn]: [9345, 72843, 2382, 16003]

TRAIN, epoch 49, loss 0.5291267414855054, acc 0.7528093564189821,recall 0.4700942996397542,precision 0.7338778041972501,specificity 0.9070175692076519,[tp,tn,fp,fn]: [35494, 125553, 12871, 40010]
VAL, loss 0.42325728898994364, acc 0.8128722420530361,f1 0.47927618836810365, recall 0.3416837620325075,precision 0.802390216787104,specificity 0.9716450648055832,[tp,tn,fp,fn]: [8661, 73092, 2133, 16687]



 * BEST_ACC: 0.820428942161415
 * TIME: Time 2726.695 (2726.695)

