pooling_ratio 0.2, dropout0.2, hidden_dim 64, outdim 128
epochs 100, lr 1e-05, weight_decay 0.001
TRAIN, epoch 0, loss 0.5356858266812649, acc 0.7595733143861486,recall 0.5188731722822632,precision 0.721704369611672,specificity 0.890864300988268,[tp,tn,fp,fn]: [39177, 123317, 15107, 36327]
VAL, loss 0.3958254224807787, acc 0.8397382995436151,f1 0.624534103615356, recall 0.528838567145337,precision 0.762514220705347,specificity 0.9444998338318378,[tp,tn,fp,fn]: [13405, 71050, 4175, 11943]

TRAIN, epoch 1, loss 0.47439890931308915, acc 0.789279570696683,recall 0.6564155541428268,precision 0.7214369932604551,specificity 0.8617508524533318,[tp,tn,fp,fn]: [49562, 119287, 19137, 25942]
VAL, loss 0.3841466513301673, acc 0.8395493820409056,f1 0.6184114072217362, recall 0.5158592393877229,precision 0.7718552623812054,specificity 0.9486208042539049,[tp,tn,fp,fn]: [13076, 71360, 3865, 12272]

TRAIN, epoch 2, loss 0.462647402965471, acc 0.7940101342507759,recall 0.659965034965035,precision 0.7303988391011829,specificity 0.8671256429520893,[tp,tn,fp,fn]: [49830, 120031, 18393, 25674]
VAL, loss 0.3746109085826598, acc 0.8427808656398834,f1 0.6320394675602719, recall 0.5357424648887487,precision 0.7705401724920563,specificity 0.9462412761714856,[tp,tn,fp,fn]: [13580, 71181, 4044, 11768]

TRAIN, epoch 3, loss 0.45527392951905704, acc 0.7975533824464306,recall 0.6628655435473617,precision 0.7370661090084385,specificity 0.8710194763913772,[tp,tn,fp,fn]: [50049, 120570, 17854, 25455]
VAL, loss 0.3709252735451213, acc 0.8418064490469609,f1 0.6193051301684533, recall 0.5105333754142338,precision 0.7869739722695208,specificity 0.9534330342306414,[tp,tn,fp,fn]: [12941, 71722, 3503, 12407]

TRAIN, epoch 4, loss 0.45086042561200645, acc 0.799161400097229,recall 0.6639118457300276,precision 0.7402572470723747,specificity 0.8729338842975206,[tp,tn,fp,fn]: [50128, 120835, 17589, 25376]
VAL, loss 0.3698743590256384, acc 0.8428007516928002,f1 0.621878886444083, recall 0.5129004260691179,precision 0.7896622934888241,specificity 0.9539647723496179,[tp,tn,fp,fn]: [13001, 71762, 3463, 12347]

TRAIN, epoch 5, loss 0.4471056288612045, acc 0.8012041434501328,recall 0.6676997245179064,precision 0.7429994694334728,specificity 0.8740247355949835,[tp,tn,fp,fn]: [50414, 120986, 17438, 25090]
VAL, loss 0.3670291240776521, acc 0.8445706104023942,f1 0.6302568711859595, recall 0.5256035979169954,precision 0.7869462492616657,specificity 0.9520505151213028,[tp,tn,fp,fn]: [13323, 71618, 3607, 12025]

TRAIN, epoch 6, loss 0.44388528228327667, acc 0.8030645824763472,recall 0.6682692307692307,precision 0.7470684039087948,specificity 0.876589319771138,[tp,tn,fp,fn]: [50457, 121341, 17083, 25047]
VAL, loss 0.36275009694861327, acc 0.8471458542551181,f1 0.6455955921340802, recall 0.5523907211614328,precision 0.7766376393588108,specificity 0.9464672648720505,[tp,tn,fp,fn]: [14002, 71198, 4027, 11346]

TRAIN, epoch 7, loss 0.44178174147609106, acc 0.8039433828203881,recall 0.6709048527230346,precision 0.747690036900369,specificity 0.8765098537825811,[tp,tn,fp,fn]: [50656, 121330, 17094, 24848]
VAL, loss 0.35982073978521995, acc 0.8479412963717896,f1 0.6495405275339735, recall 0.5590973646836043,precision 0.7748920115916671,specificity 0.9452708541043536,[tp,tn,fp,fn]: [14172, 71108, 4117, 11176]

TRAIN, epoch 8, loss 0.4395129895015009, acc 0.8059440559440559,recall 0.6750635727908455,precision 0.7501103752759382,specificity 0.8773334103912617,[tp,tn,fp,fn]: [50970, 121444, 16980, 24534]
VAL, loss 0.35780593606365213, acc 0.8483986755888757,f1 0.6500493470127844, recall 0.5586634053968755,precision 0.7771801767191702,specificity 0.946028580923895,[tp,tn,fp,fn]: [14161, 71165, 4060, 11187]

TRAIN, epoch 9, loss 0.43834510098879914, acc 0.8064208518753974,recall 0.6747854418308964,precision 0.7513936819750464,specificity 0.8782219846269433,[tp,tn,fp,fn]: [50949, 121567, 16857, 24555]
VAL, loss 0.3613962461892644, acc 0.847215455440327,f1 0.6427840803421981, recall 0.545407921729525,precision 0.7824881141045958,specificity 0.948913260219342,[tp,tn,fp,fn]: [13825, 71382, 3843, 11523]

TRAIN, epoch 10, loss 0.43588832274526784, acc 0.8076642608728171,recall 0.6781230133502861,precision 0.7524689906531068,specificity 0.8783231231578339,[tp,tn,fp,fn]: [51201, 121581, 16843, 24303]
VAL, loss 0.35548416245346287, acc 0.8491344595467969,f1 0.6555114087864684, recall 0.5695123875650939,precision 0.7721024763331016,specificity 0.9433565968760386,[tp,tn,fp,fn]: [14436, 70964, 4261, 10912]

TRAIN, epoch 11, loss 0.43487945696182495, acc 0.8080802886952619,recall 0.6798580207671117,precision 0.7524810531099286,specificity 0.8780197075651621,[tp,tn,fp,fn]: [51332, 121539, 16885, 24172]
VAL, loss 0.35689826412672493, acc 0.8486472512503356,f1 0.6493757773989958, recall 0.5560991005207512,precision 0.7802501937340861,specificity 0.9472249916915919,[tp,tn,fp,fn]: [14096, 71255, 3970, 11252]

TRAIN, epoch 12, loss 0.4342313944025148, acc 0.8081317078643282,recall 0.6773415977961432,precision 0.7540176333559402,specificity 0.8794717679015199,[tp,tn,fp,fn]: [51142, 121740, 16684, 24362]
VAL, loss 0.3544672223934836, acc 0.8494625794199239,f1 0.656736044982542, recall 0.571366577244753,precision 0.7720972385115684,specificity 0.9431704885343968,[tp,tn,fp,fn]: [14483, 70950, 4275, 10865]

TRAIN, epoch 13, loss 0.432128205132562, acc 0.8098472383231742,recall 0.6802685950413223,precision 0.7564395222456223,specificity 0.8805264982950933,[tp,tn,fp,fn]: [51363, 121886, 16538, 24141]
VAL, loss 0.3586844279352401, acc 0.8475435753134539,f1 0.6423956899969681, recall 0.5433170269843774,precision 0.7856694620343431,specificity 0.9500564971751413,[tp,tn,fp,fn]: [13772, 71468, 3757, 11576]

TRAIN, epoch 14, loss 0.4313360047984117, acc 0.8107213641973,recall 0.6832485696122059,precision 0.7568217827592277,specificity 0.8802519794255331,[tp,tn,fp,fn]: [51588, 121848, 16576, 23916]
VAL, loss 0.35540589574915676, acc 0.8495222375786742,f1 0.6542854532163743, recall 0.5649755404765662,precision 0.7771326242674191,specificity 0.9454037886340977,[tp,tn,fp,fn]: [14321, 71118, 4107, 11027]

TRAIN, epoch 15, loss 0.4307282710847936, acc 0.8110065068621218,recall 0.6827055520237338,precision 0.75781008806104,specificity 0.8809888458648789,[tp,tn,fp,fn]: [51547, 121950, 16474, 23957]
VAL, loss 0.3554386603237283, acc 0.8484384476947093,f1 0.6465391304347826, recall 0.5499842196623008,precision 0.7842155594307251,specificity 0.9490063143901628,[tp,tn,fp,fn]: [13941, 71389, 3836, 11407]

TRAIN, epoch 16, loss 0.42944663690047796, acc 0.8111327175498299,recall 0.6827320406865861,precision 0.7580958263478338,specificity 0.8811694503843264,[tp,tn,fp,fn]: [51549, 121975, 16449, 23955]
VAL, loss 0.35601285025353696, acc 0.8492438328378392,f1 0.6523433917270476, recall 0.5611882594287517,precision 0.7788545773105563,specificity 0.9463077434363576,[tp,tn,fp,fn]: [14225, 71186, 4039, 11123]

TRAIN, epoch 17, loss 0.42835015272609156, acc 0.8117777943981153,recall 0.6846127357490994,precision 0.7585554120685607,specificity 0.8811405536612148,[tp,tn,fp,fn]: [51691, 121971, 16453, 23813]
VAL, loss 0.3564869171144796, acc 0.8492239467849224,f1 0.6509368813590534, recall 0.5577954868234181,precision 0.781419255001658,specificity 0.947424393486208,[tp,tn,fp,fn]: [14139, 71270, 3955, 11209]

TRAIN, epoch 18, loss 0.42838857008619935, acc 0.8122499158595415,recall 0.6847319347319347,precision 0.7596127003717253,specificity 0.8818051782927816,[tp,tn,fp,fn]: [51700, 122063, 16361, 23804]
VAL, loss 0.35321310586119015, acc 0.8508347170711821,f1 0.6592003634711494, recall 0.5723922991952027,precision 0.7770458440445587,specificity 0.9446593552675308,[tp,tn,fp,fn]: [14509, 71062, 4163, 10839]

TRAIN, epoch 19, loss 0.42666517688067124, acc 0.8128248756591002,recall 0.6863874761602035,precision 0.76003109051446,specificity 0.8817907299312258,[tp,tn,fp,fn]: [51825, 122061, 16363, 23679]
VAL, loss 0.35250484428509904, acc 0.8505065971980551,f1 0.6583498079850932, recall 0.5714849297774972,precision 0.7763545742001179,specificity 0.9445264207377866,[tp,tn,fp,fn]: [14486, 71052, 4173, 10862]

TRAIN, epoch 20, loss 0.42609821388753655, acc 0.813147414083243,recall 0.6870894257257893,precision 0.7603957493587394,specificity 0.8819063168236722,[tp,tn,fp,fn]: [51878, 122077, 16347, 23626]
VAL, loss 0.35389686581880253, acc 0.8499995028486771,f1 0.6561673808004376, recall 0.5678949029509232,precision 0.7769322107081175,specificity 0.945058158856763,[tp,tn,fp,fn]: [14395, 71092, 4133, 10953]

TRAIN, epoch 21, loss 0.4257432659042073, acc 0.8134278822781497,recall 0.688731722822632,precision 0.760118690892082,specificity 0.8814439692538866,[tp,tn,fp,fn]: [52002, 122013, 16411, 23502]
VAL, loss 0.3544122756625974, acc 0.8497906992930508,f1 0.6542625014303696, recall 0.5639103676818684,precision 0.7790919496375429,specificity 0.9461216350947158,[tp,tn,fp,fn]: [14294, 71172, 4053, 11054]

TRAIN, epoch 22, loss 0.42526680577920684, acc 0.8133390673497626,recall 0.6887847001483365,precision 0.7598772647574518,specificity 0.881277813095995,[tp,tn,fp,fn]: [52006, 121990, 16434, 23498]
VAL, loss 0.35208960169512155, acc 0.8501784773249281,f1 0.6562642576877453, recall 0.5674609436641944,precision 0.7780181739506707,specificity 0.9454436689930209,[tp,tn,fp,fn]: [14384, 71121, 4104, 10964]

TRAIN, epoch 23, loss 0.4247823179376664, acc 0.8137784675217831,recall 0.6885860351769443,precision 0.7610369459570232,specificity 0.882065248800786,[tp,tn,fp,fn]: [51991, 122099, 16325, 23513]
VAL, loss 0.3524379061433269, acc 0.8506259135155558,f1 0.6577826374177088, recall 0.56959128925359,precision 0.7782868848040537,specificity 0.9453240279162513,[tp,tn,fp,fn]: [14438, 71112, 4113, 10910]

TRAIN, epoch 24, loss 0.42405424016267634, acc 0.8143861486107475,recall 0.6909435261707989,precision 0.7611245659595577,specificity 0.8817184881234468,[tp,tn,fp,fn]: [52169, 122051, 16373, 23335]
VAL, loss 0.35335653305313586, acc 0.8511031787855587,f1 0.6587516806052458, recall 0.5702225027615591,precision 0.7798219584569733,specificity 0.9457494184114323,[tp,tn,fp,fn]: [14454, 71144, 4081, 10894]

TRAIN, epoch 25, loss 0.4239656009276782, acc 0.8141337272353315,recall 0.6893409620682348,precision 0.7614477572636569,specificity 0.8822025082355661,[tp,tn,fp,fn]: [52048, 122118, 16306, 23456]
VAL, loss 0.35018755635510085, acc 0.8517395324788959,f1 0.6629139821408387, recall 0.578428278365157,precision 0.7763011595277175,specificity 0.9438351611831173,[tp,tn,fp,fn]: [14662, 71000, 4225, 10686]

TRAIN, epoch 26, loss 0.422858565739279, acc 0.8144796380090498,recall 0.6912084127993219,precision 0.7611942475423704,specificity 0.8817184881234468,[tp,tn,fp,fn]: [52189, 122051, 16373, 23315]
VAL, loss 0.3547074938933388, acc 0.8506656856213894,f1 0.6543939986653473, recall 0.5609515543632634,precision 0.7851896846871721,specificity 0.9482884679295447,[tp,tn,fp,fn]: [14219, 71335, 3890, 11129]

TRAIN, epoch 27, loss 0.42272996236229393, acc 0.8149657828802214,recall 0.6925328459419369,precision 0.7615864138192199,specificity 0.8817473848465583,[tp,tn,fp,fn]: [52289, 122055, 16369, 23215]
VAL, loss 0.3507639646757803, acc 0.8530022968391119,f1 0.6693505099302199, recall 0.5903424333280732,precision 0.7727742202024375,specificity 0.9415088069125955,[tp,tn,fp,fn]: [14964, 70825, 4400, 10384]

TRAIN, epoch 28, loss 0.42209173528932603, acc 0.8153724617628361,recall 0.6929301758847214,precision 0.7623231484314669,specificity 0.8821591631508987,[tp,tn,fp,fn]: [52319, 122112, 16312, 23185]
VAL, loss 0.35143026197299065, acc 0.8521372535372317,f1 0.6659028105412146, recall 0.5846615117563516,precision 0.7733653394562437,specificity 0.9422665337321369,[tp,tn,fp,fn]: [14820, 70882, 4343, 10528]

TRAIN, epoch 29, loss 0.42269037334663356, acc 0.8148769679518343,recall 0.691393833439288,precision 0.7620319684694548,specificity 0.8822314049586777,[tp,tn,fp,fn]: [52203, 122122, 16302, 23301]
VAL, loss 0.3487609683856219, acc 0.8532906446064052,f1 0.6714174368110455, recall 0.5947214770396086,precision 0.7708237459733088,specificity 0.9404187437686939,[tp,tn,fp,fn]: [15075, 70743, 4482, 10273]

TRAIN, epoch 30, loss 0.4213985293832804, acc 0.8149657828802214,recall 0.6918971180334816,precision 0.7619526851608763,specificity 0.8820941455238976,[tp,tn,fp,fn]: [52241, 122103, 16321, 23263]
VAL, loss 0.3513884322669392, acc 0.851640102214312,f1 0.6617857061903574, recall 0.5759034243332807,precision 0.7777718578507112,specificity 0.9445530076437355,[tp,tn,fp,fn]: [14598, 71054, 4171, 10750]

TRAIN, epoch 31, loss 0.4212152680722676, acc 0.8153210425937699,recall 0.6926255562619199,precision 0.762376814974634,specificity 0.8822458533202335,[tp,tn,fp,fn]: [52296, 122124, 16300, 23208]
VAL, loss 0.350912721773232, acc 0.8517494755053543,f1 0.6636892678305589, recall 0.5804008205775604,precision 0.7748867586642789,specificity 0.9431837819873712,[tp,tn,fp,fn]: [14712, 70951, 4274, 10636]

TRAIN, epoch 32, loss 0.4201729543848966, acc 0.8164709621928873,recall 0.6949962915872007,precision 0.7637393025557432,specificity 0.8827298734323528,[tp,tn,fp,fn]: [52475, 122191, 16233, 23029]
VAL, loss 0.3533353473802137, acc 0.8513815835263938,f1 0.660965817587951, recall 0.5747988006943349,precision 0.7775228133838519,specificity 0.9445795945496843,[tp,tn,fp,fn]: [14570, 71056, 4169, 10778]

TRAIN, epoch 33, loss 0.41970799505088724, acc 0.8159147002729891,recall 0.6939235007416825,precision 0.7630379378140246,specificity 0.8824553545627926,[tp,tn,fp,fn]: [52394, 122153, 16271, 23110]
VAL, loss 0.3498475133833251, acc 0.852574746701401,f1 0.6668314495651978, recall 0.5853716269528167,precision 0.7746280344557557,specificity 0.9426121635094716,[tp,tn,fp,fn]: [14838, 70908, 4317, 10510]

TRAIN, epoch 34, loss 0.4195312164755357, acc 0.8161157024793388,recall 0.6937910574274211,precision 0.7635928981662342,specificity 0.8828382361440212,[tp,tn,fp,fn]: [52384, 122206, 16218, 23120]
VAL, loss 0.3519974222085547, acc 0.8514412416851441,f1 0.6580615631079072, recall 0.5671847877544579,precision 0.7836158500027253,specificity 0.9472249916915919,[tp,tn,fp,fn]: [14377, 71255, 3970, 10971]

TRAIN, epoch 35, loss 0.419146689026907, acc 0.816835570846266,recall 0.6950757575757576,precision 0.7645610559132893,specificity 0.8832500144483616,[tp,tn,fp,fn]: [52481, 122263, 16161, 23023]
VAL, loss 0.3489633531013811, acc 0.8526940630189017,f1 0.6686645941896093, recall 0.5897506706643523,precision 0.7719597211463981,specificity 0.9412961116650049,[tp,tn,fp,fn]: [14949, 70809, 4416, 10399]

TRAIN, epoch 36, loss 0.4187775189576271, acc 0.8163681238547549,recall 0.6952611782157236,precision 0.7633415733604769,specificity 0.882426457839681,[tp,tn,fp,fn]: [52495, 122149, 16275, 23009]
VAL, loss 0.3494151817210049, acc 0.8520875384049397,f1 0.6637736190217882, recall 0.5792961969386144,precision 0.7770956816257409,specificity 0.9440079760717847,[tp,tn,fp,fn]: [14684, 71013, 4212, 10664]

TRAIN, epoch 37, loss 0.41838324278384653, acc 0.8164803111327176,recall 0.6939897223988133,precision 0.7643463546984859,specificity 0.883293359533029,[tp,tn,fp,fn]: [52399, 122269, 16155, 23105]
VAL, loss 0.3500820946048335, acc 0.8530917840772374,f1 0.6661243305538608, recall 0.5814659933722581,precision 0.7796350171912193,specificity 0.9446194749086075,[tp,tn,fp,fn]: [14739, 71059, 4166, 10609]

TRAIN, epoch 38, loss 0.4182090418836993, acc 0.8169664560038892,recall 0.6952744225471498,precision 0.7647572985257269,specificity 0.8833439287984742,[tp,tn,fp,fn]: [52496, 122276, 16148, 23008]
VAL, loss 0.34951365828267705, acc 0.852017937219731,f1 0.6629526462395542, recall 0.5774420072589553,precision 0.7781912914030518,specificity 0.9445397141907611,[tp,tn,fp,fn]: [14637, 71053, 4172, 10711]

TRAIN, epoch 39, loss 0.41801093800530364, acc 0.8172001794996447,recall 0.695910150455605,precision 0.7649439510845829,specificity 0.8833583771600301,[tp,tn,fp,fn]: [52544, 122278, 16146, 22960]
VAL, loss 0.34947309634640455, acc 0.8523361140663995,f1 0.6643159060599896, recall 0.5797301562253432,precision 0.7778013020695496,specificity 0.9441940844134263,[tp,tn,fp,fn]: [14695, 71027, 4198, 10653]

TRAIN, epoch 40, loss 0.417314960448727, acc 0.8176442541415804,recall 0.6967975206611571,precision 0.7654847298811274,specificity 0.8835606542218113,[tp,tn,fp,fn]: [52611, 122306, 16118, 22893]
VAL, loss 0.3500756448431642, acc 0.8528133793364024,f1 0.666921674954436, recall 0.5846615117563516,precision 0.7761194029850746,specificity 0.9431704885343968,[tp,tn,fp,fn]: [14820, 70950, 4275, 10528]

TRAIN, epoch 41, loss 0.4173011440626458, acc 0.8166906622788975,recall 0.6956187751642298,precision 0.7639008072140208,specificity 0.8827298734323528,[tp,tn,fp,fn]: [52522, 122191, 16233, 22982]
VAL, loss 0.3498382311871325, acc 0.851689817346604,f1 0.6613847900113508, recall 0.5746804481615907,precision 0.7789006523366485,specificity 0.9450315719508142,[tp,tn,fp,fn]: [14567, 71090, 4135, 10781]

TRAIN, epoch 42, loss 0.41648010061939217, acc 0.8178920010470813,recall 0.6979630218266581,precision 0.7653953407308429,specificity 0.8833078078945847,[tp,tn,fp,fn]: [52699, 122271, 16153, 22805]
VAL, loss 0.3490362886252047, acc 0.8525150885426506,f1 0.6642218449349179, recall 0.5787833359633896,precision 0.7792532001912147,specificity 0.9447524094383516,[tp,tn,fp,fn]: [14671, 71069, 4156, 10677]

TRAIN, epoch 43, loss 0.4158580566298689, acc 0.8180696309038555,recall 0.6974862258953168,precision 0.7660964184923337,specificity 0.8838423972721493,[tp,tn,fp,fn]: [52663, 122345, 16079, 22841]
VAL, loss 0.35001640351214697, acc 0.8522764559076492,f1 0.6617951694780214, recall 0.5734574719899006,precision 0.7823045046014746,specificity 0.9462279827185112,[tp,tn,fp,fn]: [14536, 71180, 4045, 10812]

TRAIN, epoch 44, loss 0.4162824990596363, acc 0.8182753075801205,recall 0.6970094299639754,precision 0.7668667851834582,specificity 0.8844203317343813,[tp,tn,fp,fn]: [52627, 122425, 15999, 22877]
VAL, loss 0.35117512262505185, acc 0.8523460570928579,f1 0.6633569096844396, recall 0.5772053021934669,precision 0.7797377957791516,specificity 0.945058158856763,[tp,tn,fp,fn]: [14631, 71092, 4133, 10717]

TRAIN, epoch 45, loss 0.4163354335744309, acc 0.8172843199581168,recall 0.6961088154269972,precision 0.7650286745655148,specificity 0.8833800497023637,[tp,tn,fp,fn]: [52559, 122281, 16143, 22945]
VAL, loss 0.3481236932359714, acc 0.8528829805216112,f1 0.6699973235792666, recall 0.592551680605965,precision 0.7707307060755336,specificity 0.9406048521103356,[tp,tn,fp,fn]: [15020, 70757, 4468, 10328]

TRAIN, epoch 46, loss 0.41622976722760435, acc 0.8179293968064022,recall 0.6966915660097478,precision 0.7662267668822467,specificity 0.8840591226954864,[tp,tn,fp,fn]: [52603, 122375, 16049, 22901]
VAL, loss 0.3473663520885677, acc 0.8537977389557834,f1 0.6696769555645414, recall 0.5880148335174372,precision 0.7776792236251696,specificity 0.9433565968760386,[tp,tn,fp,fn]: [14905, 70964, 4261, 10443]

TRAIN, epoch 47, loss 0.4157918774897968, acc 0.817966792565723,recall 0.6981087094723458,precision 0.7654883964100032,specificity 0.8833439287984742,[tp,tn,fp,fn]: [52710, 122276, 16148, 22794]
VAL, loss 0.34887052991455736, acc 0.8531216131566126,f1 0.6675369103348938, recall 0.5850560201988323,precision 0.7770907566547893,specificity 0.9434496510468594,[tp,tn,fp,fn]: [14830, 70971, 4254, 10518]

TRAIN, epoch 48, loss 0.4157439183089519, acc 0.8184202161474888,recall 0.6970094299639754,precision 0.7672133537429842,specificity 0.8846442813384963,[tp,tn,fp,fn]: [52627, 122456, 15968, 22877]
VAL, loss 0.35199282323720843, acc 0.8515108428703528,f1 0.6566107151069212, recall 0.5632791541738993,precision 0.7870135596957336,specificity 0.9486340977068793,[tp,tn,fp,fn]: [14278, 71361, 3864, 11070]

TRAIN, epoch 49, loss 0.41556019165107466, acc 0.8190372461762836,recall 0.6992212333121424,precision 0.7673881128537582,specificity 0.8843914350112697,[tp,tn,fp,fn]: [52794, 122421, 16003, 22710]
VAL, loss 0.3495365506127875, acc 0.8523659431457747,f1 0.6645581059099946, recall 0.5802430172005681,precision 0.7775428208923663,specificity 0.9440611498836823,[tp,tn,fp,fn]: [14708, 71017, 4208, 10640]

TRAIN, epoch 50, loss 0.4148830053330734, acc 0.8185277289555365,recall 0.6981087094723458,precision 0.766824754866304,specificity 0.8842108304918223,[tp,tn,fp,fn]: [52710, 122396, 16028, 22794]
VAL, loss 0.3498927893966468, acc 0.8532707585534886,f1 0.6689993943879955, recall 0.5883304402714218,precision 0.7753054328047829,specificity 0.9425456962445995,[tp,tn,fp,fn]: [14913, 70903, 4322, 10435]

TRAIN, epoch 51, loss 0.41495361851284424, acc 0.8185884970644329,recall 0.6980954651409197,precision 0.7669775766482837,specificity 0.8843119690227128,[tp,tn,fp,fn]: [52709, 122410, 16014, 22795]
VAL, loss 0.3510273417108589, acc 0.8529625247332783,f1 0.6659739790386701, recall 0.5815843459050024,precision 0.7790107799619531,specificity 0.9444067796610169,[tp,tn,fp,fn]: [14742, 71043, 4182, 10606]

TRAIN, epoch 52, loss 0.4145694642524606, acc 0.8188689652593396,recall 0.6982014197923289,precision 0.7675854336842411,specificity 0.8846876264231636,[tp,tn,fp,fn]: [52717, 122462, 15962, 22787]
VAL, loss 0.350171465495542, acc 0.8523162280134827,f1 0.6627920176175448, recall 0.5758639734890326,precision 0.7806299802128456,specificity 0.9454702558989697,[tp,tn,fp,fn]: [14597, 71123, 4102, 10751]

TRAIN, epoch 53, loss 0.41475076930809385, acc 0.8183921693279982,recall 0.6987576817122272,precision 0.7661221229942642,specificity 0.883647344391146,[tp,tn,fp,fn]: [52759, 122318, 16106, 22745]
VAL, loss 0.3495961484178198, acc 0.852525031569109,f1 0.6661865322290241, recall 0.5838724948713903,precision 0.7755187591699854,specificity 0.9430508474576271,[tp,tn,fp,fn]: [14800, 70941, 4284, 10548]

TRAIN, epoch 54, loss 0.4147223812970926, acc 0.8190138738267081,recall 0.6979232888323798,precision 0.7680960848905344,specificity 0.8850632838236144,[tp,tn,fp,fn]: [52696, 122514, 15910, 22808]
VAL, loss 0.35201121510583017, acc 0.851640102214312,f1 0.659345677039337, recall 0.5696701909420862,precision 0.7825285861377553,specificity 0.9466533732136923,[tp,tn,fp,fn]: [14440, 71212, 4013, 10908]

TRAIN, epoch 55, loss 0.4139521069096661, acc 0.8191120376949254,recall 0.6988636363636364,precision 0.7677768562573661,specificity 0.8847020747847194,[tp,tn,fp,fn]: [52767, 122464, 15960, 22737]
VAL, loss 0.3492295612993772, acc 0.8523858291986915,f1 0.6633712756791075, recall 0.5770869496607227,precision 0.7799936013650421,specificity 0.9451512130275839,[tp,tn,fp,fn]: [14628, 71099, 4126, 10720]

TRAIN, epoch 56, loss 0.41417163475717683, acc 0.8187427545716316,recall 0.6983206187751643,precision 0.7672137826668994,specificity 0.8844275559151592,[tp,tn,fp,fn]: [52726, 122426, 15998, 22778]
VAL, loss 0.34938909668687373, acc 0.852853151442236,f1 0.6658236423168116, recall 0.5816237967492505,precision 0.7785288060410835,specificity 0.9442472582253241,[tp,tn,fp,fn]: [14743, 71031, 4194, 10605]

TRAIN, epoch 57, loss 0.4138477221908675, acc 0.8193925058898321,recall 0.6993934096206823,precision 0.7681353368146974,specificity 0.8848465584002774,[tp,tn,fp,fn]: [52807, 122484, 15940, 22697]
VAL, loss 0.3487548054974933, acc 0.8532608155270301,f1 0.6675826651049644, recall 0.5846220609121036,precision 0.7779819403611927,specificity 0.9437819873712197,[tp,tn,fp,fn]: [14819, 70996, 4229, 10529]

TRAIN, epoch 58, loss 0.41325504348912945, acc 0.8201778168355709,recall 0.7010092180546726,precision 0.7690597619981692,specificity 0.8851788707160608,[tp,tn,fp,fn]: [52929, 122530, 15894, 22575]
VAL, loss 0.34984661894295055, acc 0.8526344048601513,f1 0.6620145492691158, recall 0.5726290042606912,precision 0.7844673836675133,specificity 0.9469857095380525,[tp,tn,fp,fn]: [14515, 71237, 3988, 10833]

TRAIN, epoch 59, loss 0.41346331368739647, acc 0.8192943420216148,recall 0.700505933460479,precision 0.767247882093536,specificity 0.8840880194185979,[tp,tn,fp,fn]: [52891, 122379, 16045, 22613]
VAL, loss 0.3489929033138876, acc 0.853310530659322,f1 0.6657604386143773, recall 0.5796512545368471,precision 0.7819168750997818,specificity 0.9455234297108674,[tp,tn,fp,fn]: [14693, 71127, 4098, 10655]

TRAIN, epoch 60, loss 0.4127255867783443, acc 0.8198225571220223,recall 0.7010357067175249,precision 0.7681958695557523,specificity 0.8846153846153846,[tp,tn,fp,fn]: [52931, 122452, 15972, 22573]
VAL, loss 0.3507270043417824, acc 0.8520577093255645,f1 0.6602735347169898, recall 0.5704197569827995,precision 0.7837281153450052,specificity 0.9469591226321037,[tp,tn,fp,fn]: [14459, 71235, 3990, 10889]

TRAIN, epoch 61, loss 0.4126145734506495, acc 0.8197103698440596,recall 0.7000026488662853,precision 0.7685361562286429,specificity 0.8850054903773912,[tp,tn,fp,fn]: [52853, 122506, 15918, 22651]
VAL, loss 0.3491908922276542, acc 0.8525648036749426,f1 0.6629080658361372, recall 0.5751933091368155,precision 0.7821888412017167,specificity 0.946028580923895,[tp,tn,fp,fn]: [14580, 71165, 4060, 10768]

TRAIN, epoch 62, loss 0.4131966938931371, acc 0.8192896675516996,recall 0.6997774952320407,precision 0.7676638528484461,specificity 0.8844781251806045,[tp,tn,fp,fn]: [52836, 122433, 15991, 22668]
VAL, loss 0.3507197896237738, acc 0.8529326956539032,f1 0.662760208851091, recall 0.5733785703014045,precision 0.7851547728377721,specificity 0.9471319375207711,[tp,tn,fp,fn]: [14534, 71248, 3977, 10814]

TRAIN, epoch 63, loss 0.41271493369240814, acc 0.8204676339703078,recall 0.7011946386946387,precision 0.7696434022881565,specificity 0.8855256313934,[tp,tn,fp,fn]: [52943, 122578, 15846, 22561]
VAL, loss 0.3506536564879249, acc 0.852246626828274,f1 0.6598452593508218, recall 0.5686050181473884,precision 0.7859635729087141,specificity 0.9478231970754404,[tp,tn,fp,fn]: [14413, 71300, 3925, 10935]

TRAIN, epoch 64, loss 0.4127378690006943, acc 0.8199394188699002,recall 0.699009324009324,precision 0.7696727527270606,specificity 0.8859012887938508,[tp,tn,fp,fn]: [52778, 122630, 15794, 22726]
VAL, loss 0.34873483663343974, acc 0.8531017271036958,f1 0.6664258297584105, recall 0.5822155594129714,precision 0.7791151937493401,specificity 0.9443801927550681,[tp,tn,fp,fn]: [14758, 71041, 4184, 10590]

TRAIN, epoch 65, loss 0.4123982663993315, acc 0.8199253954601549,recall 0.6986252383979656,precision 0.7698673321949298,specificity 0.8860891174940762,[tp,tn,fp,fn]: [52749, 122656, 15768, 22755]
VAL, loss 0.35002601148787094, acc 0.8530022968391119,f1 0.6638930568817352, recall 0.576021776866025,precision 0.7833995063848053,specificity 0.9463343303423064,[tp,tn,fp,fn]: [14601, 71188, 4037, 10747]

TRAIN, epoch 66, loss 0.4115665743247202, acc 0.8210893384690177,recall 0.7031945327399873,precision 0.7699469242147394,specificity 0.8853955961393978,[tp,tn,fp,fn]: [53094, 122560, 15864, 22410]
VAL, loss 0.35148580714315125, acc 0.8526344048601513,f1 0.6616287299376726, recall 0.5716427331544895,precision 0.7852381726548529,specificity 0.9473180458624127,[tp,tn,fp,fn]: [14490, 71262, 3963, 10858]

TRAIN, epoch 67, loss 0.4116750036536486, acc 0.8199394188699002,recall 0.69953909726637,precision 0.7693585037580842,specificity 0.8856123215627348,[tp,tn,fp,fn]: [52818, 122590, 15834, 22686]
VAL, loss 0.3500914993701258, acc 0.8528829805216112,f1 0.663925861990642, recall 0.5765740886854979,precision 0.7824713566763036,specificity 0.9459887005649718,[tp,tn,fp,fn]: [14615, 71162, 4063, 10733]

TRAIN, epoch 68, loss 0.4113540241714815, acc 0.8197197187838899,recall 0.7007443314261496,precision 0.7681218333067173,specificity 0.8846153846153846,[tp,tn,fp,fn]: [52909, 122452, 15972, 22595]
VAL, loss 0.3488914055761942, acc 0.8533304167122389,f1 0.6685540950455005, recall 0.5869102098784914,precision 0.7765829722816725,specificity 0.9431040212695248,[tp,tn,fp,fn]: [14877, 70945, 4280, 10471]

TRAIN, epoch 69, loss 0.4112891865460457, acc 0.8204162148012415,recall 0.7013668150031787,precision 0.7694185336936623,specificity 0.8853522510547304,[tp,tn,fp,fn]: [52956, 122554, 15870, 22548]
VAL, loss 0.3475624368660156, acc 0.8535392202678651,f1 0.6673892426500474, recall 0.5830045762979328,precision 0.780335832717288,specificity 0.944699235626454,[tp,tn,fp,fn]: [14778, 71065, 4160, 10570]

TRAIN, epoch 70, loss 0.41127105409025294, acc 0.8208976852024981,recall 0.7018700995973723,precision 0.7702728237329031,specificity 0.8858218228052939,[tp,tn,fp,fn]: [52994, 122619, 15805, 22510]
VAL, loss 0.35092400773371013, acc 0.8526741769659849,f1 0.663960265801828, recall 0.5774814581032034,precision 0.7809015737530008,specificity 0.9454037886340977,[tp,tn,fp,fn]: [14638, 71118, 4107, 10710]

TRAIN, epoch 71, loss 0.41087314067793285, acc 0.8205097041995437,recall 0.7009297520661157,precision 0.7699010765202211,specificity 0.885735132635959,[tp,tn,fp,fn]: [52923, 122607, 15817, 22581]
VAL, loss 0.34986009540290475, acc 0.8528829805216112,f1 0.662515396195429, recall 0.5729446110146758,precision 0.7852817129879961,specificity 0.9472116982386175,[tp,tn,fp,fn]: [14523, 71254, 3971, 10825]

TRAIN, epoch 72, loss 0.41077474867556224, acc 0.8209678022512247,recall 0.7009959737232464,precision 0.7709607877410709,specificity 0.8864069814483038,[tp,tn,fp,fn]: [52928, 122700, 15724, 22576]
VAL, loss 0.3488368487299243, acc 0.8532111003947381,f1 0.6640267631596916, recall 0.5755483667350482,precision 0.7846501371483892,specificity 0.9467730142904619,[tp,tn,fp,fn]: [14589, 71221, 4004, 10759]

TRAIN, epoch 73, loss 0.410633176838218, acc 0.8209631277813096,recall 0.7023601398601399,precision 0.7701389796540757,specificity 0.8856556666474021,[tp,tn,fp,fn]: [53031, 122596, 15828, 22473]
VAL, loss 0.346653580298071, acc 0.8537679098764082,f1 0.6687985587208647, recall 0.5858055862395455,precision 0.7791887495408512,specificity 0.9440611498836823,[tp,tn,fp,fn]: [14849, 71017, 4208, 10499]

TRAIN, epoch 74, loss 0.4106696128258998, acc 0.8205751467783553,recall 0.7011019283746557,precision 0.7699557831044915,specificity 0.885742356816737,[tp,tn,fp,fn]: [52936, 122608, 15816, 22568]
VAL, loss 0.35040056915002754, acc 0.8525946327543178,f1 0.663137085596128, recall 0.5756667192677923,precision 0.781951663897969,specificity 0.9459089398471253,[tp,tn,fp,fn]: [14592, 71156, 4069, 10756]

TRAIN, epoch 75, loss 0.4103953729876004, acc 0.8209865001308851,recall 0.701313837677474,precision 0.7708163502969605,specificity 0.8862624978327458,[tp,tn,fp,fn]: [52952, 122680, 15744, 22552]
VAL, loss 0.3496229267976193, acc 0.8528730374951528,f1 0.6611865454628717, recall 0.56959128925359,precision 0.7878854024556616,specificity 0.9483283482884679,[tp,tn,fp,fn]: [14438, 71338, 3887, 10910]

TRAIN, epoch 76, loss 0.410215143274117, acc 0.8209117086122434,recall 0.7016184573002755,precision 0.7704558015067338,specificity 0.8859807547824077,[tp,tn,fp,fn]: [52975, 122641, 15783, 22529]
VAL, loss 0.3497007388281572, acc 0.8529724677597367,f1 0.6640616125587842, recall 0.5765740886854979,precision 0.7828485724998661,specificity 0.9461083416417414,[tp,tn,fp,fn]: [14615, 71171, 4054, 10733]

TRAIN, epoch 77, loss 0.40906823038506546, acc 0.8217203919075576,recall 0.7027044924772198,precision 0.7717494072641057,specificity 0.8866381552331966,[tp,tn,fp,fn]: [53057, 122732, 15692, 22447]
VAL, loss 0.3461149236180838, acc 0.8546926113370388,f1 0.6730502483332588, recall 0.5934195991794224,precision 0.7773643410852713,specificity 0.9427318045862413,[tp,tn,fp,fn]: [15042, 70917, 4308, 10306]

TRAIN, epoch 78, loss 0.4102108987117018, acc 0.82077147451479,recall 0.7025985378258105,precision 0.7695398630613903,specificity 0.885229439981506,[tp,tn,fp,fn]: [53049, 122537, 15887, 22455]
VAL, loss 0.3490415422016523, acc 0.853787795929325,f1 0.6674055142152762, recall 0.5820577560359792,precision 0.7820832228995495,specificity 0.9453506148222001,[tp,tn,fp,fn]: [14754, 71114, 4111, 10594]

TRAIN, epoch 79, loss 0.40942039110622125, acc 0.8217344153173031,recall 0.7047573638482729,precision 0.7705630213160334,specificity 0.8855400797549557,[tp,tn,fp,fn]: [53212, 122580, 15844, 22292]
VAL, loss 0.34587644696811715, acc 0.8550704463424578,f1 0.6743084417035349, recall 0.5952737888590816,precision 0.7775430279295064,specificity 0.9426121635094716,[tp,tn,fp,fn]: [15089, 70908, 4317, 10259]

TRAIN, epoch 80, loss 0.4091444520384875, acc 0.8217157174376426,recall 0.7017509006145369,precision 0.7723085444421771,specificity 0.8871510720684275,[tp,tn,fp,fn]: [52985, 122803, 15621, 22519]
VAL, loss 0.3477702030729561, acc 0.8534000178974476,f1 0.6657447290863749, recall 0.5792567460943664,precision 0.7825924741498774,specificity 0.9457760053173812,[tp,tn,fp,fn]: [14683, 71146, 4079, 10665]

TRAIN, epoch 81, loss 0.40931954591165753, acc 0.8217063684978123,recall 0.7027177368086459,precision 0.7717078279081945,specificity 0.886609258510085,[tp,tn,fp,fn]: [53058, 122728, 15696, 22446]
VAL, loss 0.34847011433692854, acc 0.8534397900032812,f1 0.6656534954407295, recall 0.5788622376518857,precision 0.7830611591418508,specificity 0.9459621136590229,[tp,tn,fp,fn]: [14673, 71160, 4065, 10675]

TRAIN, epoch 82, loss 0.40961683555105133, acc 0.8218559515350959,recall 0.7021349862258953,precision 0.7724160037299298,specificity 0.8871582962492054,[tp,tn,fp,fn]: [53014, 122804, 15620, 22490]
VAL, loss 0.34921482697409423, acc 0.8526741769659849,f1 0.6603864402117857, recall 0.5683288622376519,precision 0.788031289316777,specificity 0.9484878697241609,[tp,tn,fp,fn]: [14406, 71350, 3875, 10942]

TRAIN, epoch 83, loss 0.40909261241383027, acc 0.8222439325380502,recall 0.7044262555626192,precision 0.7719784606006067,specificity 0.8865081199791943,[tp,tn,fp,fn]: [53187, 122714, 15710, 22317]
VAL, loss 0.3506374861779653, acc 0.8526940630189017,f1 0.6609607066846694, recall 0.5697096417863342,precision 0.7870183661234945,specificity 0.9480491857760053,[tp,tn,fp,fn]: [14441, 71317, 3908, 10907]

TRAIN, epoch 84, loss 0.40848687499441727, acc 0.8217203919075576,recall 0.7031018224200042,precision 0.7715124474996004,specificity 0.8864214298098596,[tp,tn,fp,fn]: [53087, 122702, 15722, 22417]
VAL, loss 0.3470122707576929, acc 0.8545832380459965,f1 0.6721513595911139, recall 0.591447056967019,precision 0.7783604174238098,specificity 0.9432502492522433,[tp,tn,fp,fn]: [14992, 70956, 4269, 10356]

TRAIN, epoch 85, loss 0.4085038344717691, acc 0.8221878388990689,recall 0.70432030091121,precision 0.7719071603791386,specificity 0.8864792232560827,[tp,tn,fp,fn]: [53179, 122710, 15714, 22325]
VAL, loss 0.34794780872424763, acc 0.8532707585534886,f1 0.6618701739110511, recall 0.5697885434748303,precision 0.789450669581853,specificity 0.9487936191425723,[tp,tn,fp,fn]: [14443, 71373, 3852, 10905]

TRAIN, epoch 86, loss 0.4089265981763139, acc 0.8219167196439924,recall 0.703869993642721,precision 0.7715256304167937,specificity 0.8863058429174132,[tp,tn,fp,fn]: [53145, 122686, 15738, 22359]
VAL, loss 0.3474837089162986, acc 0.8542650611993279,f1 0.6669544865822901, recall 0.57898059018463,precision 0.7864530303842238,specificity 0.9470255898969757,[tp,tn,fp,fn]: [14676, 71240, 3985, 10672]

TRAIN, epoch 87, loss 0.4081344905234744, acc 0.8220382558617852,recall 0.7030620894257258,precision 0.7722994107805339,specificity 0.8869343466450904,[tp,tn,fp,fn]: [53084, 122773, 15651, 22420]
VAL, loss 0.3487113435367161, acc 0.8538076819822418,f1 0.6687543650167843, recall 0.5855294303298091,precision 0.7795577498818215,specificity 0.9442073778664007,[tp,tn,fp,fn]: [14842, 71028, 4197, 10506]

TRAIN, epoch 88, loss 0.40854272857876217, acc 0.8219728132829737,recall 0.7026515151515151,precision 0.7723877880821698,specificity 0.8870571577183147,[tp,tn,fp,fn]: [53053, 122790, 15634, 22451]
VAL, loss 0.3492007381642458, acc 0.852902866574528,f1 0.6626994984040128, recall 0.5733391194571564,precision 0.7850583405358686,specificity 0.9471053506148222,[tp,tn,fp,fn]: [14533, 71246, 3979, 10815]

TRAIN, epoch 89, loss 0.40809754319320435, acc 0.8224636326240604,recall 0.7047838525111252,precision 0.7722918843608498,specificity 0.8866526035947524,[tp,tn,fp,fn]: [53214, 122734, 15690, 22290]
VAL, loss 0.34937654800029516, acc 0.8536585365853658,f1 0.6640953076501734, recall 0.5739703329651255,precision 0.787795105046567,specificity 0.9479029577932868,[tp,tn,fp,fn]: [14549, 71306, 3919, 10799]

TRAIN, epoch 90, loss 0.4079589854761067, acc 0.8225384241427022,recall 0.7045719432083069,precision 0.7725978854420821,specificity 0.8868837773796452,[tp,tn,fp,fn]: [53198, 122766, 15658, 22306]
VAL, loss 0.34713957321261807, acc 0.8541755739612024,f1 0.666515075719678, recall 0.5781915732996686,precision 0.7866881374127751,specificity 0.9471718178796943,[tp,tn,fp,fn]: [14656, 71251, 3974, 10692]

TRAIN, epoch 91, loss 0.40766981422961335, acc 0.8220335813918702,recall 0.7028899131171858,precision 0.7723912094309416,specificity 0.8870210368144252,[tp,tn,fp,fn]: [53071, 122785, 15639, 22433]
VAL, loss 0.3475767357138154, acc 0.854523579887246,f1 0.6731160213588329, recall 0.5942875177528799,precision 0.7760548142805626,specificity 0.9422133599202392,[tp,tn,fp,fn]: [15064, 70878, 4347, 10284]

TRAIN, epoch 92, loss 0.4075812088770506, acc 0.8225571220223626,recall 0.7041083916083916,precision 0.7729202407606641,specificity 0.8871655204299832,[tp,tn,fp,fn]: [53163, 122805, 15619, 22341]
VAL, loss 0.3482659465352463, acc 0.8543048333051614,f1 0.6703709535914336, recall 0.5878175792961969,precision 0.7799005495943471,specificity 0.9441010302426055,[tp,tn,fp,fn]: [14900, 71020, 4205, 10448]

TRAIN, epoch 93, loss 0.40755546934308373, acc 0.8219213941139075,recall 0.7031812884085611,precision 0.7719474250487074,specificity 0.8866887244986419,[tp,tn,fp,fn]: [53093, 122739, 15685, 22411]
VAL, loss 0.3458459707617795, acc 0.8545434659401628,f1 0.6697519019346683, recall 0.5852138235758245,precision 0.7828381444931131,specificity 0.9452974410103024,[tp,tn,fp,fn]: [14834, 71110, 4115, 10514]

TRAIN, epoch 94, loss 0.4074062430599161, acc 0.8231788265210725,recall 0.7048235855054037,precision 0.7739866486321393,specificity 0.8877362307114374,[tp,tn,fp,fn]: [53217, 122884, 15540, 22287]
VAL, loss 0.3452291890960886, acc 0.8551201614747497,f1 0.6731127313516545, recall 0.5918415654094997,precision 0.7802569303583502,specificity 0.9438351611831173,[tp,tn,fp,fn]: [15002, 71000, 4225, 10346]

TRAIN, epoch 95, loss 0.40667552407653335, acc 0.8233424329681014,recall 0.7049295401568129,precision 0.774316971689604,specificity 0.8879312835924407,[tp,tn,fp,fn]: [53225, 122911, 15513, 22279]
VAL, loss 0.3472312674149783, acc 0.8551400475276665,f1 0.6746320655693772, recall 0.5958655515228026,precision 0.7773946162952288,specificity 0.9425058158856763,[tp,tn,fp,fn]: [15104, 70900, 4325, 10244]

TRAIN, epoch 96, loss 0.4065054908530223, acc 0.8226038667215138,recall 0.7051017164653528,precision 0.7724384086358492,specificity 0.8866959486794197,[tp,tn,fp,fn]: [53238, 122740, 15684, 22266]
VAL, loss 0.35062219530672784, acc 0.8532608155270301,f1 0.6645451652498068, recall 0.576692441218242,precision 0.7839751153062319,specificity 0.9464539714190761,[tp,tn,fp,fn]: [14618, 71197, 4028, 10730]

TRAIN, epoch 97, loss 0.4058472366662181, acc 0.8240669758049437,recall 0.7055387794024157,precision 0.7756971241354205,specificity 0.8887187192972317,[tp,tn,fp,fn]: [53271, 123020, 15404, 22233]
VAL, loss 0.3496957427141885, acc 0.8542551181728695,f1 0.6674531512319071, recall 0.5803219188890643,precision 0.785371062466631,specificity 0.9465603190428714,[tp,tn,fp,fn]: [14710, 71205, 4020, 10638]

TRAIN, epoch 98, loss 0.40601020995682835, acc 0.8233330840282712,recall 0.7040819029455393,precision 0.7748061563574885,specificity 0.8883791828006704,[tp,tn,fp,fn]: [53161, 122973, 15451, 22343]
VAL, loss 0.3472202986217817, acc 0.8555278255595438,f1 0.6752201707720507, recall 0.5958655515228026,precision 0.7789582258896338,specificity 0.9430242605516783,[tp,tn,fp,fn]: [15104, 70939, 4286, 10244]

TRAIN, epoch 99, loss 0.4056106693896407, acc 0.8237818331401219,recall 0.7052341597796143,precision 0.7751928956179939,specificity 0.8884442004276715,[tp,tn,fp,fn]: [53248, 122982, 15442, 22256]
VAL, loss 0.3477937102502791, acc 0.8545832380459965,f1 0.6695139312588976, recall 0.5844248066908632,precision 0.7836022216344882,specificity 0.9456164838816883,[tp,tn,fp,fn]: [14814, 71134, 4091, 10534]



 * BEST_ACC: 0.8555278255595438
 * TIME: Time 9813.594 (9813.594)

